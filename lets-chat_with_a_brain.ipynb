{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMISSOR chat bot with a BRAIN that interacts through camera and NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates a simple chatbot that chats with you and stores entity mentions both as annotations and in the BRAIN.\n",
    "\n",
    "Requires spacy and a language model installed and available in the venv kernel of Jupyter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/piek/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# general imports for EMISSOR and the BRAIN\n",
    "import emissor as em\n",
    "from cltl import brain\n",
    "from cltl.triple_extraction.api import Chat, UtteranceHypothesis\n",
    "from emissor.persistence import ScenarioStorage\n",
    "from emissor.representation.scenario import Modality, ImageSignal, TextSignal, Mention, Annotation, Scenario\n",
    "from cltl.brain.long_term_memory import LongTermMemory\n",
    "from cltl.combot.backend.api.discrete import UtteranceType\n",
    "\n",
    "# specific imports\n",
    "import spacy\n",
    "from datetime import datetime\n",
    "import requests\n",
    "\n",
    "#### The next utils are needed for the interaction and creating triples and capsules\n",
    "import util.driver_util as d_util\n",
    "import util.capsule_util as c_util\n",
    "import util.text_util as t_util\n",
    "import dummies.text_to_triple as ttt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have not done so, you need to download the specific language module from spaCy using the terminal within the same venv: (venv)(bas)% python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load a language model in spaCy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the BRAIN\n",
    "\n",
    "Before we start, we need to create an empty Brain or load an existing Brain. The next code assumes we have a repository in GraphDB with the name sandbox as a brain. By setting clear_all=True it is emptied and next loaded with the background ontologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pathlib.PosixPath'>\n",
      "2021-10-29 12:17:14,506 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Booted\n",
      "2021-10-29 12:17:14,507 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Clearing brain\n",
      "2021-10-29 12:17:16,554 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Checking if ontology is in brain\n",
      "2021-10-29 12:17:16,558 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting query\n",
      "2021-10-29 12:17:17,264 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Uploading ontology to brain\n",
      "2021-10-29 12:17:20,057 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Booted\n",
      "2021-10-29 12:17:20,060 -    DEBUG -  cltl.brain.basic_brain.LocationReasoner - Booted\n",
      "2021-10-29 12:17:20,062 -    DEBUG -      cltl.brain.basic_brain.TypeReasoner - Booted\n",
      "2021-10-29 12:17:20,064 -    DEBUG -   cltl.brain.basic_brain.TrustCalculator - Booted\n",
      "2021-10-29 12:17:20,355 -    DEBUG -   cltl.brain.basic_brain.TrustCalculator - Posting query\n",
      "2021-10-29 12:17:20,402 -     INFO -   cltl.brain.basic_brain.TrustCalculator - Computed trust for all known agents\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "log_path=pathlib.Path('./logs')\n",
    "print(type(log_path))\n",
    "my_brain = brain.LongTermMemory(address=\"http://localhost:7200/repositories/sandbox\",\n",
    "                           log_dir=log_path,\n",
    "                           clear_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard initialisation of a scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  ./data/2021-10-29-12:17:22  Created \n",
      "Directory  ./data/2021-10-29-12:17:22/image  Created \n"
     ]
    }
   ],
   "source": [
    "from random import getrandbits\n",
    "\n",
    "##### Setting the location\n",
    "place_id = getrandbits(8)\n",
    "location = requests.get(\"https://ipinfo.io\").json()\n",
    "\n",
    "##### Setting the agents\n",
    "AGENT = \"Leolani2\"\n",
    "HUMAN_NAME = \"Stranger\"\n",
    "HUMAN_ID = \"stranger\"\n",
    "\n",
    "### The name of your scenario\n",
    "scenario_id = datetime.today().strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "\n",
    "### Specify the path to an existing data folder where your scenario is created and saved as a subfolder\n",
    "scenario_path = \"./data\"\n",
    "\n",
    "### Define the folder where the images are saved\n",
    "imagefolder = scenario_path + \"/\" + scenario_id + \"/\" + \"image\"\n",
    "\n",
    "\n",
    "### Create the scenario folder, the json files and a scenarioStorage and scenario in memory\n",
    "scenarioStorage = d_util.create_scenario(scenario_path, scenario_id)\n",
    "scenario = scenarioStorage.create_scenario(scenario_id, datetime.now().microsecond, datetime.now().microsecond, AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Starting the interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: Hi there. Who are you Stranger?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " I am from Amsterdam\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stranger: I am from Amsterdam\n",
      "Subject: Amsterdam Predicate: denotedBy Object: 1e3758ea-d485-4080-9641-4aff0e508a91\n",
      "Capsule: {'chat': '2021-10-29-12:17:22', 'turn': '1e3758ea-d485-4080-9641-4aff0e508a91', 'author': 'stranger', 'utterance': 'I am from Amsterdam', 'utterance_type': <UtteranceType.STATEMENT: 0>, 'position': '0-19', 'subject': {'label': 'Amsterdam', 'type': 'person'}, 'predicate': {'type': 'denotedBy'}, 'object': {'label': '1e3758ea-d485-4080-9641-4aff0e508a91', 'type': 'object'}, 'perspective': {'certainty': 1, 'polarity': 1, 'sentiment': 1}, 'context_id': 'Leolani2', 'date': datetime.date(2021, 10, 29), 'place': 'Amsterdam', 'place_id': 110, 'country': 'NL', 'region': 'North Holland', 'city': 'Amsterdam', 'objects': [{'type': 'chair', 'confidence': 0.59, 'id': 1}, {'type': 'table', 'confidence': 0.73, 'id': 1}, {'type': 'pillbox', 'confidence': 0.32, 'id': 1}], 'people': [{'name': 'stranger', 'confidence': 0.98, 'id': 1}]}\n",
      "2021-10-29 12:44:07,017 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting query\n",
      "2021-10-29 12:44:07,026 -    DEBUG -  cltl.brain.basic_brain.LocationReasoner - Posting query\n",
      "2021-10-29 12:44:07,085 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: amsterdam_denotedby_1e3758ea-d485-4080-9641-4aff0e508a91 [person_->_object])\n",
      "2021-10-29 12:44:07,086 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n",
      "2021-10-29 12:44:07,119 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n",
      "2021-10-29 12:44:07,123 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n",
      "2021-10-29 12:44:07,166 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Entity Novelty: new subject - new object \n",
      "2021-10-29 12:44:07,167 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n",
      "2021-10-29 12:44:07,176 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n",
      "2021-10-29 12:44:08,351 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting triples\n",
      "2021-10-29 12:44:09,373 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n",
      "2021-10-29 12:44:09,423 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n",
      "2021-10-29 12:44:09,469 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n",
      "2021-10-29 12:44:09,478 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 0 gaps as subject: e.g. '' - 7 gaps as object: e.g. travel-to agent\n",
      "2021-10-29 12:44:09,479 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n",
      "2021-10-29 12:44:09,519 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n",
      "2021-10-29 12:44:09,525 -    DEBUG -   cltl.brain.basic_brain.TrustCalculator - Posting query\n",
      "Leolani2: I am thinking: new subject - new object; 0 gaps as subject: e.g. '' - 0 gaps as object: e.g. ''; 0 subject overlaps: e.g. '' - 0 object overlaps: e.g. '';0 gaps as subject: e.g. '' - 7 gaps as object: e.g. travel-to agent; \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " stop\n"
     ]
    }
   ],
   "source": [
    "##### First signals to get started\n",
    "\n",
    "#### Initial prompt by the system from which we create a TextSignal and store it\n",
    "initial_prompt = \"Hi there. Who are you \" + HUMAN_NAME + \"?\"\n",
    "print(AGENT + \": \" + initial_prompt)\n",
    "textSignal = d_util.create_text_signal(scenario, initial_prompt)\n",
    "scenario.append_signal(textSignal)\n",
    "\n",
    "utterance = input('\\n')\n",
    "print(HUMAN_NAME + \": \" + utterance)\n",
    "while not (utterance.lower() == 'stop' or utterance.lower() == 'bye'):\n",
    "    textSignal = d_util.create_text_signal(scenario, utterance)\n",
    "\n",
    "    ### Apply some processing to the textSignal and add annotations\n",
    "    entityText = t_util.add_ner_annotation_with_spacy(textSignal, nlp)\n",
    "    scenario.append_signal(textSignal)\n",
    "    \n",
    "    ## Post triples to the brain:\n",
    "    ### we use a dummy function that creates a denotedBy triple for the entityText\n",
    "    subj, pred, obj = ttt.getTriplesFromEntities(entityText, textSignal.id)\n",
    "\n",
    "    response = {}\n",
    "    if not subj==\"\":\n",
    "        print('Subject:', subj, 'Predicate:', pred, 'Object:', obj)\n",
    "        perspective = {\"certainty\": 1, \"polarity\": 1, \"sentiment\": 1}\n",
    "        capsule = c_util.scenario_utterance_to_capsule(scenario, place_id, location, textSignal, HUMAN_ID, perspective, subj, pred, obj)\n",
    "        \n",
    "        print('Capsule:', capsule)\n",
    "        \n",
    "        \n",
    "        #response = my_brain.update(capsule, reason_types=True, create_label=False) ## use this version if you want to use the URI as subject\n",
    "        response = my_brain.update(capsule, reason_types=True) ## this function creates a label from the subject\n",
    "\n",
    "        #print(thoughts)\n",
    "\n",
    "\n",
    "    # Create the response from the system and store this as a new signal\n",
    "    utterance = ttt.getTextFromTriples(response)\n",
    "    if not utterance:\n",
    "        if not entityText:\n",
    "            utterance = \"Any gossip\" + '\\n'\n",
    "        else:\n",
    "            utterance = \"So you what do you want to talk about \" + entityText[0] + '\\n'\n",
    "\n",
    "    response = utterance[::-1]\n",
    "    print(AGENT + \": \" + utterance)\n",
    "    textSignal = d_util.create_text_signal(scenario, utterance)\n",
    "    scenario.append_signal(textSignal)\n",
    "\n",
    "    ###### Getting the next input signals\n",
    "    utterance = input('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After we stopped the interaction, we set the end time of the scenarion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scenario.scenario.end = datetime.now().microsecond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Saving the Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarioStorage.save_scenario(scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
