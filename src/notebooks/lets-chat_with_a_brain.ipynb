{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMISSOR chat bot with a BRAIN that interacts through camera and NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@CLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates a simple chatbot that chats with you and stores entity mentions both as annotations and in the BRAIN.\n",
    "\n",
    "Requires spacy and a language model installed and available in the venv kernel of Jupyter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports for EMISSOR and the BRAIN\n",
    "import emissor as em\n",
    "from cltl import brain\n",
    "from cltl.triple_extraction.api import Chat, UtteranceHypothesis\n",
    "from emissor.persistence import ScenarioStorage\n",
    "from emissor.representation.scenario import Modality, ImageSignal, TextSignal, Mention, Annotation, Scenario\n",
    "from cltl.brain.long_term_memory import LongTermMemory\n",
    "from cltl.combot.backend.api.discrete import UtteranceType\n",
    "from cltl.reply_generation.lenka_replier import LenkaReplier\n",
    "\n",
    "# specific imports\n",
    "import spacy\n",
    "from datetime import datetime\n",
    "import requests\n",
    "\n",
    "#### The next utils are needed for the interaction and creating triples and capsules\n",
    "import util.driver_util as d_util\n",
    "import util.capsule_util as c_util\n",
    "import util.text_util as t_util\n",
    "import dummies.text_to_triple as ttt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have not done so, you need to download the specific language module from spaCy using the terminal within the same venv: (venv)(bas)% python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load a language model in spaCy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the BRAIN\n",
    "\n",
    "Before we start, we need to create an empty Brain or load an existing Brain. The next code assumes we have a repository in GraphDB with the name sandbox as a brain. By setting clear_all=True it is emptied and next loaded with the background ontologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pathlib.PosixPath'>\n",
      "2021-10-31 22:01:29,190 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Booted\n",
      "2021-10-31 22:01:29,192 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Clearing brain\n",
      "2021-10-31 22:01:30,020 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Checking if ontology is in brain\n",
      "2021-10-31 22:01:30,021 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting query\n",
      "2021-10-31 22:01:30,669 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Uploading ontology to brain\n",
      "2021-10-31 22:01:32,250 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Booted\n",
      "2021-10-31 22:01:32,252 -    DEBUG -  cltl.brain.basic_brain.LocationReasoner - Booted\n",
      "2021-10-31 22:01:32,255 -    DEBUG -      cltl.brain.basic_brain.TypeReasoner - Booted\n",
      "2021-10-31 22:01:32,256 -    DEBUG -   cltl.brain.basic_brain.TrustCalculator - Booted\n",
      "2021-10-31 22:01:32,400 -    DEBUG -   cltl.brain.basic_brain.TrustCalculator - Posting query\n",
      "2021-10-31 22:01:32,408 -     INFO -   cltl.brain.basic_brain.TrustCalculator - Computed trust for all known agents\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "log_path=pathlib.Path('./logs')\n",
    "print(type(log_path))\n",
    "my_brain = brain.LongTermMemory(address=\"http://localhost:7200/repositories/sandbox\",\n",
    "                           log_dir=log_path,\n",
    "                           clear_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard initialisation of a scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-31 22:01:33,435 -    DEBUG -   cltl.reply_generation.api.LenkaReplier - Booted\n",
      "Directory  ./data/2021-10-31-22:01:33  Created \n",
      "Directory  ./data/2021-10-31-22:01:33/image  Created \n"
     ]
    }
   ],
   "source": [
    "from random import getrandbits\n",
    "\n",
    "replier = LenkaReplier()\n",
    "\n",
    "##### Setting the location\n",
    "place_id = getrandbits(8)\n",
    "location = requests.get(\"https://ipinfo.io\").json()\n",
    "\n",
    "##### Setting the agents\n",
    "AGENT = \"Leolani2\"\n",
    "HUMAN_NAME = \"Stranger\"\n",
    "HUMAN_ID = \"stranger\"\n",
    "\n",
    "### The name of your scenario\n",
    "scenario_id = datetime.today().strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "\n",
    "### Specify the path to an existing data folder where your scenario is created and saved as a subfolder\n",
    "scenario_path = \"./data\"\n",
    "\n",
    "### Define the folder where the images are saved\n",
    "imagefolder = scenario_path + \"/\" + scenario_id + \"/\" + \"image\"\n",
    "\n",
    "\n",
    "### Create the scenario folder, the json files and a scenarioStorage and scenario in memory\n",
    "scenarioStorage = d_util.create_scenario(scenario_path, scenario_id)\n",
    "scenario = scenarioStorage.create_scenario(scenario_id, datetime.now().microsecond, datetime.now().microsecond, AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Starting the interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: Hi there. Who are you Stranger?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " I am from Amsterdam\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stranger: I am from Amsterdam\n",
      "Subject: Amsterdam Predicate: denotedBy Object: 9c3ecd0c-fd3c-4db3-b9ae-66f82ef643cc\n",
      "Capsule: {'chat': '2021-10-31-21:52:22', 'turn': '9c3ecd0c-fd3c-4db3-b9ae-66f82ef643cc', 'author': 'stranger', 'utterance': 'I am from Amsterdam', 'utterance_type': <UtteranceType.STATEMENT: 0>, 'position': '0-19', 'subject': {'label': 'Amsterdam', 'type': 'person'}, 'predicate': {'type': 'denotedBy'}, 'object': {'label': '9c3ecd0c-fd3c-4db3-b9ae-66f82ef643cc', 'type': 'object'}, 'perspective': {'certainty': 1, 'polarity': 1, 'sentiment': 1}, 'context_id': 'Leolani2', 'date': datetime.date(2021, 10, 31), 'place': 'Weesp', 'place_id': 249, 'country': 'NL', 'region': 'North Holland', 'city': 'Weesp', 'objects': [{'type': 'chair', 'confidence': 0.59, 'id': 1}, {'type': 'table', 'confidence': 0.73, 'id': 1}, {'type': 'pillbox', 'confidence': 0.32, 'id': 1}], 'people': [{'name': 'stranger', 'confidence': 0.98, 'id': 1}]}\n",
      "2021-10-31 21:52:30,703 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting query\n",
      "2021-10-31 21:52:30,732 -    DEBUG -  cltl.brain.basic_brain.LocationReasoner - Posting query\n",
      "2021-10-31 21:52:30,767 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: amsterdam_denotedby_9c3ecd0c-fd3c-4db3-b9ae-66f82ef643cc [person_->_object])\n",
      "2021-10-31 21:52:30,768 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n",
      "2021-10-31 21:52:30,778 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n",
      "2021-10-31 21:52:30,789 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n",
      "2021-10-31 21:52:30,795 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Entity Novelty: new subject - new object \n",
      "2021-10-31 21:52:30,796 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n",
      "2021-10-31 21:52:30,812 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n",
      "2021-10-31 21:52:31,938 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting triples\n",
      "2021-10-31 21:52:32,310 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n",
      "2021-10-31 21:52:32,320 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n",
      "2021-10-31 21:52:32,328 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n",
      "2021-10-31 21:52:32,335 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n",
      "2021-10-31 21:52:32,342 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n",
      "2021-10-31 21:52:32,350 -    DEBUG -   cltl.brain.basic_brain.TrustCalculator - Posting query\n",
      "Leolani2: I am thinking: new subject - new object; 0 gaps as subject: e.g. '' - 0 gaps as object: e.g. ''; 0 subject overlaps: e.g. '' - 0 object overlaps: e.g. '';0 gaps as subject: e.g. '' - 0 gaps as object: e.g. ''; \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3d0f9348e28b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m###### Getting the next input signals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mutterance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m         )\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "##### First signals to get started\n",
    "\n",
    "#### Initial prompt by the system from which we create a TextSignal and store it\n",
    "initial_prompt = \"Hi there. Who are you \" + HUMAN_NAME + \"?\"\n",
    "print(AGENT + \": \" + initial_prompt)\n",
    "textSignal = d_util.create_text_signal(scenario, initial_prompt)\n",
    "scenario.append_signal(textSignal)\n",
    "\n",
    "utterance = input('\\n')\n",
    "print(HUMAN_NAME + \": \" + utterance)\n",
    "while not (utterance.lower() == 'stop' or utterance.lower() == 'bye'):\n",
    "    textSignal = d_util.create_text_signal(scenario, utterance)\n",
    "\n",
    "    ### Apply some processing to the textSignal and add annotations\n",
    "    entityText = t_util.add_ner_annotation_with_spacy(textSignal, nlp)\n",
    "    scenario.append_signal(textSignal)\n",
    "    \n",
    "    ## Post triples to the brain:\n",
    "    ### we use a dummy function that creates a denotedBy triple for the entityText\n",
    "    subj, pred, obj = ttt.getTriplesFromEntities(entityText, textSignal.id)\n",
    "\n",
    "    response = {}\n",
    "    if not subj==\"\":\n",
    "        print('Subject:', subj, 'Predicate:', pred, 'Object:', obj)\n",
    "        perspective = {\"certainty\": 1, \"polarity\": 1, \"sentiment\": 1}\n",
    "        capsule = c_util.scenario_utterance_to_capsule_with_perspective(scenario, place_id, location, textSignal, HUMAN_ID, perspective, subj, pred, obj)\n",
    "        \n",
    "        print('Capsule:', capsule)\n",
    "        \n",
    "        \n",
    "        response = my_brain.update(capsule, reason_types=True, create_label=False) ## use this version if you want to use the URI as subject\n",
    "        #response = my_brain.update(capsule, reason_types=True) ## this function creates a label from the subject\n",
    "\n",
    "        #print(thoughts)\n",
    "\n",
    "\n",
    "    # Create the response from the system and store this as a new signal\n",
    "    utterance = ttt.getTextFromTriples(response)\n",
    "    if not utterance:\n",
    "        if not entityText:\n",
    "            utterance = \"Any gossip\" + '\\n'\n",
    "        else:\n",
    "            utterance = \"So you what do you want to talk about \" + entityText[0] + '\\n'\n",
    "\n",
    "    response = utterance[::-1]\n",
    "    print(AGENT + \": \" + utterance)\n",
    "    textSignal = d_util.create_text_signal(scenario, utterance)\n",
    "    scenario.append_signal(textSignal)\n",
    "\n",
    "    ###### Getting the next input signals\n",
    "    utterance = input('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After we stopped the interaction, we set the end time of the scenarion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scenario.scenario.end = datetime.now().microsecond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Saving the Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarioStorage.save_scenario(scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
