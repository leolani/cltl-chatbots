{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's chat with a friend and I have a brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo chat with Leolani that combine face recognition and storage in the BRAIN. This notebook combines the functions of two other notebooks:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports for EMISSOR and the BRAIN\n",
    "import emissor as em\n",
    "from cltl import brain\n",
    "from cltl.triple_extraction.api import Chat, UtteranceHypothesis\n",
    "from emissor.persistence import ScenarioStorage\n",
    "from emissor.representation.annotation import AnnotationType, Token, NER\n",
    "from emissor.representation.container import Index\n",
    "from emissor.representation.scenario import Modality, ImageSignal, TextSignal, Mention, Annotation, Scenario\n",
    "from cltl.brain.long_term_memory import LongTermMemory\n",
    "from cltl.combot.backend.api.discrete import UtteranceType\n",
    "from cltl.reply_generation.data.sentences import GREETING, ASK_NAME, ELOQUENCE, TALK_TO_ME\n",
    "from cltl.reply_generation.lenka_replier import LenkaReplier\n",
    "from cltl.triple_extraction.api import Chat, UtteranceHypothesis\n",
    "from cltl.brain.utils.helper_functions import brain_response_to_json\n",
    "\n",
    "\n",
    "# specific imports\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "import time\n",
    "import cv2\n",
    "import requests\n",
    "import pickle\n",
    "import jsonpickle\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cltl.asr.speechbrain_asr import SpeechbrainASR\n",
    "from cltl.asr.wav2vec_asr import Wav2Vec2ASR\n",
    "from cltl.backend.api.camera import CameraResolution \n",
    "from cltl.backend.source.pyaudio_source import PyAudioSource\n",
    "from cltl.backend.source.cv2_source import SystemImageSource\n",
    "from cltl.backend.source.client_source import ClientAudioSource, ClientImageSource\n",
    "from cltl.vad.webrtc_vad import WebRtcVAD\n",
    "\n",
    "from cltl.backend.api.util import raw_frames_to_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_remote = False\n",
    "\n",
    "audio_source = ClientAudioSource(\"http://192.168.1.176:8000/audio\") if run_remote else PyAudioSource(16000, 1, 480)\n",
    "image_source = ClientImageSource(\"http://192.168.1.176:8000/video\") if run_remote else SystemImageSource(CameraResolution.QVGA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Add a `storage` directory to store audio files to VAD or ASR for debugging\n",
    "vad = WebRtcVAD(allow_gap=250, padding=5, storage=\"./audio\")\n",
    "#asr=Wav2Vec2ASR(\"jonatasgrosman/wav2vec2-large-xlsr-53-english\", 16000, storage=\"./audio\")\n",
    "asr = SpeechbrainASR(model_id=\"speechbrain/asr-transformer-transformerlm-librispeech\",storage=\"./audio\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Voice detection and speech recognition\n",
    "def detect_and_transcribe():\n",
    "    text = \"\"\n",
    "    with audio_source as audio:\n",
    "        frames = raw_frames_to_np(audio, audio_source.frame_size, audio_source.channels, audio_source.depth)\n",
    "\n",
    "        print(\"Listening\")\n",
    "        speech, offset, consumed = tuple(vad.detect_vad(frames, audio_source.rate))\n",
    "        print(\"Voice activity detected\")\n",
    "\n",
    "        text = asr.speech_to_text(np.concatenate(tuple(speech)), audio_source.rate)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting an image from the source\n",
    "def take_image():\n",
    "    image = None\n",
    "\n",
    "        \n",
    "    with image_source as img_src:\n",
    "        image = img_src.capture()\n",
    "\n",
    "\n",
    "    return True, image.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Posting a text and gesture\n",
    "def speak_and_act(text:str, animation:str=None):\n",
    "    tts_headers = {'Content-type': 'text/plain'}\n",
    "    if animation:\n",
    "        response = f\"\\\\^startTag({animation}){text}^stopTag({animation})\"   #### cannot pass in strings with quotes!!\n",
    "    else:\n",
    "         response = f\"{text}\"   #### cannot pass in strings with quotes!!           \n",
    "    requests.post(\"http://192.168.1.176:8000/text\", data=response, headers=tts_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "src_path = os.path.abspath(os.path.join('..'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "#### The next utils are needed for the interaction and creating triples and capsules\n",
    "import chatbots.util.driver_util as d_util\n",
    "import chatbots.util.capsule_util as c_util\n",
    "import chatbots.intentions.talk as talk\n",
    "import chatbots.util.face_util as f_util\n",
    "import chatbots.intentions.get_to_know_you as friend\n",
    "import chatbots.intentions.gestures as gestures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Link your camera\n",
    "#camera = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the BRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:17:04,037 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Booted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Booted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:17:11,223 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Uploading ontology to brain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading ontology to brain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:17:13,019 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Booted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Booted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:17:13,022 -     INFO -  cltl.brain.basic_brain.LocationReasoner - Booted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Booted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:17:13,025 -     INFO -      cltl.brain.basic_brain.TypeReasoner - Booted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Booted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:17:13,027 -     INFO -   cltl.brain.basic_brain.TrustCalculator - Booted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Booted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:17:13,121 -     INFO -   cltl.brain.basic_brain.TrustCalculator - Computed trust for all known agents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computed trust for all known agents\n"
     ]
    }
   ],
   "source": [
    "# Initialise the brain in GraphDB\n",
    "import pathlib\n",
    "\n",
    "log_path = pathlib.Path('./logs')\n",
    "my_brain = brain.LongTermMemory(address=\"http://localhost:7200/repositories/sandbox\",\n",
    "                                log_dir=log_path,\n",
    "                                clear_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an instance of a replier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:17:16,343 -     INFO -   cltl.reply_generation.api.LenkaReplier - Booted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Booted\n"
     ]
    }
   ],
   "source": [
    "replier = LenkaReplier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard initialisation of a scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paths with the friends: /Users/piek/PycharmProjects/cltl-chatbots/friend_embeddings\n",
      "Directories for 2022-02-01-13:17:35 created in /Users/piek/PycharmProjects/cltl-chatbots/data\n"
     ]
    }
   ],
   "source": [
    "from random import getrandbits, choice\n",
    "import requests\n",
    "##### Setting the location\n",
    "place_id = getrandbits(8)\n",
    "location = None\n",
    "try:\n",
    "    location = requests.get(\"https://ipinfo.io\").json()\n",
    "except:\n",
    "    print(\"failed to get the IP location\")\n",
    "    \n",
    "##### Setting the agents\n",
    "AGENT = \"Leolani2\"\n",
    "HUMAN_NAME = \"Stranger\"\n",
    "HUMAN_ID = \"stranger\"\n",
    "\n",
    "### The name of your scenario\n",
    "scenario_id = datetime.today().strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "\n",
    "### Specify the path to an existing data folder where your scenario is created and saved as a subfolder\n",
    "# Find the repository root dir\n",
    "parent, dir_name = (d_util.__file__, \"_\")\n",
    "while dir_name and dir_name != \"src\":\n",
    "    parent, dir_name = os.path.split(parent)\n",
    "root_dir = parent\n",
    "scenario_path = os.path.abspath(os.path.join(root_dir, 'data'))\n",
    "\n",
    "if scenario_path not in sys.path:\n",
    "    sys.path.append(scenario_path)\n",
    "\n",
    "if not os.path.exists(scenario_path) :\n",
    "    os.mkdir(scenario_path)\n",
    "    print(\"Created a data folder for storing the scenarios\", scenario_path)\n",
    "\n",
    "### Specify the path to an existing folder with the embeddings of your friends\n",
    "friends_path = os.path.abspath(os.path.join(root_dir, 'friend_embeddings'))\n",
    "if friends_path not in sys.path:\n",
    "    sys.path.append(friends_path)\n",
    "    print(\"The paths with the friends:\", friends_path)\n",
    "    \n",
    "### Define the folders where the images and rdf triples are saved\n",
    "imagefolder = scenario_path + \"/\" + scenario_id + \"/\" + \"image\"\n",
    "rdffolder = scenario_path + \"/\" + scenario_id + \"/\" + \"rdf\"\n",
    "\n",
    "\n",
    "### Create the scenario folder, the json files and a scenarioStorage and scenario in memory\n",
    "scenarioStorage = d_util.create_scenario(scenario_path, scenario_id)\n",
    "scenario_ctrl = scenarioStorage.create_scenario(scenario_id, int(time.time() * 1e3), None, AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the docker containers for face detection and face property detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the docker images are running you can skip the next part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is only needed if you start the docker containers from this notebook\n",
    "\n",
    "#container_fdr = f_util.start_docker_container(\"tae898/face-detection-recognition:v0.1\", 10002)\n",
    "#container_ag = f_util.start_docker_container(\"tae898/age-gender:v0.2\", 10003)\n",
    "#cntainer_yolo = f_util.start_docker_container(\"tae898/yolov5\", 10004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is a problem starting the dockers, you may need to kill them and start them again. Use the following command to kill and rerun the previous command. Note that if there are running already you should not restart. Starting it again gives an error that the port is occupied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!docker kill $(docker ps -q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting and storing triples from an utterance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function processes any textSignal using the baseline language model from the Leolani platform.\n",
    "This model uses a context-free grammar and closed-class lexicons specifically designed for social robot interaction.\n",
    "\n",
    "The function creates a capsule for posting any triples and perspective to the BRAIN.\n",
    "If no triples are extracted, a dummy prompt is returned: \"Any gossip?\".\n",
    "\n",
    "Any thoughts coming from the BRAIN are returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new friend.\n",
    "\n",
    "The functions in *intentions/get_to_know_you.py* are needed to get the properties and visual information for identifying a new friend.\n",
    "\n",
    "The visual information is based on the camera images of the uses from which we extract an averaged embedding.\n",
    "These embeddings are store in the *friend_embeddings* folder. \n",
    "\n",
    "By comparing an image with the stored embeddings, the system decides whether a person is a *stranger*.\n",
    "In case the user is a *stranger*, the system will try to get to know him/her.\n",
    "\n",
    "If you delete someone's embeddings from the *friend_embeddings* folder. This person will become a *stranger* again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piek/PycharmProjects/cltl-chatbots/data/2022-02-01-13:17:35/image/1643718126677.png image loaded!\n",
      "got <Response [200]> from server!...\n",
      "1 faces deteced!\n",
      "new face!\n",
      "got <Response [200]> from server!...\n",
      "got <Response [200]> from server!...\n",
      "YOLO image annotation is done!\n",
      "Annotating face, genders, and ages is done!\n",
      "image annotation is done!\n",
      "image saved at /Users/piek/PycharmProjects/cltl-chatbots/data/2022-02-01-13:17:35/image/1643718126677.png.ANNOTATED.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: Hi there. We haven't met. I only know that \n",
      "your estimated age is 43 \n",
      " and that your estimated gender is male. What's your name?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Piek\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek\n",
      "Leolani2: So your name is Piek?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: Nice to meet you, Piek\n",
      "\n",
      "Leolani2: So you what do you want to talk about Piek?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parse_age(face_info):\n",
    "    return round(face_info.age[\"mean\"])\n",
    "def parse_gender(face_info):\n",
    "    return \"male\" if face_info.gender[\"m\"] > 0.5 else \"female\"\n",
    "def parse_bbox(face_info):\n",
    "    return [int(num) for num in face_info.bbox.tolist()]\n",
    "def parse_id(face_info):\n",
    "    return face_info.face_id['name'] if 'name' in face_info.face_id else f\"Stranger_t_{int(time.time() * 1e3)}\"\n",
    "def parse_name(face_info):\n",
    "    face_id = parse_id(face_info)\n",
    "    return face_id.split(\"_t_\")[0] if face_id else \"Stranger\"\n",
    "\n",
    "# First signals to get started\n",
    "faces =[]\n",
    "while not len(faces) == 1:\n",
    "    success, frame = take_image() #camera.read()\n",
    "    if not success:\n",
    "        raise ValueError(\"Failed to take a picture\")\n",
    "        \n",
    "    image_time = int(time.time() * 1e3)\n",
    "    imagepath = d_util.absolute_path(scenarioStorage, scenario_id, Modality.IMAGE, f\"{image_time}.png\")\n",
    "    cv2.imwrite(imagepath, frame)\n",
    "    \n",
    "    faces = f_util.detect_faces(friends_path, imagepath)\n",
    "    \n",
    "    image_bbox = (0, 0, frame.shape[1], frame.shape[0])\n",
    "    imageSignal = d_util.create_image_signal(scenario_ctrl, f\"{image_time}.png\", image_bbox, image_time)\n",
    "    mentions = [f_util.create_face_mention(imageSignal, \"front_camera\", image_time,\n",
    "                                           parse_bbox(face), parse_id(face), parse_name(face),\n",
    "                                           parse_age(face), parse_gender(face), face.det_score)\n",
    "                for face in faces]\n",
    "    \n",
    "    imageSignal.mentions.extend(mentions)\n",
    "    scenario_ctrl.append_signal(imageSignal)\n",
    "\n",
    "    if not faces:\n",
    "        response = \"Hi, anyone there? I can't see you..\"\n",
    "        time.sleep(3)\n",
    "    elif len(faces) > 1:\n",
    "        response = \"Hi there! Apologizes, but I will only talk to one of you at a time..\"\n",
    "        time.sleep(3)\n",
    "    else:\n",
    "        face = faces[0]\n",
    "        if parse_id(face) is None:\n",
    "            ### This is a stranger, we process the new face\n",
    "            HUMAN_ID, HUMAN_NAME, _ = friend.get_to_know_person(scenario_ctrl, AGENT, parse_gender(face),\n",
    "                                                                parse_age(face), face.face_id, face.embedding,\n",
    "                                                                friends_path)\n",
    "            HUMAN_ID = HUMAN_NAME  ### Hack because we cannot force the namespace through capsules, name and identity are the same till this is fixed\n",
    "\n",
    "\n",
    "            ### Add the new information to the signal\n",
    "            mention = f_util.create_face_mention(imageSignal, \"front_camera\", int(time.time() * 1e3),\n",
    "                                                 parse_bbox(face), HUMAN_ID, HUMAN_NAME,\n",
    "                                                 parse_age(face), parse_gender(face), face.det_score)\n",
    "            imageSignal.mentions.append(mention)\n",
    "\n",
    "            response = f\"So you what do you want to talk about {HUMAN_NAME}?\"\n",
    "        else:\n",
    "            ### We know this person\n",
    "            HUMAN_ID = parse_id(face)\n",
    "            HUMAN_NAME = parse_name(face)\n",
    "            response = f\"Hi {parse_name(face)}. Nice to see you again. How are you today?\"\n",
    "\n",
    "    print(f\"{AGENT}: {response}\\n\")\n",
    "\n",
    "    # Store signals, annotated with the infered Person information\n",
    "    textSignal = d_util.create_text_signal_with_speaker_annotation(scenario_ctrl, response, AGENT)\n",
    "    scenario_ctrl.append_signal(textSignal)\n",
    "    \n",
    "scenarioStorage.save_scenario(scenario_ctrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceed to communicate with an identified friend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next while loop is for continuous communication with the identified user until *stop* or *bye*.\n",
    "We process the user input and the captured image sequentially step by step in the code block of the while loop.\n",
    "At the end of the code block, a response is generated and new input from the user is requested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first initialise a Chat class with the HUMAN_ID value for the speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:27:52,596 -     INFO - cltl.triple_extraction.api.Chat (Piek)              000 - << Start of Chat with Piek >>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<< Start of Chat with Piek >>\n"
     ]
    }
   ],
   "source": [
    "chat = Chat(HUMAN_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respondig to what it sees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function that does the following:\n",
    "\n",
    "* captures an image from the camera\n",
    "* creates an imageSignal from it, \n",
    "* annotates the image with the mention of the person\n",
    "* stores the mention in the brain as a perceivedBy data\n",
    "* gets the response from the brain\n",
    "* verbalises the response\n",
    "* stores the verbalised response as a textSignal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respond to an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond_to_an_image(imagefolder, \n",
    "                        scenario_ctrl, \n",
    "                        place_id, \n",
    "                        location, \n",
    "                        HUMAN_ID, \n",
    "                        my_brain, \n",
    "                        replier,\n",
    "                       respond_to_thought:False):\n",
    "        ## We capture the image again\n",
    "    ## For now, we only take pictures of faces of the user\n",
    "    ## @TODO add object recognition and check if there are other people detected than the user\n",
    "    what_did_i_see = []\n",
    "\n",
    "    success, frame = take_image() # camera.read()\n",
    "    if success:\n",
    "        current_time = int(time.time() * 1e3)\n",
    "        imagepath = f\"{imagefolder}/{current_time}.png\"\n",
    "        image_bbox = (0, 0, frame.shape[1], frame.shape[0])\n",
    "        cv2.imwrite(imagepath, frame)\n",
    "        print(imagepath)\n",
    " \n",
    "        results = f_util.detect_objects(imagepath)\n",
    "\n",
    "        #[{'det_score': 0.9202485680580139, 'label_num': 0, 'label_string': 'person', 'yolo_bbox': [430, 349, 918, 715]}, \n",
    "        # {'det_score': 0.45640841126441956, 'label_num': 0, 'label_string': 'person', 'yolo_bbox': [309, 167, 365, 324]}, \n",
    "        #{'det_score': 0.339588463306427, 'label_num': 72, 'label_string': 'refrigerator', 'yolo_bbox': [0, 208, 111, 707]}]\n",
    "       \n",
    "        imageSignal = d_util.create_image_signal(scenario_ctrl, f\"{current_time}.png\", image_bbox, current_time)\n",
    "        scenario_ctrl.append_signal(imageSignal)\n",
    "\n",
    "        ## The next for loop creates a capsule for each object detected in the image and posts a perceivedIn property for the object in the signal\n",
    "        ## The \"front_camera\" is the source of the signal\n",
    "        for result in results:\n",
    "            current_time = int(time.time() * 1e3)\n",
    "            \n",
    "            bbox = [int(num) for num in result['yolo_bbox']]\n",
    "            object_type = result['label_string']\n",
    "            object_prob = result['det_score']\n",
    "            what_did_i_see.append(object_type)\n",
    "            mention = f_util.create_object_mention(imageSignal, \"front_camera\", current_time, bbox, object_type, object_prob)\n",
    "            imageSignal.mentions.append(mention)\n",
    "            \n",
    "            ### We created a perceivedBy triple for this experience, \n",
    "            ### @TODO we need to include the bouding box somehow in the object\n",
    "            capsule = c_util.scenario_image_triple_to_capsule(scenario_ctrl,\n",
    "                                                              place_id,\n",
    "                                                              location,\n",
    "                                                              imageSignal,\n",
    "                                                              \"front_camera\",\n",
    "                                                              object_type,\n",
    "                                                              \"perceivedIn\",\n",
    "                                                              imageSignal.id)\n",
    "\n",
    "            # Create the response from the system and store this as a new signal\n",
    "            # We use the throughts to respond\n",
    "            response = my_brain.update(capsule, reason_types=True, create_label=True)\n",
    "            if (respond_to_thought):\n",
    "                response_json = brain_response_to_json(response)\n",
    "                reply = replier.reply_to_statement(response_json, proactive=True, persist=True)\n",
    "                print(AGENT + \": \" + reply)\n",
    "                textSignal = d_util.create_text_signal_with_speaker_annotation(scenario_ctrl, reply, AGENT)\n",
    "                scenario_ctrl.append_signal(textSignal)\n",
    "        \n",
    "    return what_did_i_see"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start conversation now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: Tell me anything, I love learning things\n",
      "Listening\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetch asr-1643720257.261463.wav: Linking to local file in /Users/piek/PycharmProjects/cltl-chatbots/src/notebooks/audio/asr-1643720257.261463.wav.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voice activity detected\n",
      "Piek: IT'S ME AGAIN\n",
      "\n",
      "2022-02-01 13:57:41,516 -     INFO - cltl.triple_extraction.api.Chat (Piek)              025 -       Piek: \"IT'S ME AGAIN\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      Piek: \"IT'S ME AGAIN\"\n",
      "Couldn't parse input\n",
      "Couldn't parse input\n",
      "Couldn't parse input\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: But, why?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piek/PycharmProjects/cltl-chatbots/data/2022-02-01-13:17:35/image/1643720264438.png image loaded!\n",
      "got <Response [200]> from server!...\n",
      "YOLO image annotation is done!\n",
      "image annotation is done!\n",
      "image saved at /Users/piek/PycharmProjects/cltl-chatbots/data/2022-02-01-13:17:35/image/1643720264438.png.ANNOTATED.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/piek/PycharmProjects/cltl-chatbots/data/2022-02-01-13:17:35/image/1643720264438.png\n",
      "2022-02-01 13:57:47,751 -  WARNING -      cltl.brain.basic_brain.TypeReasoner - Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Read timed out. (read timeout=3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Read timed out. (read timeout=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:57:48,166 -     INFO -      cltl.brain.basic_brain.TypeReasoner - Reasoned type of 16cc06ec-b38c-4425-97ee-0292ab38d5d1 to: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reasoned type of 16cc06ec-b38c-4425-97ee-0292ab38d5d1 to: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:57:48,223 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: chair_perceivedin_16cc06ec-b38c-4425-97ee-0292ab38d5d1 [person_->_])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Triple in statement: chair_perceivedin_16cc06ec-b38c-4425-97ee-0292ab38d5d1 [person_->_])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:57:48,274 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Entity Novelty: existing subject - new object \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entity Novelty: existing subject - new object \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:57:53,530 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. experience taste - 15 gaps as object: e.g. be-parent-of person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gaps: 26 gaps as subject: e.g. experience taste - 15 gaps as object: e.g. be-parent-of person\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:57:56,722 -  WARNING -      cltl.brain.basic_brain.TypeReasoner - Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Read timed out. (read timeout=3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Read timed out. (read timeout=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:57:57,188 -     INFO -      cltl.brain.basic_brain.TypeReasoner - Reasoned type of 16cc06ec-b38c-4425-97ee-0292ab38d5d1 to: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reasoned type of 16cc06ec-b38c-4425-97ee-0292ab38d5d1 to: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:57:57,230 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: chair_perceivedin_16cc06ec-b38c-4425-97ee-0292ab38d5d1 [person_->_])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Triple in statement: chair_perceivedin_16cc06ec-b38c-4425-97ee-0292ab38d5d1 [person_->_])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:57:57,271 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Statement Novelty: 1 times, e.g. front-camera on February,2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Statement Novelty: 1 times, e.g. front-camera on February,2022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:02,177 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. work-at institution - 15 gaps as object: e.g. write-by book\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gaps: 26 gaps as subject: e.g. work-at institution - 15 gaps as object: e.g. write-by book\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:05,391 -  WARNING -      cltl.brain.basic_brain.TypeReasoner - Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Read timed out. (read timeout=3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Read timed out. (read timeout=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:05,686 -     INFO -      cltl.brain.basic_brain.TypeReasoner - Reasoned type of 16cc06ec-b38c-4425-97ee-0292ab38d5d1 to: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reasoned type of 16cc06ec-b38c-4425-97ee-0292ab38d5d1 to: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:05,729 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: chair_perceivedin_16cc06ec-b38c-4425-97ee-0292ab38d5d1 [person_->_])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Triple in statement: chair_perceivedin_16cc06ec-b38c-4425-97ee-0292ab38d5d1 [person_->_])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:05,771 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Statement Novelty: 1 times, e.g. front-camera on February,2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Statement Novelty: 1 times, e.g. front-camera on February,2022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:10,782 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. favorite interest - 15 gaps as object: e.g. be-child-of agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gaps: 26 gaps as subject: e.g. favorite interest - 15 gaps as object: e.g. be-child-of agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:13,953 -  WARNING -      cltl.brain.basic_brain.TypeReasoner - Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Read timed out. (read timeout=3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Read timed out. (read timeout=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:14,598 -     INFO -      cltl.brain.basic_brain.TypeReasoner - Reasoned type of 16cc06ec-b38c-4425-97ee-0292ab38d5d1 to: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reasoned type of 16cc06ec-b38c-4425-97ee-0292ab38d5d1 to: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:14,629 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: laptop_perceivedin_16cc06ec-b38c-4425-97ee-0292ab38d5d1 [person_->_])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Triple in statement: laptop_perceivedin_16cc06ec-b38c-4425-97ee-0292ab38d5d1 [person_->_])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:20,830 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. be-parent-of person - 15 gaps as object: e.g. like agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gaps: 26 gaps as subject: e.g. be-parent-of person - 15 gaps as object: e.g. like agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:20,983 -  WARNING -      cltl.brain.basic_brain.TypeReasoner - Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Max retries exceeded with url: /sparql?format=json&query=SELECT+%3Fitem+%3FitemLabel+%3Fitemtype+%3FitemtypeLabel+%3FitemDescription%0AWHERE+%7B%0A++%3Fitem+rdfs%3Alabel%7Cskos%3AaltLabel+%3FitemLabel.%0A++FILTER%28%28LCASE%28%3FitemLabel%29+%3D+%2216cc06ec-b38c-4425-97ee-0292ab38d5d1%22%40en%29%29.%0A++OPTIONAL%7B%3Fitem+wdt%3AP31+%3Fitemtype+.+%7D%0A++OPTIONAL+%7B%3Fitemtype+rdfs%3Alabel+%3FitemtypeLabel+.+%7D%0A++FILTER%28LANG%28%3FitemtypeLabel%29+in+%28%22en%22%29%29+.%0A++OPTIONAL+%7B%3Fitem+schema%3Adescription+%3FitemDescription.%7D%0A++FILTER%28LANG%28%3FitemDescription%29+in+%28%22en%22%29%29+.%0A%7D+limit+1 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f842a2d09d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Max retries exceeded with url: /sparql?format=json&query=SELECT+%3Fitem+%3FitemLabel+%3Fitemtype+%3FitemtypeLabel+%3FitemDescription%0AWHERE+%7B%0A++%3Fitem+rdfs%3Alabel%7Cskos%3AaltLabel+%3FitemLabel.%0A++FILTER%28%28LCASE%28%3FitemLabel%29+%3D+%2216cc06ec-b38c-4425-97ee-0292ab38d5d1%22%40en%29%29.%0A++OPTIONAL%7B%3Fitem+wdt%3AP31+%3Fitemtype+.+%7D%0A++OPTIONAL+%7B%3Fitemtype+rdfs%3Alabel+%3FitemtypeLabel+.+%7D%0A++FILTER%28LANG%28%3FitemtypeLabel%29+in+%28%22en%22%29%29+.%0A++OPTIONAL+%7B%3Fitem+schema%3Adescription+%3FitemDescription.%7D%0A++FILTER%28LANG%28%3FitemDescription%29+in+%28%22en%22%29%29+.%0A%7D+limit+1 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f842a2d09d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:20,990 -  WARNING -      cltl.brain.basic_brain.TypeReasoner - Failed to query DBpedia: HTTPConnectionPool(host='dbpedia.org', port=80): Max retries exceeded with url: /sparql?format=json&query=PREFIX+dbo%3A+%3Chttp%3A%2F%2Fdbpedia.org%2Fontology%2F%3E%0APREFIX+rdfs%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2000%2F01%2Frdf-schema%23%3E%0APREFIX+rdf%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F1999%2F02%2F22-rdf-syntax-ns%23%3E%0A%0ASELECT+DISTINCT+%3Flabel_type+%3Fdescription+WHERE+%7B%0A++%23+Get+type%0A++%3Fthing+rdfs%3Alabel+%2216cc06ec-b38c-4425-97ee-0292ab38d5d1%22%40en%3B%0A++++rdf%3Atype+%3Ftype.%0A%0A++%23+Rank+types%0A++BIND%28IF%28REGEX%28STR%28%3Ftype%29%2C+STR%28dbo%3A%29%29%2C+%22DB+type%22%40en%2C+%22not+DB+type%22%40en%29+AS+%3Fdb_type%29%0A%0A++%23+Get+label+of+type%0A++OPTIONAL+%7B+%3Ftype+rdfs%3Alabel+%3Flt.+%7D%0A++BIND%28IF%28%21%28BOUND%28%3Flt%29%29%2C+%2216cc06ec-b38c-4425-97ee-0292ab38d5d1%22%40en%2C+%3Flt%29+AS+%3Flabel_type%29%0A++FILTER%28LANGMATCHES%28LANG%28%3Flabel_type%29%2C+%22EN%22%29%29%0A%0A++%23+Get+description%0A++OPTIONAL+%7B%0A++++%3Fthing+dbo%3Aabstract+%3Fdescription.%0A++++FILTER%28LANGMATCHES%28LANG%28%3Fdescription%29%2C+%22EN%22%29%29%0A++%7D%0A%0A%7DORDER+BY+%3Fdb_type%0ALIMIT+1 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8429c91b50>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query DBpedia: HTTPConnectionPool(host='dbpedia.org', port=80): Max retries exceeded with url: /sparql?format=json&query=PREFIX+dbo%3A+%3Chttp%3A%2F%2Fdbpedia.org%2Fontology%2F%3E%0APREFIX+rdfs%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2000%2F01%2Frdf-schema%23%3E%0APREFIX+rdf%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F1999%2F02%2F22-rdf-syntax-ns%23%3E%0A%0ASELECT+DISTINCT+%3Flabel_type+%3Fdescription+WHERE+%7B%0A++%23+Get+type%0A++%3Fthing+rdfs%3Alabel+%2216cc06ec-b38c-4425-97ee-0292ab38d5d1%22%40en%3B%0A++++rdf%3Atype+%3Ftype.%0A%0A++%23+Rank+types%0A++BIND%28IF%28REGEX%28STR%28%3Ftype%29%2C+STR%28dbo%3A%29%29%2C+%22DB+type%22%40en%2C+%22not+DB+type%22%40en%29+AS+%3Fdb_type%29%0A%0A++%23+Get+label+of+type%0A++OPTIONAL+%7B+%3Ftype+rdfs%3Alabel+%3Flt.+%7D%0A++BIND%28IF%28%21%28BOUND%28%3Flt%29%29%2C+%2216cc06ec-b38c-4425-97ee-0292ab38d5d1%22%40en%2C+%3Flt%29+AS+%3Flabel_type%29%0A++FILTER%28LANGMATCHES%28LANG%28%3Flabel_type%29%2C+%22EN%22%29%29%0A%0A++%23+Get+description%0A++OPTIONAL+%7B%0A++++%3Fthing+dbo%3Aabstract+%3Fdescription.%0A++++FILTER%28LANGMATCHES%28LANG%28%3Fdescription%29%2C+%22EN%22%29%29%0A++%7D%0A%0A%7DORDER+BY+%3Fdb_type%0ALIMIT+1 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8429c91b50>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:20,996 -  WARNING -      cltl.brain.basic_brain.TypeReasoner - Failed to query DBpedia: HTTPConnectionPool(host='dbpedia.org', port=80): Max retries exceeded with url: /sparql?format=json&query=PREFIX+dbo%3A+%3Chttp%3A%2F%2Fdbpedia.org%2Fontology%2F%3E%0APREFIX+rdfs%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2000%2F01%2Frdf-schema%23%3E%0APREFIX+rdf%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F1999%2F02%2F22-rdf-syntax-ns%23%3E%0A%0ASELECT+DISTINCT+%3Flabel_type+%3Fdescription+WHERE+%7B%0A++%23+Get+type%0A++%3Fthing+rdfs%3Alabel+%2216cc06ec-b38c-4425-97ee-0292ab38d5d1%22%40en%3B%0A++++rdf%3Atype+%3Ftype.%0A%0A++%23+Rank+types%0A++BIND%28IF%28REGEX%28STR%28%3Ftype%29%2C+STR%28dbo%3A%29%29%2C+%22DB+type%22%40en%2C+%22not+DB+type%22%40en%29+AS+%3Fdb_type%29%0A%0A++%23+Get+label+of+type%0A++OPTIONAL+%7B+%3Ftype+rdfs%3Alabel+%3Flt.+%7D%0A++BIND%28IF%28%21%28BOUND%28%3Flt%29%29%2C+%2216cc06ec-b38c-4425-97ee-0292ab38d5d1%22%40en%2C+%3Flt%29+AS+%3Flabel_type%29%0A++FILTER%28LANGMATCHES%28LANG%28%3Flabel_type%29%2C+%22EN%22%29%29%0A%0A++%23+Get+description%0A++OPTIONAL+%7B%0A++++%3Fthing+dbo%3Aabstract+%3Fdescription.%0A++++FILTER%28LANGMATCHES%28LANG%28%3Fdescription%29%2C+%22EN%22%29%29%0A++%7D%0A%0A%7DORDER+BY+%3Fdb_type%0ALIMIT+1 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8429c91410>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query DBpedia: HTTPConnectionPool(host='dbpedia.org', port=80): Max retries exceeded with url: /sparql?format=json&query=PREFIX+dbo%3A+%3Chttp%3A%2F%2Fdbpedia.org%2Fontology%2F%3E%0APREFIX+rdfs%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2000%2F01%2Frdf-schema%23%3E%0APREFIX+rdf%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F1999%2F02%2F22-rdf-syntax-ns%23%3E%0A%0ASELECT+DISTINCT+%3Flabel_type+%3Fdescription+WHERE+%7B%0A++%23+Get+type%0A++%3Fthing+rdfs%3Alabel+%2216cc06ec-b38c-4425-97ee-0292ab38d5d1%22%40en%3B%0A++++rdf%3Atype+%3Ftype.%0A%0A++%23+Rank+types%0A++BIND%28IF%28REGEX%28STR%28%3Ftype%29%2C+STR%28dbo%3A%29%29%2C+%22DB+type%22%40en%2C+%22not+DB+type%22%40en%29+AS+%3Fdb_type%29%0A%0A++%23+Get+label+of+type%0A++OPTIONAL+%7B+%3Ftype+rdfs%3Alabel+%3Flt.+%7D%0A++BIND%28IF%28%21%28BOUND%28%3Flt%29%29%2C+%2216cc06ec-b38c-4425-97ee-0292ab38d5d1%22%40en%2C+%3Flt%29+AS+%3Flabel_type%29%0A++FILTER%28LANGMATCHES%28LANG%28%3Flabel_type%29%2C+%22EN%22%29%29%0A%0A++%23+Get+description%0A++OPTIONAL+%7B%0A++++%3Fthing+dbo%3Aabstract+%3Fdescription.%0A++++FILTER%28LANGMATCHES%28LANG%28%3Fdescription%29%2C+%22EN%22%29%29%0A++%7D%0A%0A%7DORDER+BY+%3Fdb_type%0ALIMIT+1 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8429c91410>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:21,004 -  WARNING -      cltl.brain.basic_brain.TypeReasoner - Failed to query DBpedia: HTTPConnectionPool(host='dbpedia.org', port=80): Max retries exceeded with url: /sparql?format=json&query=PREFIX+dbo%3A+%3Chttp%3A%2F%2Fdbpedia.org%2Fontology%2F%3E%0APREFIX+rdfs%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2000%2F01%2Frdf-schema%23%3E%0APREFIX+rdf%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F1999%2F02%2F22-rdf-syntax-ns%23%3E%0A%0ASELECT+DISTINCT+%3Flabel_type+%3Fdescription+WHERE+%7B%0A++%23+Get+type%0A++%3Fthing+rdfs%3Alabel+%2216cc06ec-b38c-4425-97ee-0292ab38d5d1%22%40en%3B%0A++++rdf%3Atype+%3Ftype.%0A%0A++%23+Rank+types%0A++BIND%28IF%28REGEX%28STR%28%3Ftype%29%2C+STR%28dbo%3A%29%29%2C+%22DB+type%22%40en%2C+%22not+DB+type%22%40en%29+AS+%3Fdb_type%29%0A%0A++%23+Get+label+of+type%0A++OPTIONAL+%7B+%3Ftype+rdfs%3Alabel+%3Flt.+%7D%0A++BIND%28IF%28%21%28BOUND%28%3Flt%29%29%2C+%2216cc06ec-b38c-4425-97ee-0292ab38d5d1%22%40en%2C+%3Flt%29+AS+%3Flabel_type%29%0A++FILTER%28LANGMATCHES%28LANG%28%3Flabel_type%29%2C+%22EN%22%29%29%0A%0A++%23+Get+description%0A++OPTIONAL+%7B%0A++++%3Fthing+dbo%3Aabstract+%3Fdescription.%0A++++FILTER%28LANGMATCHES%28LANG%28%3Fdescription%29%2C+%22EN%22%29%29%0A++%7D%0A%0A%7DORDER+BY+%3Fdb_type%0ALIMIT+1 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8429c91850>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query DBpedia: HTTPConnectionPool(host='dbpedia.org', port=80): Max retries exceeded with url: /sparql?format=json&query=PREFIX+dbo%3A+%3Chttp%3A%2F%2Fdbpedia.org%2Fontology%2F%3E%0APREFIX+rdfs%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2000%2F01%2Frdf-schema%23%3E%0APREFIX+rdf%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F1999%2F02%2F22-rdf-syntax-ns%23%3E%0A%0ASELECT+DISTINCT+%3Flabel_type+%3Fdescription+WHERE+%7B%0A++%23+Get+type%0A++%3Fthing+rdfs%3Alabel+%2216cc06ec-b38c-4425-97ee-0292ab38d5d1%22%40en%3B%0A++++rdf%3Atype+%3Ftype.%0A%0A++%23+Rank+types%0A++BIND%28IF%28REGEX%28STR%28%3Ftype%29%2C+STR%28dbo%3A%29%29%2C+%22DB+type%22%40en%2C+%22not+DB+type%22%40en%29+AS+%3Fdb_type%29%0A%0A++%23+Get+label+of+type%0A++OPTIONAL+%7B+%3Ftype+rdfs%3Alabel+%3Flt.+%7D%0A++BIND%28IF%28%21%28BOUND%28%3Flt%29%29%2C+%2216cc06ec-b38c-4425-97ee-0292ab38d5d1%22%40en%2C+%3Flt%29+AS+%3Flabel_type%29%0A++FILTER%28LANGMATCHES%28LANG%28%3Flabel_type%29%2C+%22EN%22%29%29%0A%0A++%23+Get+description%0A++OPTIONAL+%7B%0A++++%3Fthing+dbo%3Aabstract+%3Fdescription.%0A++++FILTER%28LANGMATCHES%28LANG%28%3Fdescription%29%2C+%22EN%22%29%29%0A++%7D%0A%0A%7DORDER+BY+%3Fdb_type%0ALIMIT+1 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8429c91850>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:21,010 -  WARNING -      cltl.brain.basic_brain.TypeReasoner - Failed to query DBpedia: HTTPConnectionPool(host='dbpedia.org', port=80): Max retries exceeded with url: /sparql?format=json&query=PREFIX+dbo%3A+%3Chttp%3A%2F%2Fdbpedia.org%2Fontology%2F%3E%0APREFIX+rdfs%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2000%2F01%2Frdf-schema%23%3E%0APREFIX+rdf%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F1999%2F02%2F22-rdf-syntax-ns%23%3E%0A%0ASELECT+DISTINCT+%3Flabel_type+%3Fdescription+WHERE+%7B%0A++%23+Get+type%0A++%3Fthing+rdfs%3Alabel+%2216Cc06Ec-B38C-4425-97Ee-0292Ab38D5D1%22%40en%3B%0A++++rdf%3Atype+%3Ftype.%0A%0A++%23+Rank+types%0A++BIND%28IF%28REGEX%28STR%28%3Ftype%29%2C+STR%28dbo%3A%29%29%2C+%22DB+type%22%40en%2C+%22not+DB+type%22%40en%29+AS+%3Fdb_type%29%0A%0A++%23+Get+label+of+type%0A++OPTIONAL+%7B+%3Ftype+rdfs%3Alabel+%3Flt.+%7D%0A++BIND%28IF%28%21%28BOUND%28%3Flt%29%29%2C+%2216Cc06Ec-B38C-4425-97Ee-0292Ab38D5D1%22%40en%2C+%3Flt%29+AS+%3Flabel_type%29%0A++FILTER%28LANGMATCHES%28LANG%28%3Flabel_type%29%2C+%22EN%22%29%29%0A%0A++%23+Get+description%0A++OPTIONAL+%7B%0A++++%3Fthing+dbo%3Aabstract+%3Fdescription.%0A++++FILTER%28LANGMATCHES%28LANG%28%3Fdescription%29%2C+%22EN%22%29%29%0A++%7D%0A%0A%7DORDER+BY+%3Fdb_type%0ALIMIT+1 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8429c912d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query DBpedia: HTTPConnectionPool(host='dbpedia.org', port=80): Max retries exceeded with url: /sparql?format=json&query=PREFIX+dbo%3A+%3Chttp%3A%2F%2Fdbpedia.org%2Fontology%2F%3E%0APREFIX+rdfs%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F2000%2F01%2Frdf-schema%23%3E%0APREFIX+rdf%3A+%3Chttp%3A%2F%2Fwww.w3.org%2F1999%2F02%2F22-rdf-syntax-ns%23%3E%0A%0ASELECT+DISTINCT+%3Flabel_type+%3Fdescription+WHERE+%7B%0A++%23+Get+type%0A++%3Fthing+rdfs%3Alabel+%2216Cc06Ec-B38C-4425-97Ee-0292Ab38D5D1%22%40en%3B%0A++++rdf%3Atype+%3Ftype.%0A%0A++%23+Rank+types%0A++BIND%28IF%28REGEX%28STR%28%3Ftype%29%2C+STR%28dbo%3A%29%29%2C+%22DB+type%22%40en%2C+%22not+DB+type%22%40en%29+AS+%3Fdb_type%29%0A%0A++%23+Get+label+of+type%0A++OPTIONAL+%7B+%3Ftype+rdfs%3Alabel+%3Flt.+%7D%0A++BIND%28IF%28%21%28BOUND%28%3Flt%29%29%2C+%2216Cc06Ec-B38C-4425-97Ee-0292Ab38D5D1%22%40en%2C+%3Flt%29+AS+%3Flabel_type%29%0A++FILTER%28LANGMATCHES%28LANG%28%3Flabel_type%29%2C+%22EN%22%29%29%0A%0A++%23+Get+description%0A++OPTIONAL+%7B%0A++++%3Fthing+dbo%3Aabstract+%3Fdescription.%0A++++FILTER%28LANGMATCHES%28LANG%28%3Fdescription%29%2C+%22EN%22%29%29%0A++%7D%0A%0A%7DORDER+BY+%3Fdb_type%0ALIMIT+1 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8429c912d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:21,011 -     INFO -      cltl.brain.basic_brain.TypeReasoner - Reasoned type of 16cc06ec-b38c-4425-97ee-0292ab38d5d1 to: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reasoned type of 16cc06ec-b38c-4425-97ee-0292ab38d5d1 to: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:21,032 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: person_perceivedin_16cc06ec-b38c-4425-97ee-0292ab38d5d1 [person_->_])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Triple in statement: person_perceivedin_16cc06ec-b38c-4425-97ee-0292ab38d5d1 [person_->_])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:27,181 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. like agent - 15 gaps as object: e.g. cook-by food\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gaps: 26 gaps as subject: e.g. like agent - 15 gaps as object: e.g. cook-by food\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:30,387 -  WARNING -      cltl.brain.basic_brain.TypeReasoner - Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Read timed out. (read timeout=3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Read timed out. (read timeout=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:31,136 -     INFO -      cltl.brain.basic_brain.TypeReasoner - Reasoned type of 16cc06ec-b38c-4425-97ee-0292ab38d5d1 to: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reasoned type of 16cc06ec-b38c-4425-97ee-0292ab38d5d1 to: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:31,227 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: book_perceivedin_16cc06ec-b38c-4425-97ee-0292ab38d5d1 [person_->_])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Triple in statement: book_perceivedin_16cc06ec-b38c-4425-97ee-0292ab38d5d1 [person_->_])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:37,178 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. like agent - 15 gaps as object: e.g. like-by agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gaps: 26 gaps as subject: e.g. like agent - 15 gaps as object: e.g. like-by agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:40,348 -  WARNING -      cltl.brain.basic_brain.TypeReasoner - Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Read timed out. (read timeout=3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Read timed out. (read timeout=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:41,941 -     INFO -      cltl.brain.basic_brain.TypeReasoner - Reasoned type of 16cc06ec-b38c-4425-97ee-0292ab38d5d1 to: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reasoned type of 16cc06ec-b38c-4425-97ee-0292ab38d5d1 to: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:41,977 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: cup_perceivedin_16cc06ec-b38c-4425-97ee-0292ab38d5d1 [person_->_])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Triple in statement: cup_perceivedin_16cc06ec-b38c-4425-97ee-0292ab38d5d1 [person_->_])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:48,215 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. like agent - 15 gaps as object: e.g. be-parent-of person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gaps: 26 gaps as subject: e.g. like agent - 15 gaps as object: e.g. be-parent-of person\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:51,394 -  WARNING -      cltl.brain.basic_brain.TypeReasoner - Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Read timed out. (read timeout=3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Read timed out. (read timeout=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:51,738 -     INFO -      cltl.brain.basic_brain.TypeReasoner - Reasoned type of 16cc06ec-b38c-4425-97ee-0292ab38d5d1 to: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reasoned type of 16cc06ec-b38c-4425-97ee-0292ab38d5d1 to: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:51,776 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: chair_perceivedin_16cc06ec-b38c-4425-97ee-0292ab38d5d1 [person_->_])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Triple in statement: chair_perceivedin_16cc06ec-b38c-4425-97ee-0292ab38d5d1 [person_->_])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:51,815 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Statement Novelty: 1 times, e.g. front-camera on February,2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Statement Novelty: 1 times, e.g. front-camera on February,2022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:56,082 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. dislike interest - 15 gaps as object: e.g. be-child-of agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gaps: 26 gaps as subject: e.g. dislike interest - 15 gaps as object: e.g. be-child-of agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:59,148 -  WARNING -      cltl.brain.basic_brain.TypeReasoner - Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Read timed out. (read timeout=3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Read timed out. (read timeout=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:59,411 -     INFO -      cltl.brain.basic_brain.TypeReasoner - Reasoned type of 16cc06ec-b38c-4425-97ee-0292ab38d5d1 to: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reasoned type of 16cc06ec-b38c-4425-97ee-0292ab38d5d1 to: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:58:59,429 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: refrigerator_perceivedin_16cc06ec-b38c-4425-97ee-0292ab38d5d1 [person_->_])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Triple in statement: refrigerator_perceivedin_16cc06ec-b38c-4425-97ee-0292ab38d5d1 [person_->_])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-02-01 13:59:02,165 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. be-friends-with person - 15 gaps as object: e.g. cook-by food\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gaps: 26 gaps as subject: e.g. be-friends-with person - 15 gaps as object: e.g. cook-by food\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: \n",
      "By the way while talking, I have been seeing a chair a chair a chair a laptop a person a book a cup a chair and a refrigerator\n",
      "\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='192.168.1.176', port=8000): Max retries exceeded with url: /text (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f842a2d7e50>: Failed to establish a new connection: [Errno 51] Network is unreachable'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             )\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 51] Network is unreachable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             )\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_user_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             )\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7f842a2d7e50>: Failed to establish a new connection: [Errno 51] Network is unreachable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    755\u001b[0m             retries = retries.increment(\n\u001b[0;32m--> 756\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m             )\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='192.168.1.176', port=8000): Max retries exceeded with url: /text (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f842a2d7e50>: Failed to establish a new connection: [Errno 51] Network is unreachable'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6w/bw7dqbl9727c48pcjjh32r140000gn/T/ipykernel_99176/1633739139.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAGENT\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\": \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mspeak_and_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mtextSignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_text_signal_with_speaker_annotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenario_ctrl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAGENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mscenario_ctrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextSignal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/6w/bw7dqbl9727c48pcjjh32r140000gn/T/ipykernel_99176/2422420204.py\u001b[0m in \u001b[0;36mspeak_and_act\u001b[0;34m(text, animation)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m          \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{text}\"\u001b[0m   \u001b[0;31m#### cannot pass in strings with quotes!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http://192.168.1.176:8000/text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtts_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \"\"\"\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='192.168.1.176', port=8000): Max retries exceeded with url: /text (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f842a2d7e50>: Failed to establish a new connection: [Errno 51] Network is unreachable'))"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "import random\n",
    "print_details=False\n",
    "#### Initial prompt by the system from which we create a TextSignal and store it\n",
    "initial_prompt = f\"{choice(TALK_TO_ME)}\"\n",
    "print(AGENT + \": \" + initial_prompt)\n",
    "speak_and_act(initial_prompt)\n",
    "textSignal = d_util.create_text_signal_with_speaker_annotation(scenario_ctrl, initial_prompt, AGENT)\n",
    "scenario_ctrl.append_signal(textSignal)\n",
    "\n",
    "utterance = \"\"\n",
    "#utterance = input('\\n')\n",
    "utterance = detect_and_transcribe()\n",
    "print(HUMAN_NAME + \": \" + utterance+'\\n')\n",
    "\n",
    "#### Get input and loop\n",
    "while not (utterance.lower() == 'stop' or utterance.lower() == 'bye'):\n",
    "    ###### Getting the next input signals\n",
    "    textSignal = d_util.create_text_signal_with_speaker_annotation(scenario_ctrl, utterance, HUMAN_ID)\n",
    "    scenario_ctrl.append_signal(textSignal)\n",
    "\n",
    "    capsule, reply, response_json = talk.process_text_and_reply(scenario_ctrl,\n",
    "                           place_id,\n",
    "                           location,\n",
    "                           HUMAN_ID,\n",
    "                           textSignal,\n",
    "                           chat,\n",
    "                           replier,\n",
    "                           my_brain,\n",
    "                           print_details)\n",
    "\n",
    "\n",
    "    print(AGENT + \": \" + reply)\n",
    "    speak_and_act(reply)\n",
    "    textSignal = d_util.create_text_signal_with_speaker_annotation(scenario_ctrl, reply, AGENT)\n",
    "    scenario_ctrl.append_signal(textSignal)\n",
    "    what_do_i_see = respond_to_an_image(imagefolder, \n",
    "                                        scenario_ctrl, \n",
    "                                        place_id, \n",
    "                                        location, \n",
    "                                        HUMAN_ID, \n",
    "                                        my_brain, \n",
    "                                        replier,\n",
    "                                       False)\n",
    "\n",
    "    reply = \"\\nBy the way while talking, I have been seeing\"\n",
    "    if len(what_do_i_see)>1:\n",
    "        for index, object in enumerate(what_do_i_see):\n",
    "            if index==len(what_do_i_see)-1:\n",
    "                reply += \" and\"\n",
    "            reply += \" a \"+object\n",
    "    elif len(what_do_i_see)==1:\n",
    "        reply += \" a \" + what_do_i_see[0]\n",
    "    else:\n",
    "        reply = \"\\nI cannot see! Something wrong with my camera.\"\n",
    "\n",
    "       \n",
    "    print(AGENT + \": \" + reply+\"\\n\")\n",
    "    \n",
    "    \n",
    "    animation = f\"{choice(gesttures.pepper_gestures)}\"\n",
    "    \n",
    "    speak_and_act(reply, animation)\n",
    "    textSignal = d_util.create_text_signal_with_speaker_annotation(scenario_ctrl, reply, AGENT)\n",
    "    scenario_ctrl.append_signal(textSignal)\n",
    "\n",
    "    # Get the next input signal from the user\n",
    "    #utterance = input(\"\\n\")\n",
    "    utterance = detect_and_transcribe()\n",
    "    print(HUMAN_NAME + \": \" + utterance+\"\\n\")\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    ### We now have a new input check if the user wants to continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the end time of the scenario, save it and stop the containers\n",
    "\n",
    "After we stopped the interaction, we set the end time and save the scenario as EMISSOR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_ctrl.scenario.ruler.end = int(time.time() * 1e3)\n",
    "scenarioStorage.save_scenario(scenario_ctrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stopping the docker containers\n",
    "### This is only needed of you started them in this notebook\n",
    "#f_util.kill_container(container_fdr)\n",
    "#f_util.kill_container(container_ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Stop the camera when we are done\n",
    "#camera.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
