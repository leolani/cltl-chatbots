{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uses interaction to push triples to the brain and query it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook assumes you already understand the following notebooks:\n",
    "\n",
    "* lets-chat.ipynb\n",
    "* roboGrasp-api.ipynb\n",
    "\n",
    "In this notebook, we will combine the interaction modeled through EMISSOR with the interaction throught *capsules* with the BRAIN. As auxiliary modules, we will use the *cltl-knowledgeextraction* and *cltl-language-generation*. The *cltl-knowledgeextraction* will extract triples from the utterances either for posting or for querying. In the former case, it also extracts the source perspective from the text. The triples and source perspectives are represented in enriched capsules. We will also use a replier that is include in the *cltl-languagegeneration* package. This replier transfers the response from the BRAIN into natural language expressions and possibly gestures. \n",
    "\n",
    "In order to connect to the EMISSOR scenario, we need to align the meta properties of the scenario with the meta data in the capsules. However,  the *cltl-knowledgeextraction* uses a similar data object to keep track of the conversation history. This is a Chat object that needs to be created. Through this Chat object, we keep track of what was said before and deal with coreference to earlier utterances.\n",
    "\n",
    "Combining EMISSOR and the BRAIN, we can model the interaction in a infite while loop where we go through the following steps:\n",
    "\n",
    "* We create an EMISSOR scenario at the start of the interaction and a corresponding Chat object to keep track of the dialogue history\n",
    "* while the user does not stop:\n",
    "    * create TextSignals for each utterance from the user and store these in an EMISSOR scenario\n",
    "    * add the utterance also to the Chat instance\n",
    "    * process the latest utterance in the Chat object using the *cltl-knowledgeextraction* to get triples and perspectives\n",
    "    * create a capsule from the triples, perspectives and the text signal meta data\n",
    "    * post the triple to the BRAIN\n",
    "    * get the answer or throughts as a response from the BRAIN\n",
    "    * verbalise the answer or thoughts\n",
    "    * create a new TextSignal for the system response and add it to the EMISSOR scenario\n",
    "* When the user stops, we save the scenario in the EMISSOR format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running, start GraphDB and make sure that there is a sandbox repository.\n",
    "GraphDB can be downloaded from:\n",
    "\n",
    "https://graphdb.ontotext.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from random import getrandbits, choice\n",
    "import pathlib\n",
    "import pprint\n",
    "\n",
    "# general imports for EMISSOR and the BRAIN\n",
    "import emissor as em\n",
    "import requests\n",
    "from cltl import brain\n",
    "from cltl.brain.long_term_memory import LongTermMemory\n",
    "from cltl.brain.utils.helper_functions import brain_response_to_json\n",
    "from cltl.combot.backend.api.discrete import UtteranceType\n",
    "from cltl.reply_generation.data.sentences import GREETING, ASK_NAME, ELOQUENCE, TALK_TO_ME\n",
    "from cltl.reply_generation.lenka_replier import LenkaReplier\n",
    "from cltl.triple_extraction.api import Chat, UtteranceHypothesis\n",
    "from emissor.persistence import ScenarioStorage\n",
    "from emissor.representation.annotation import AnnotationType, Token, NER\n",
    "from emissor.representation.container import Index\n",
    "from emissor.representation.scenario import Modality, ImageSignal, TextSignal, Mention, Annotation, Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the chatbot utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "src_path = os.path.abspath(os.path.join('..'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "#### The next utils are needed for the interaction and creating triples and capsules\n",
    "import chatbots.util.driver_util as d_util\n",
    "import chatbots.util.capsule_util as c_util\n",
    "import chatbots.intentions.talk as talk\n",
    "import chatbots.intentions.get_to_know_you as friend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard initialisation of a scenario\n",
    "\n",
    "We initialise a scenario in the standard way by creating a unique folder and setting the AGENT and HUMAN_NAME and HUMAN_ID variables. Throughout this scenario, the HUMAN_NAME and HUMAN_ID will be used as the source for the utterances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories for 2021-12-09-10:29:02 created in /Users/piek/PycharmProjects/cltl-chatbots/data\n"
     ]
    }
   ],
   "source": [
    "from random import getrandbits\n",
    "import requests\n",
    "##### Setting the location\n",
    "place_id = getrandbits(8)\n",
    "location = None\n",
    "try:\n",
    "    location = requests.get(\"https://ipinfo.io\").json()\n",
    "except:\n",
    "    print(\"failed to get the IP location\")\n",
    "    \n",
    "##### Setting the agents\n",
    "AGENT = \"Leolani2\"\n",
    "HUMAN_NAME = \"Stranger\"\n",
    "HUMAN_ID = \"stranger\"\n",
    "\n",
    "### The name of your scenario\n",
    "scenario_id = datetime.today().strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "\n",
    "### Specify the path to an existing data folder where your scenario is created and saved as a subfolder\n",
    "# Find the repository root dir\n",
    "parent, dir_name = (d_util.__file__, \"_\")\n",
    "while dir_name and dir_name != \"src\":\n",
    "    parent, dir_name = os.path.split(parent)\n",
    "root_dir = parent\n",
    "scenario_path = os.path.abspath(os.path.join(root_dir, 'data'))\n",
    "\n",
    "if not os.path.exists(scenario_path) :\n",
    "    os.mkdir(scenario_path)\n",
    "    print(\"Created a data folder for storing the scenarios\", scenario_path)\n",
    "\n",
    "### Define the folders where the images and rdf triples are saved\n",
    "imagefolder = scenario_path + \"/\" + scenario_id + \"/\" + \"image\"\n",
    "rdffolder = scenario_path + \"/\" + scenario_id + \"/\" + \"rdf\"\n",
    "\n",
    "### Create the scenario folder, the json files and a scenarioStorage and scenario in memory\n",
    "scenarioStorage = d_util.create_scenario(scenario_path, scenario_id)\n",
    "scenario_ctrl = scenarioStorage.create_scenario(scenario_id, int(time.time() * 1e3), None, AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying the BRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify the BRAIN in GraphDB and use the scenario path just defined for storing the RDF triple produced in EMISSOR.\n",
    "\n",
    "If you set *clear_all* to *True*, the sandbox triple store is emptied (memory erased) and the basic ontological models are reloaded. Setting it to *False* means you add things to the current memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-09 10:29:21,061 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Booted\n",
      "2021-12-09 10:29:26,321 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Uploading ontology to brain\n",
      "2021-12-09 10:29:29,189 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Booted\n",
      "2021-12-09 10:29:29,192 -     INFO -  cltl.brain.basic_brain.LocationReasoner - Booted\n",
      "2021-12-09 10:29:29,194 -     INFO -      cltl.brain.basic_brain.TypeReasoner - Booted\n",
      "2021-12-09 10:29:29,196 -     INFO -   cltl.brain.basic_brain.TrustCalculator - Booted\n",
      "2021-12-09 10:29:29,634 -     INFO -   cltl.brain.basic_brain.TrustCalculator - Computed trust for all known agents\n"
     ]
    }
   ],
   "source": [
    "log_path = pathlib.Path(rdffolder)\n",
    "my_brain = brain.LongTermMemory(address=\"http://localhost:7200/repositories/sandbox\",\n",
    "                                log_dir=log_path,\n",
    "                                clear_all=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an instance of a replier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-09 10:29:31,504 -     INFO -   cltl.reply_generation.api.LenkaReplier - Booted\n"
     ]
    }
   ],
   "source": [
    "replier = LenkaReplier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish the speaker identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: Hello, I am Leolani2\n",
      "Leolani2: Good to see you! I've told you my name, but what about yours? Stranger?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Piek\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek\n",
      "Leolani2: So your name is Piek?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Piek\n",
      "Id: Piek\n",
      "2021-12-09 10:29:51,523 -  WARNING -      cltl.brain.basic_brain.TypeReasoner - Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Read timed out. (read timeout=3)\n",
      "2021-12-09 10:29:52,258 -     INFO -      cltl.brain.basic_brain.TypeReasoner - Reasoned type of Piek to: None\n",
      "2021-12-09 10:29:52,298 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: leolani2_know_piek [person_->_])\n",
      "2021-12-09 10:29:52,384 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Entity Novelty: new subject - new object \n",
      "2021-12-09 10:29:55,537 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Negation Conflicts: piek on December,2021 about UNDERSPECIFIED\n",
      "2021-12-09 10:29:55,591 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. be-friends-with person - 15 gaps as object: e.g. write-by book\n",
      "2021-12-09 10:29:55,641 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 25 gaps as subject: e.g. favorite interest - 14 gaps as object: e.g. cook-by food\n"
     ]
    }
   ],
   "source": [
    "#### Small sequence to learn name of speaker\n",
    "initial_prompt = \"Hello, I am \"+AGENT\n",
    "print(AGENT + \": \" + initial_prompt)\n",
    "\n",
    "\n",
    "initial_prompt = f\"{choice(GREETING)} {choice(ASK_NAME)} {HUMAN_NAME}?\"\n",
    "print(AGENT + \": \" + initial_prompt)\n",
    "textSignal = d_util.create_text_signal_with_speaker_annotation(scenario_ctrl, initial_prompt, AGENT)\n",
    "scenario_ctrl.append_signal(textSignal)\n",
    "\n",
    "#### Get name from person \n",
    "HUMAN_NAME, HUMAN_ID = friend.get_a_name_and_id(scenario_ctrl, AGENT)\n",
    "HUMAN_ID = HUMAN_NAME  ### Hack because we cannot force the namespace through capsules, name and identity are the same till this is fixed\n",
    "\n",
    "print(\"Name:\", HUMAN_NAME)\n",
    "print(\"Id:\", HUMAN_ID)\n",
    "                \n",
    "capsule = c_util.scenario_utterance_to_capsule(scenario_ctrl,place_id,location, textSignal,HUMAN_ID,AGENT,\"know\", HUMAN_ID)\n",
    "\n",
    "name_thoughts = my_brain.update(capsule, reason_types=True, create_label=True)\n",
    "\n",
    "#pprint.pprint(capsule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise a chat with the HUMAN_ID to keep track of the dialogue history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-09 10:30:07,659 -     INFO - cltl.triple_extraction.api.Chat (Piek)              000 - << Start of Chat with Piek >>\n"
     ]
    }
   ],
   "source": [
    "chat = Chat(HUMAN_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: Tell me anything, I love learning things\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " I am from Weesp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek: I am from Weesp\n",
      "2021-12-09 10:30:20,010 -     INFO -               cltl.triple_extraction.api - Started POS tagger\n",
      "2021-12-09 10:30:20,012 -     INFO -               cltl.triple_extraction.api - Started NER tagger\n",
      "2021-12-09 10:30:20,018 -     INFO -               cltl.triple_extraction.api - Loaded grammar\n",
      "2021-12-09 10:30:21,527 -     INFO - cltl.triple_extraction.api.Chat (Piek)              001 -       Piek: \"I am from Weesp\"\n",
      "initial triple: {'subject': 'I', 'predicate': 'am', 'object': 'from-Weesp'}\n",
      "2021-12-09 10:30:22,848 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: piek_be-from_weesp [agent_->_person])\n",
      "2021-12-09 10:30:25,437 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Negation Conflicts: piek on December,2021 about POSITIVE\n",
      "2021-12-09 10:30:25,538 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. born-in location - 15 gaps as object: e.g. like-by interest\n",
      "2021-12-09 10:30:25,592 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. be-member-of institution - 20 gaps as object: e.g. cook-by food\n",
      "Leolani2: Let me ask you something. Has piek be member of institution?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " I work at the VU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek: I work at the VU\n",
      "2021-12-09 10:30:36,876 -     INFO - cltl.triple_extraction.api.Chat (Piek)              002 -       Piek: \"I work at the VU\"\n",
      "initial triple: {'subject': 'I', 'predicate': 'work', 'object': 'at-the-VU'}\n",
      "2021-12-09 10:30:37,633 -     INFO -      cltl.brain.basic_brain.TypeReasoner - Reasoned type of VU to: country\n",
      "2021-12-09 10:30:37,694 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: piek_work-at_the-vu [agent_->_country])\n",
      "2021-12-09 10:30:37,790 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Entity Novelty: existing subject - new object \n",
      "2021-12-09 10:30:40,191 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Negation Conflicts: piek on December,2021 about POSITIVE\n",
      "2021-12-09 10:30:40,291 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. like-by agent - 15 gaps as object: e.g. cook-by food\n",
      "2021-12-09 10:30:40,343 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 0 gaps as subject: e.g. '' - 6 gaps as object: e.g. born-in person\n",
      "Leolani2: Interesting! I did not know anything that piek work at\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " I like cats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek: I like cats\n",
      "2021-12-09 10:30:45,279 -     INFO - cltl.triple_extraction.api.Chat (Piek)              003 -       Piek: \"I like cats\"\n",
      "initial triple: {'subject': 'I', 'predicate': 'like', 'object': 'cats'}\n",
      "2021-12-09 10:30:45,391 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: piek_like_cats [agent_->_animal])\n",
      "2021-12-09 10:30:45,539 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Entity Novelty: existing subject - new object \n",
      "2021-12-09 10:30:48,094 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Negation Conflicts: piek on December,2021 about POSITIVE\n",
      "2021-12-09 10:30:48,144 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. perceive sensor - 15 gaps as object: e.g. know agent\n",
      "2021-12-09 10:30:48,191 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 0 gaps as subject: e.g. '' - 2 gaps as object: e.g. own person\n",
      "Leolani2: If you don't mind me asking. Has piek like by agent?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " I like dogs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek: I like dogs\n",
      "2021-12-09 10:30:54,477 -     INFO - cltl.triple_extraction.api.Chat (Piek)              004 -       Piek: \"I like dogs\"\n",
      "initial triple: {'subject': 'I', 'predicate': 'like', 'object': 'dogs'}\n",
      "2021-12-09 10:30:54,547 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: piek_like_dogs [agent_->_animal])\n",
      "2021-12-09 10:30:54,635 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Entity Novelty: existing subject - new object \n",
      "2021-12-09 10:30:54,687 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Overlaps: 1 subject overlaps: e.g. piek on December,2021 about cats - 0 object overlaps: e.g. ''\n",
      "2021-12-09 10:30:57,396 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Negation Conflicts: piek on December,2021 about POSITIVE\n",
      "2021-12-09 10:30:57,447 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. play sport - 15 gaps as object: e.g. be-family-of person\n",
      "2021-12-09 10:30:57,495 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 0 gaps as subject: e.g. '' - 2 gaps as object: e.g. own person\n",
      "Leolani2: I am curious. Has piek live in location?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Where am I from?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek: Where am I from?\n",
      "2021-12-09 10:31:06,200 -     INFO - cltl.triple_extraction.api.Chat (Piek)              005 -       Piek: \"Where am I from?\"\n",
      "2021-12-09 10:31:06,204 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in question: piek_from_? [agent_->_])\n",
      "Leolani2: I wouldn't know!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Where is Piek from?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek: Where is Piek from?\n",
      "2021-12-09 10:31:13,840 -     INFO - cltl.triple_extraction.api.Chat (Piek)              006 -       Piek: \"Where is Piek from?\"\n",
      "2021-12-09 10:31:13,843 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in question: piek-from_be_? [agent_->_])\n",
      "Leolani2: I wouldn't know!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " WHat do I like\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek: WHat do I like\n",
      "2021-12-09 10:31:23,763 -     INFO - cltl.triple_extraction.api.Chat (Piek)              007 -       Piek: \"WHat do I like\"\n",
      "initial triple: {'subject': 'WHat', 'predicate': 'do', 'object': 'I-like'}\n",
      "2021-12-09 10:31:26,889 -  WARNING -      cltl.brain.basic_brain.TypeReasoner - Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Read timed out. (read timeout=3)\n",
      "2021-12-09 10:31:27,058 -     INFO -      cltl.brain.basic_brain.TypeReasoner - Reasoned type of what to: what\n",
      "2021-12-09 10:31:27,099 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: what_do_i-like [_->_person or what])\n",
      "2021-12-09 10:31:27,192 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Entity Novelty: new subject - new object \n",
      "2021-12-09 10:31:29,785 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Negation Conflicts: piek on December,2021 about POSITIVE\n",
      "2021-12-09 10:31:29,892 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. experience taste - 15 gaps as object: e.g. be-family-of person\n",
      "Leolani2: I would like to know. What kinds of things can do a i like like what\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " What do I like\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek: What do I like\n",
      "2021-12-09 10:31:38,863 -     INFO - cltl.triple_extraction.api.Chat (Piek)              008 -       Piek: \"What do I like\"\n",
      "2021-12-09 10:31:38,867 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in question: piek_like_? [agent_->_])\n",
      "Leolani2: you told me you like cats and that you like dogs\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek: stop\n",
      "2021-12-09 10:31:46,329 -     INFO - cltl.triple_extraction.api.Chat (Piek)              009 -       Piek: \"stop\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't parse input\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: Why?\n"
     ]
    }
   ],
   "source": [
    "print_details=False\n",
    "\n",
    "\n",
    "#### Initial prompt by the system from which we create a TextSignal and store it\n",
    "initial_prompt = f\"{choice(TALK_TO_ME)}\"\n",
    "print(AGENT + \": \" + initial_prompt)\n",
    "textSignal = d_util.create_text_signal_with_speaker_annotation(scenario_ctrl, initial_prompt, AGENT)\n",
    "scenario_ctrl.append_signal(textSignal)\n",
    "\n",
    "utterance = \"\"\n",
    "#### Get input and loop\n",
    "while not (utterance.lower() == 'stop' or utterance.lower() == 'bye'):\n",
    "    ###### Getting the next input signals\n",
    "    utterance = input('\\n')\n",
    "    print(HUMAN_NAME + \": \" + utterance)\n",
    "    textSignal = d_util.create_text_signal_with_speaker_annotation(scenario_ctrl, utterance, HUMAN_ID)\n",
    "    scenario_ctrl.append_signal(textSignal)\n",
    "\n",
    "    #### Process input and generate reply\n",
    "    \n",
    "    capsule, reply = talk.process_text_and_reply(scenario_ctrl,\n",
    "                           place_id,\n",
    "                           location,\n",
    "                           HUMAN_ID,\n",
    "                           textSignal,\n",
    "                           chat,\n",
    "                           replier,\n",
    "                           my_brain,\n",
    "                           print_details)\n",
    "\n",
    "    print(AGENT + \": \" + reply)\n",
    "    textSignal = d_util.create_text_signal_with_speaker_annotation(scenario_ctrl, reply, AGENT)\n",
    "    scenario_ctrl.append_signal(textSignal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switch speaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset the identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMAN_NAME = \"Stranger\"\n",
    "HUMAN_ID = \"stranger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: Hello, I am Leolani2\n",
      "Leolani2: Nice to see you! I would like to know your name! Piek?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Fred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fred\n",
      "Leolani2: So your name is Fred?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Fred\n",
      "Id: Fred\n",
      "2021-12-09 10:33:02,973 -  WARNING -      cltl.brain.basic_brain.TypeReasoner - Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Read timed out. (read timeout=3)\n",
      "2021-12-09 10:33:03,639 -     INFO -      cltl.brain.basic_brain.TypeReasoner - Reasoned type of Fred to: None\n",
      "2021-12-09 10:33:03,741 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: leolani2_know_fred [person_->_])\n",
      "2021-12-09 10:33:03,835 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Entity Novelty: existing subject - new object \n",
      "2021-12-09 10:33:03,887 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Overlaps: 1 subject overlaps: e.g. piek on December,2021 about piek - 0 object overlaps: e.g. ''\n",
      "2021-12-09 10:33:06,687 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Negation Conflicts: fred on December,2021 about UNDERSPECIFIED\n",
      "2021-12-09 10:33:06,791 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. be-ancestor-of person - 15 gaps as object: e.g. be-parent-of person\n",
      "2021-12-09 10:33:06,887 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 25 gaps as subject: e.g. be-friends-with person - 14 gaps as object: e.g. cook-by food\n",
      "2021-12-09 10:33:06,938 -     INFO - cltl.triple_extraction.api.Chat (Fred)              000 - << Start of Chat with Fred >>\n"
     ]
    }
   ],
   "source": [
    "#### Small sequence to learn name of speaker\n",
    "initial_prompt = \"Hello, I am \"+AGENT\n",
    "print(AGENT + \": \" + initial_prompt)\n",
    "\n",
    "\n",
    "initial_prompt = f\"{choice(GREETING)} {choice(ASK_NAME)} {HUMAN_NAME}?\"\n",
    "print(AGENT + \": \" + initial_prompt)\n",
    "textSignal = d_util.create_text_signal_with_speaker_annotation(scenario_ctrl, initial_prompt, AGENT)\n",
    "scenario_ctrl.append_signal(textSignal)\n",
    "\n",
    "#### Get name from person \n",
    "HUMAN_NAME, HUMAN_ID = friend.get_a_name_and_id(scenario_ctrl, AGENT)\n",
    "HUMAN_ID = HUMAN_NAME  ### Hack because we cannot force the namespace through capsules, name and identity are the same till this is fixed\n",
    "\n",
    "print(\"Name:\", HUMAN_NAME)\n",
    "print(\"Id:\", HUMAN_ID)\n",
    "                \n",
    "capsule = c_util.scenario_utterance_to_capsule(scenario_ctrl,place_id,location, textSignal,HUMAN_ID,AGENT,\"know\", HUMAN_ID)\n",
    "\n",
    "name_thoughts = my_brain.update(capsule, reason_types=True, create_label=True)\n",
    "chat = Chat(HUMAN_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue the conversation with another speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: Do you have any gossip?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " I am from Rotterdam\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fred: I am from Rotterdam\n",
      "2021-12-09 10:35:12,829 -     INFO - cltl.triple_extraction.api.Chat (Fred)              001 -       Fred: \"I am from Rotterdam\"\n",
      "initial triple: {'subject': 'I', 'predicate': 'am', 'object': 'from-Rotterdam'}\n",
      "2021-12-09 10:35:12,898 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: fred_be-from_rotterdam [person_->_location])\n",
      "2021-12-09 10:35:12,944 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Entity Novelty: existing subject - new object \n",
      "2021-12-09 10:35:15,395 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Negation Conflicts: fred on December,2021 about POSITIVE\n",
      "2021-12-09 10:35:15,489 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. live-in location - 15 gaps as object: e.g. be-friends-with person\n",
      "2021-12-09 10:35:15,540 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 0 gaps as subject: e.g. '' - 5 gaps as object: e.g. manufacture-in robot\n",
      "Leolani2: I would like to know. Has a person ever born in rotterdam?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " I like cats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fred: I like cats\n",
      "2021-12-09 10:35:19,715 -     INFO - cltl.triple_extraction.api.Chat (Fred)              002 -       Fred: \"I like cats\"\n",
      "initial triple: {'subject': 'I', 'predicate': 'like', 'object': 'cats'}\n",
      "2021-12-09 10:35:19,748 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: fred_like_cats [person_->_animal])\n",
      "2021-12-09 10:35:19,885 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Overlaps: 0 subject overlaps: e.g. '' - 1 object overlaps: e.g. piek on December,2021 about piek\n",
      "2021-12-09 10:35:22,486 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Negation Conflicts: fred on December,2021 about POSITIVE\n",
      "2021-12-09 10:35:22,542 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. be-member-of institution - 15 gaps as object: e.g. know agent\n",
      "2021-12-09 10:35:22,596 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 0 gaps as subject: e.g. '' - 2 gaps as object: e.g. own agent\n",
      "Leolani2: I am curious. What types can fred like\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Who likes cats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fred: Who likes cats\n",
      "2021-12-09 10:35:28,282 -     INFO - cltl.triple_extraction.api.Chat (Fred)              003 -       Fred: \"Who likes cats\"\n",
      "2021-12-09 10:35:28,288 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in question: cats_like_? [animal_->_])\n",
      "Leolani2: I may be ignorant, bu tI don't know.I am sorry, I have no idea\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Who does like cats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fred: Who does like cats\n",
      "2021-12-09 10:35:54,171 -     INFO - cltl.triple_extraction.api.Chat (Fred)              004 -       Fred: \"Who does like cats\"\n",
      "2021-12-09 10:35:54,175 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in question: cats_like_? [animal_->_])\n",
      "Leolani2: I don't know\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Piek likes cats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fred: Piek likes cats\n",
      "2021-12-09 10:36:01,084 -     INFO - cltl.triple_extraction.api.Chat (Fred)              005 -       Fred: \"Piek likes cats\"\n",
      "initial triple: {'subject': 'Piek', 'predicate': 'likes', 'object': 'cats'}\n",
      "2021-12-09 10:36:01,152 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: piek_like_cats [agent_->_animal])\n",
      "2021-12-09 10:36:01,189 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Statement Novelty: 1 times, e.g. piek on December,2021\n",
      "2021-12-09 10:36:01,340 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Overlaps: 1 subject overlaps: e.g. piek on December,2021 about dogs - 1 object overlaps: e.g. fred on December,2021 about fred\n",
      "2021-12-09 10:36:03,644 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Negation Conflicts: piek on December,2021 about POSITIVE\n",
      "2021-12-09 10:36:03,741 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. be-child-of agent - 15 gaps as object: e.g. like-by agent\n",
      "2021-12-09 10:36:03,792 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 0 gaps as subject: e.g. '' - 2 gaps as object: e.g. own person\n",
      "Leolani2: If you don't mind me asking. Has a person ever own cats?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Piek owns cats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fred: Piek owns cats\n",
      "2021-12-09 10:36:15,170 -     INFO - cltl.triple_extraction.api.Chat (Fred)              006 -       Fred: \"Piek owns cats\"\n",
      "initial triple: {'subject': 'Piek', 'predicate': 'owns', 'object': 'cats'}\n",
      "2021-12-09 10:36:15,197 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: piek_own_cats [agent_->_animal])\n",
      "2021-12-09 10:36:17,843 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Negation Conflicts: fred on December,2021 about POSITIVE\n",
      "2021-12-09 10:36:17,942 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. like interest - 15 gaps as object: e.g. cook-by food\n",
      "Leolani2: Exciting news! I did not know anybody who own cats\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " I own cats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fred: I own cats\n",
      "2021-12-09 10:36:24,869 -     INFO - cltl.triple_extraction.api.Chat (Fred)              007 -       Fred: \"I own cats\"\n",
      "initial triple: {'subject': 'I', 'predicate': 'own', 'object': 'cats'}\n",
      "2021-12-09 10:36:24,897 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: fred_own_cats [person_->_animal])\n",
      "2021-12-09 10:36:25,038 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Overlaps: 0 subject overlaps: e.g. '' - 1 object overlaps: e.g. fred on December,2021 about piek\n",
      "2021-12-09 10:36:27,643 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Negation Conflicts: fred on December,2021 about POSITIVE\n",
      "2021-12-09 10:36:27,695 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. play sport - 15 gaps as object: e.g. cook-by dish\n",
      "Leolani2: I am glad to have learned something new. I had never heard about cats before!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Piek has cats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fred: Piek has cats\n",
      "2021-12-09 10:36:33,511 -     INFO - cltl.triple_extraction.api.Chat (Fred)              008 -       Fred: \"Piek has cats\"\n",
      "initial triple: {'subject': 'Piek', 'predicate': 'has', 'object': 'cats'}\n",
      "2021-12-09 10:36:33,546 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: piek_have_cats [agent_->_animal])\n",
      "2021-12-09 10:36:36,297 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Negation Conflicts: fred on December,2021 about POSITIVE\n",
      "2021-12-09 10:36:36,387 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. travel-to location - 15 gaps as object: e.g. be-parent-of person\n",
      "Leolani2: Let me ask you something. What types can piek have\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " I have cats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fred: I have cats\n",
      "2021-12-09 10:36:40,357 -     INFO - cltl.triple_extraction.api.Chat (Fred)              009 -       Fred: \"I have cats\"\n",
      "initial triple: {'subject': 'I', 'predicate': 'have', 'object': 'cats'}\n",
      "2021-12-09 10:36:40,397 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: fred_have_cats [person_->_animal])\n",
      "2021-12-09 10:36:40,538 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Overlaps: 0 subject overlaps: e.g. '' - 1 object overlaps: e.g. fred on December,2021 about piek\n",
      "2021-12-09 10:36:43,094 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Negation Conflicts: fred on December,2021 about POSITIVE\n",
      "2021-12-09 10:36:43,146 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. be-child-of agent - 15 gaps as object: e.g. be-parent-of person\n",
      "Leolani2: I would like to know. What types can fred have\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Who has cats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fred: Who has cats\n",
      "2021-12-09 10:36:52,112 -     INFO - cltl.triple_extraction.api.Chat (Fred)              010 -       Fred: \"Who has cats\"\n",
      "2021-12-09 10:36:52,115 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in question: cats_have_? [animal_->_])\n",
      "Leolani2: I may be ignorant, bu tI don't know.I am sorry, I have no idea\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Who does have cats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fred: Who does have cats\n",
      "2021-12-09 10:37:04,155 -     INFO - cltl.triple_extraction.api.Chat (Fred)              011 -       Fred: \"Who does have cats\"\n",
      "2021-12-09 10:37:04,158 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in question: cats_be_? [animal_->_])\n",
      "Leolani2: I may be ignorant, bu tI don't know.I am sorry, I have no idea\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fred: stop\n",
      "2021-12-09 10:37:08,202 -     INFO - cltl.triple_extraction.api.Chat (Fred)              012 -       Fred: \"stop\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't parse input\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: Be that as it may, still may it be as it may be\n"
     ]
    }
   ],
   "source": [
    "#### Initial prompt by the system from which we create a TextSignal and store it\n",
    "initial_prompt = f\"{choice(TALK_TO_ME)}\"\n",
    "print(AGENT + \": \" + initial_prompt)\n",
    "textSignal = d_util.create_text_signal_with_speaker_annotation(scenario_ctrl, initial_prompt, AGENT)\n",
    "scenario_ctrl.append_signal(textSignal)\n",
    "\n",
    "utterance = \"\"\n",
    "#### Get input and loop\n",
    "while not (utterance.lower() == 'stop' or utterance.lower() == 'bye'):\n",
    "    ###### Getting the next input signals\n",
    "    utterance = input('\\n')\n",
    "    print(HUMAN_NAME + \": \" + utterance)\n",
    "    textSignal = d_util.create_text_signal_with_speaker_annotation(scenario_ctrl, utterance, HUMAN_ID)\n",
    "    scenario_ctrl.append_signal(textSignal)\n",
    "\n",
    "    #### Process input and generate reply\n",
    "    \n",
    "    capsule, reply = talk.process_text_and_reply(scenario_ctrl,\n",
    "                           place_id,\n",
    "                           location,\n",
    "                           HUMAN_ID,\n",
    "                           textSignal,\n",
    "                           chat,\n",
    "                           replier,\n",
    "                           my_brain,\n",
    "                           print_details)\n",
    "\n",
    "    print(AGENT + \": \" + reply)\n",
    "    textSignal = d_util.create_text_signal_with_speaker_annotation(scenario_ctrl, reply, AGENT)\n",
    "    scenario_ctrl.append_signal(textSignal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the scenario data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_ctrl.scenario.ruler.end = int(time.time() * 1e3)\n",
    "scenarioStorage.save_scenario(scenario_ctrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
