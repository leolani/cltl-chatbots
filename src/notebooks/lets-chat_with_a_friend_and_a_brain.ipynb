{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's chat with a friend and I have a brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo chat with Leolani that combine face recognition and storage in the BRAIN. This notebook combines the functions of two other notebooks:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piek/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/rdflib_jsonld/__init__.py:12: DeprecationWarning: The rdflib-jsonld package has been integrated into rdflib as of rdflib==6.0.1.  Please remove rdflib-jsonld from your project's dependencies.\n",
      "  DeprecationWarning,\n",
      "[nltk_data] Downloading package punkt to /Users/piek/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# general imports for EMISSOR and the BRAIN\n",
    "import emissor as em\n",
    "from cltl import brain\n",
    "from cltl.triple_extraction.api import Chat, UtteranceHypothesis\n",
    "from emissor.persistence import ScenarioStorage\n",
    "from emissor.representation.annotation import AnnotationType, Token, NER\n",
    "from emissor.representation.container import Index\n",
    "from emissor.representation.scenario import Modality, ImageSignal, TextSignal, Mention, Annotation, Scenario\n",
    "from cltl.brain.long_term_memory import LongTermMemory\n",
    "from cltl.combot.backend.api.discrete import UtteranceType\n",
    "\n",
    "# specific imports\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import requests\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the chatbot utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "src_path = os.path.abspath(os.path.join('..'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "#### The next utils are needed for the interaction and creating triples and capsules\n",
    "import chatbots.util.driver_util as d_util\n",
    "import chatbots.util.capsule_util as c_util\n",
    "import chatbots.util.face_util as f_util\n",
    "import chatbots.intentions.talk as talk\n",
    "import chatbots.intentions.get_to_know_you as friend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Link your camera\n",
    "camera = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the BRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-15 10:23:05,715 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Booted\n",
      "2021-11-15 10:23:11,180 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Uploading ontology to brain\n",
      "2021-11-15 10:23:13,825 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Booted\n",
      "2021-11-15 10:23:13,827 -     INFO -  cltl.brain.basic_brain.LocationReasoner - Booted\n",
      "2021-11-15 10:23:13,830 -     INFO -      cltl.brain.basic_brain.TypeReasoner - Booted\n",
      "2021-11-15 10:23:13,832 -     INFO -   cltl.brain.basic_brain.TrustCalculator - Booted\n",
      "2021-11-15 10:23:14,078 -     INFO -   cltl.brain.basic_brain.TrustCalculator - Computed trust for all known agents\n"
     ]
    }
   ],
   "source": [
    "# Initialise the brain in GraphDB\n",
    "import pathlib\n",
    "\n",
    "log_path = pathlib.Path('./logs')\n",
    "my_brain = brain.LongTermMemory(address=\"http://localhost:7200/repositories/sandbox\",\n",
    "                                log_dir=log_path,\n",
    "                                clear_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard initialisation of a scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  ../../data/2021-11-15-10:23:38  Created \n",
      "Directory  ../../data/2021-11-15-10:23:38/image  Created \n"
     ]
    }
   ],
   "source": [
    "from random import getrandbits\n",
    "\n",
    "##### Setting the location\n",
    "place_id = getrandbits(8)\n",
    "location = requests.get(\"https://ipinfo.io\").json()\n",
    "\n",
    "##### Setting the agents\n",
    "AGENT = \"Leolani2\"\n",
    "HUMAN_NAME = \"Stranger\"\n",
    "HUMAN_ID = \"stranger\"\n",
    "\n",
    "### The name of your scenario\n",
    "scenario_id = datetime.today().strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "\n",
    "### Specify the path to an existing data folder where your scenario is created and saved as a subfolder\n",
    "scenario_path = \"../../data\"\n",
    "\n",
    "### Define the folder where the images are saved\n",
    "imagefolder = scenario_path + \"/\" + scenario_id + \"/\" + \"image\"\n",
    "\n",
    "### Create the scenario folder, the json files and a scenarioStorage and scenario in memory\n",
    "scenarioStorage = d_util.create_scenario(scenario_path, scenario_id)\n",
    "scenario = scenarioStorage.create_scenario(scenario_id, datetime.now().microsecond, datetime.now().microsecond, AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the docker containers for face detection and face property detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the docker images are running you can skip the next part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You only need to load the dockers once. The first time you load the docker, the images will be donwloaded from the DockerHub. This may take a few minutes depending on the speed of the internet connection. The images are cached in your local Docker installation.\n",
    "\n",
    "One the images are in your local Docker, they are loaded instantaniously. Once the docker is started you do not need to start it again and you can skip the next commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#container_fdr = f_util.start_docker_container(\"tae898/face-detection-recognition:v0.1\", 10002)\n",
    "#container_ag = f_util.start_docker_container(\"tae898/age-gender:v0.2\", 10003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is a problem starting the dockers, you may need to kill them and start them again. Use the following command to kill and rerun the previous command. Note that if there are running already you should not restart. Starting it again gives an error that the port is occupied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!docker kill $(docker ps -q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting and storing triples from an utterance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function processes any textSignal using the baseline language model from the Leolani platform.\n",
    "This model uses a context-free grammar and closed-class lexicons specifically designed for social robot interaction.\n",
    "\n",
    "The function creates a capsule for posting any triples and perspective to the BRAIN.\n",
    "If no triples are extracted, a dummy prompt is returned: \"Any gossip?\".\n",
    "\n",
    "Any thoughts coming from the BRAIN are returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new friend.\n",
    "\n",
    "The functions in *intentions/get_to_know_you.py* are needed to get the properties and visual information for identifying a new friend.\n",
    "\n",
    "The visual information is based on the camera images of the uses from which we extract an averaged embedding.\n",
    "These embeddings are store in the *friend_embeddings* folder. \n",
    "\n",
    "By comparing an image with the stored embeddings, the system decides whether a person is a *stranger*.\n",
    "In case the user is a *stranger*, the system will try to get to know him/her.\n",
    "\n",
    "If you delete someone's embeddings from the *friend_embeddings* folder. This person will become a *stranger* again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paths with the friends: /Users/piek/PycharmProjects/cltl-chatbots/friend_embeddings\n"
     ]
    }
   ],
   "source": [
    "### Specify the path to an existing folder with the embeddings of your friends\n",
    "friends_path = os.path.abspath(os.path.join('../../friend_embeddings'))\n",
    "if friends_path not in sys.path:\n",
    "    sys.path.append(friends_path)\n",
    "\n",
    "print(\"The paths with the friends:\", friends_path)\n",
    "\n",
    "### Define the folder where the images are saved\n",
    "imagefolder = scenario_path + \"/\" + scenario_id + \"/\" + \"image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../data/2021-11-15-10:23:38/image/142025.png image loaded!\n",
      "got <Response [200]> from server!...\n",
      "1 faces deteced!\n",
      "got <Response [200]> from server!...\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='127.0.0.1', port=10004): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa2590f2950>: Failed to establish a new connection: [Errno 61] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             )\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             )\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_user_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1297\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             )\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7fa2590f2950>: Failed to establish a new connection: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    755\u001b[0m             retries = retries.increment(\n\u001b[0;32m--> 756\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m             )\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=10004): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa2590f2950>: Failed to establish a new connection: [Errno 61] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6w/bw7dqbl9727c48pcjjh32r140000gn/T/ipykernel_99790/3305263060.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mfaces_detected\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mdet_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     ) = f_util.do_stuff_with_image(friends_path, imagepath)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Here we assume that only one face is in the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/src/chatbots/util/face_util.py\u001b[0m in \u001b[0;36mdo_stuff_with_image\u001b[0;34m(friends_path, image_path, url_face, url_age_gender, url_yolo)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0mages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_age_gender_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_age_gender\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m     \u001b[0myolo_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_yolo_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_yolo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"annotating image ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/src/chatbots/util/face_util.py\u001b[0m in \u001b[0;36mrun_yolo_api\u001b[0;34m(to_send, url_yolo)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0mto_send\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjsonpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_send\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_yolo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_send\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"got {response} from server!...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjsonpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \"\"\"\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=10004): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa2590f2950>: Failed to establish a new connection: [Errno 61] Connection refused'))"
     ]
    }
   ],
   "source": [
    "#First step is to identify the speaker\n",
    "\n",
    "imagepath = \"\"\n",
    "uuid_name = \"\"\n",
    "# First signal\n",
    "success, frame = camera.read()\n",
    "\n",
    "if success:\n",
    "    ### check if we know the human\n",
    "    current_time = str(datetime.now().microsecond)\n",
    "    imagepath = imagefolder + \"/\" + current_time + \".png\"\n",
    "    cv2.imwrite(imagepath, frame)\n",
    "    imageSignal = d_util.create_image_signal(scenario, imagepath)\n",
    "    (\n",
    "        genders,\n",
    "        ages,\n",
    "        bboxes,\n",
    "        faces_detected,\n",
    "        det_scores, embeddings,\n",
    "    ) = f_util.do_stuff_with_image(friends_path, imagepath)\n",
    "\n",
    "    # Here we assume that only one face is in the image\n",
    "    # TODO: deal with multiple people.\n",
    "    for k, (gender, age, bbox, uuid_name, faceprob, embedding) in enumerate(\n",
    "            zip(genders, ages, bboxes, faces_detected, det_scores, embeddings)\n",
    "    ):\n",
    "        age = round(age[\"mean\"])\n",
    "        gender = \"male\" if gender[\"m\"] > 0.5 else \"female\"\n",
    "        bbox = [int(num) for num in bbox.tolist()]\n",
    "    assert k == 0\n",
    "    if uuid_name[\"name\"] is None:\n",
    "        ### This is a stranger\n",
    "        ### We call the get_to_know function to create the data for a new friend\n",
    "        HUMAN_ID, HUMAN_NAME, textSignal = friend.get_to_know_person(scenario, AGENT, gender, age, uuid_name, embedding)\n",
    "        HUMAN_ID = HUMAN_NAME  ### Hack because we cannot force the namespace through capsules, name and identity are the same till this is fixed\n",
    "\n",
    "        ### We store the data in the BRAIN for the human_id that is returned            \n",
    "        name_thoughts, age_thoughts, gender_thoughts = friend.process_new_friend_and_think(scenario,\n",
    "                                                                                           place_id,\n",
    "                                                                                           location,\n",
    "                                                                                           HUMAN_ID,\n",
    "                                                                                           textSignal,\n",
    "                                                                                           imageSignal,\n",
    "                                                                                           age,\n",
    "                                                                                           gender,\n",
    "                                                                                           HUMAN_NAME,\n",
    "                                                                                           my_brain)\n",
    "\n",
    "        ### The system responds to the processing of the new name input and stores it as a textsignal\n",
    "        print(AGENT + f\": Nice to meet you, {HUMAN_NAME}\")\n",
    "        response = f\": Nice to meet you, {HUMAN_NAME}\"\n",
    "        textSignal = d_util.create_text_signal(scenario, response)\n",
    "        scenario.append_signal(textSignal)\n",
    "\n",
    "    else:\n",
    "        ### We know this person\n",
    "        HUMAN_ID = uuid_name['name']\n",
    "        HUMAN_NAME = HUMAN_ID  ### Hack because we cannot force the namespace through capsules, name and identity are the same till this is fixed \n",
    "        # HUMAN_NAME = HUMAN_ID.split(\"_t_\")[0]\n",
    "        response = f\"Hi {HUMAN_NAME}. Nice to see you again :)\"\n",
    "        print(f\"{AGENT}: {response}\")\n",
    "        textSignal = d_util.create_text_signal(scenario, response)\n",
    "        scenario.append_signal(textSignal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceed to communicate with an identified friend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next while loop is for continuous communication with the identified user until *stop* or *bye*.\n",
    "We process the user input and the captured image sequentially step by setp in the code block of the while loop.\n",
    "At the end of the code block, a response is generated and new input from the user is requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: How are you doing Stranger\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " I am great\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stranger: I am great\n",
      "2021-11-03 17:04:20,465 -     INFO - cltl.triple_extraction.api.Chat (stranger)          000 - << Start of Chat with stranger >>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 17:04:20.465 INFO api - __init__: << Start of Chat with stranger >>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-03 17:04:20,467 -     INFO - cltl.triple_extraction.api.Chat (stranger)          000 - << Start of Chat with stranger >>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 17:04:20.467 INFO api - __init__: << Start of Chat with stranger >>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-03 17:04:20,469 -     INFO -               cltl.triple_extraction.api - Started POS tagger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 17:04:20.469 INFO api - __init__: Started POS tagger\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-03 17:04:20,471 -     INFO -               cltl.triple_extraction.api - Started NER tagger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 17:04:20.480 INFO ner - _start_server: Started NER server\n",
      "2021-11-03 17:04:20.471 INFO api - __init__: Started NER tagger\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-03 17:04:20,484 -     INFO -               cltl.triple_extraction.api - Loaded grammar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 17:04:20.484 INFO api - __init__: Loaded grammar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-03 17:04:21,566 -     INFO - cltl.triple_extraction.api.Chat (stranger)          001 -   stranger: \"I am great\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 17:04:21.566 INFO api - add_utterance:   stranger: \"I am great\"\n",
      "2021-11-03 17:04:21.578 INFO ner - _start_server: Started NER server\n",
      "2021-11-03 17:04:22.895 INFO analyzer - __init__: extracted perspective: {'sentiment': 0, 'certainty': 1, 'polarity': 1, 'emotion': <Emotion.NEUTRAL: 7>}\n",
      "2021-11-03 17:04:22.901 INFO api - analyze: RDF    subject: {\"label\": \"stranger\", \"type\": [\"noun.person\"]}\n",
      "2021-11-03 17:04:22.902 INFO api - analyze: RDF  predicate: {\"label\": \"be\", \"type\": [\"verb.stative\"]}\n",
      "2021-11-03 17:04:22.903 INFO api - analyze: RDF     object: {\"label\": \"great\", \"type\": [\"adj.all\"]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-03 17:04:26,041 -  WARNING -      cltl.brain.basic_brain.TypeReasoner - Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Read timed out. (read timeout=3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 17:04:26.041 WARNING type_reasoner - _exact_match_wikidata: Failed to query Wikidata: HTTPSConnectionPool(host='query.wikidata.org', port=443): Read timed out. (read timeout=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-03 17:04:29,154 -     INFO -      cltl.brain.basic_brain.TypeReasoner - Reasoned type of great to: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 17:04:29.154 INFO type_reasoner - reason_entity_type: Reasoned type of great to: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-03 17:04:29,211 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: stranger_be_great [person_->_])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 17:04:29.211 INFO LTM_statement_processing - model_graphs: Triple in statement: stranger_be_great [person_->_])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-03 17:04:29,225 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Entity Novelty: new subject - new object \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 17:04:29.225 INFO thought_generator - fill_entity_novelty: Entity Novelty: new subject - new object \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-03 17:04:30,778 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. live-in location - 15 gaps as object: e.g. like-by agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 17:04:30.778 INFO thought_generator - get_entity_gaps: Gaps: 26 gaps as subject: e.g. live-in location - 15 gaps as object: e.g. like-by agent\n",
      "2021-11-03 17:04:30.859 INFO face_util - load_binary_image: ../../data/2021-11-03-17:04:09/image/843105.png image loaded!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: Any gossip?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-03 17:04:31.328 INFO face_util - run_face_api: got <Response [200]> from server!...\n",
      "2021-11-03 17:04:31.329 INFO face_util - run_face_api: 0 faces deteced!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'run_age_gender_api' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k1/bs53rbv901qc_hqgfx1cqm5c0000gn/T/ipykernel_44813/579361256.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mdet_scores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         ) = f_util.do_stuff_with_image(imagepath)\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/PhD/CLTL/cltl-chatbots/src/util/face_util.py\u001b[0m in \u001b[0;36mdo_stuff_with_image\u001b[0;34m(image_path, url_face, url_age_gender)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0mfaces_detected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0mages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_age_gender_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_age_gender\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"annotating image ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run_age_gender_api' is not defined"
     ]
    }
   ],
   "source": [
    "### First prompt\n",
    "response = \"How are you doing \" + HUMAN_NAME\n",
    "textSignal = d_util.create_text_signal(scenario, response)\n",
    "scenario.append_signal(textSignal)\n",
    "\n",
    "print(AGENT + \": \" + response)\n",
    "\n",
    "#### Get the input from the user\n",
    "utterance = input(\"\\n\")\n",
    "print(HUMAN_NAME + \": \" + utterance)\n",
    "chat = Chat(HUMAN_ID)\n",
    "\n",
    "replier = None\n",
    "\n",
    "while not (utterance.lower() == \"stop\" or utterance.lower() == \"bye\"):\n",
    "    textSignal = d_util.create_text_signal(scenario, utterance)\n",
    "    scenario.append_signal(textSignal)\n",
    "\n",
    "    # @TODO: also annotate the textSignal\n",
    "    # Apply some processing to the textSignal and add annotations\n",
    "\n",
    "    # We process the utterance and store triples in the brain\n",
    "    # We catch the thoughts as the response\n",
    "    thoughts = talk.process_text_and_think(scenario,\n",
    "                                             place_id,\n",
    "                                             location,\n",
    "                                             textSignal,\n",
    "                                             HUMAN_ID, my_brain, replier)\n",
    "    \n",
    "     #### Process input and generate reply\n",
    "    \n",
    "    capsule, reply = talk.process_text_and_reply(scenario,\n",
    "                           place_id,\n",
    "                           location,\n",
    "                           HUMAN_ID,\n",
    "                           textSignal,\n",
    "                           chat,\n",
    "                           replier,\n",
    "                           my_brain,\n",
    "                           print_details)\n",
    "\n",
    "    print(AGENT + \": \" + reply)\n",
    "    textSignal = d_util.create_text_signal(scenario, reply)\n",
    "    scenario.append_signal(textSignal)\n",
    "\n",
    "    ## We capture the image again\n",
    "    ## For now, we only take pictures of faces of the user\n",
    "    ## @TODO add object recognition and check if there are other people detected than the user\n",
    "\n",
    "    success, frame = camera.read()\n",
    "    if success:\n",
    "        current_time = str(datetime.now().microsecond)\n",
    "        imagepath = imagefolder + \"/\" + current_time + \".png\"\n",
    "        cv2.imwrite(imagepath, frame)\n",
    "        (\n",
    "            genders,\n",
    "            ages,\n",
    "            bboxes,\n",
    "            faces_detected,\n",
    "            det_scores,\n",
    "            embeddings,\n",
    "        ) = f_util.do_stuff_with_image(imagepath)\n",
    "\n",
    "    if success:\n",
    "        imageSignal = d_util.create_image_signal(scenario, imagepath)\n",
    "        container_id = str(uuid.uuid4())\n",
    "\n",
    "        #### Properties are now stored as annotations\n",
    "        #### We do not store these proeprties again to the BRAIN\n",
    "        for gender, age, bbox, name, faceprob in zip(\n",
    "                genders, ages, bboxes, faces_detected, det_scores\n",
    "        ):\n",
    "            age = round(age[\"mean\"])\n",
    "            gender = \"male\" if gender[\"m\"] > 0.5 else \"female\"\n",
    "            bbox = [int(num) for num in bbox.tolist()]\n",
    "\n",
    "        f_util.add_face_annotation(imageSignal, container_id, \"front_camera\", container_id, current_time,\n",
    "                                   bbox, HUMAN_ID, HUMAN_NAME, age, gender, faceprob)\n",
    "\n",
    "        scenario.append_signal(imageSignal)\n",
    "\n",
    "        ### We created a perceivedBy triple for this experience, \n",
    "        ### @TODO we need to include the bouding box somehow in the object\n",
    "        capsule = c_util.scenario_image_triple_to_capsule(scenario,\n",
    "                                                          place_id,\n",
    "                                                          location,\n",
    "                                                          imageSignal,\n",
    "                                                          \"front_camera\",\n",
    "                                                          human_id,\n",
    "                                                          \"perceivedBy\",\n",
    "                                                          imageSignal.id)\n",
    "\n",
    "        response = my_brain.update(capsule, reason_types=True, create_label=False)\n",
    "        ## use this version if you want to use the URI as subject\n",
    "\n",
    "    # Create the response from the system and store this as a new signal\n",
    "    # We could use the throughts to respond\n",
    "    # @TODO generate a response from the thoughts or based on the user query\n",
    "\n",
    "    # Getting the next input signals\n",
    "    utterance = input(\"\\n\")\n",
    "\n",
    "    ### We now have a new input check if the user wants to continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the end time of the scenario, save it and stop the containers\n",
    "\n",
    "After we stopped the interaction, we set the end time and save the scenario as EMISSOR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scenario.scenario.end = datetime.now().microsecond\n",
    "scenarioStorage.save_scenario(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stopping the docker containers\n",
    "### This is only needed of you started them in this notebook\n",
    "\n",
    "#f_util.kill_container(container_fdr)\n",
    "#f_util.kill_container(container_ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Stop the camera when we are done\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
