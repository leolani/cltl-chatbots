{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's chat with a friend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo chat with Leolani. Leolani uses face recognition and gender/age\n",
    "estimation to estiablish your identity. When you are new, it will add you to her friends.\n",
    "\n",
    "To use the face functions, you need to install Docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tkb/automatic/workspaces/robo/leolani-project/cltl-chatbots/venv/lib/python3.7/site-packages/rdflib_jsonld/__init__.py:12: DeprecationWarning: The rdflib-jsonld package has been integrated into rdflib as of rdflib==6.0.1.  Please remove rdflib-jsonld from your project's dependencies.\n",
      "  DeprecationWarning,\n"
     ]
    }
   ],
   "source": [
    "import emissor as em\n",
    "from emissor.persistence import ScenarioStorage\n",
    "from emissor.representation.annotation import AnnotationType, Token, NER\n",
    "from emissor.representation.container import Index\n",
    "from emissor.representation.scenario import Modality, ImageSignal, TextSignal, Mention, Annotation, Scenario\n",
    "from cltl.brain.utils.helper_functions import brain_response_to_json\n",
    "\n",
    "#Others\n",
    "import uuid\n",
    "import time\n",
    "from datetime import datetime\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/tkb/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# @TODO can we move the notebooks one level up instead?\n",
    "src_path = os.path.abspath(os.path.join('../'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "#### The next utils are needed for the interaction and creating triples and capsules\n",
    "import chatbots.util.driver_util as d_util\n",
    "import chatbots.util.face_util as f_util\n",
    "import chatbots.intentions.get_to_know_you as friend\n",
    "import chatbots.intentions.talk as talk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Link your camera\n",
    "camera = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard initialisation of a scenario\n",
    "\n",
    "Setup file paths and scenario context information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories for 2021-11-11-23_10_29 created in /Users/tkb/automatic/workspaces/robo/leolani-project/cltl-chatbots/data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "##### Setting the location\n",
    "place_id = str(uuid.uuid4())\n",
    "location = requests.get(\"https://ipinfo.io\").json()\n",
    "\n",
    "##### Setting the agents\n",
    "AGENT = \"Leolani2\"\n",
    "human_name = \"Stranger\"\n",
    "human_id = \"stranger\"\n",
    "\n",
    "### The name of your scenario\n",
    "scenario_id = datetime.today().strftime(\"%Y-%m-%d-%H_%M_%S\")\n",
    "\n",
    "### Specify the path to an existing data folder where your scenario is created and saved as a subfolder\n",
    "# Find the repository root dir\n",
    "parent, dir_name = (d_util.__file__, \"_\")\n",
    "while dir_name and dir_name != \"src\":\n",
    "    parent, dir_name = os.path.split(parent)\n",
    "root_dir = parent\n",
    "scenario_path = os.path.abspath(os.path.join(root_dir, 'data'))\n",
    "\n",
    "if not os.path.exists(scenario_path) :\n",
    "    os.mkdir(scenario_path)\n",
    "    print(\"Created a data folder for storing the scenarios\", scenario_path)\n",
    "\n",
    "### Create the scenario folder, the json files and a scenarioStorage and scenario in memory\n",
    "scenarioStorage = d_util.create_scenario(scenario_path, scenario_id)\n",
    "scenario_ctrl = scenarioStorage.create_scenario(scenario_id, int(time.time() * 1e3), None, AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the location of the face embedding information for her friends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The faces of friends are stored in a folder as embeddings. Every friend is identified through a name, gender and age property detected by the software. The name and the system time is used to create a unique identifier. We now save this in the file name of the mebdding file. A future version, we will create a json structure with the meta data on identities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paths with the friends: /Users/tkb/automatic/workspaces/robo/leolani-project/cltl-chatbots/friend_embeddings\n"
     ]
    }
   ],
   "source": [
    "### Specify the path to an existing folder with the embeddings of your friends\n",
    "friends_path = os.path.abspath(os.path.join(root_dir, 'friend_embeddings'))\n",
    "if friends_path not in sys.path:\n",
    "    sys.path.append(friends_path)\n",
    "\n",
    "print(\"The paths with the friends:\", friends_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the docker containers for face detection and face property detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You only need to load the dockers once. The first time you load the docker, the images will be donwloaded from the DockerHub. This may take a few minutes depending on the speed of the internet connection. The images are cached in your local Docker installation.\n",
    "\n",
    "One the images are in your local Docker, they are loaded instantaniously. Once the docker is started you do not need to start it again and you can skip the next commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNCOMMENT ON FIRST RUN\n"
     ]
    }
   ],
   "source": [
    "# container_fdr = f_util.start_docker_container(\"tae898/face-detection-recognition:v0.1\", 10002)\n",
    "# container_ag = f_util.start_docker_container(\"tae898/age-gender:v0.2\", 10003)\n",
    "print(\"UNCOMMENT ON FIRST RUN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is a problem starting the dockers, you may need to kill them and start them again. Use the following command to kill and rerun the previous command. Note that if there are running already you should not restart. Starting it again gives an error that the port is occupied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!docker kill $(docker ps -q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are now set to make a new friend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions in *intentions/get_to_know_you.py* are needed to get the properties and visual information for identifying a new friend.\n",
    "\n",
    "The visual information is based on the camera images of the uses from which we extract an averaged embedding.\n",
    "These embeddings are store in the *friend_embeddings* folder. \n",
    "\n",
    "By comparing an image with the stored embeddings, the system decides whether a person is a *stranger*.\n",
    "In case the user is a *stranger*, the system will try to get to know him/her.\n",
    "\n",
    "If you delete someone's embeddings from the *friend_embeddings* folder. This person will become a *stranger* again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-11 23:10:33.526 INFO face_util - load_binary_image: /Users/tkb/automatic/workspaces/robo/leolani-project/cltl-chatbots/data/2021-11-11-23_10_29/image/1636668633490.png image loaded!\n",
      "2021-11-11 23:10:34.880 INFO face_util - run_face_api: got <Response [200]> from server!...\n",
      "2021-11-11 23:10:34.882 INFO face_util - run_face_api: 1 faces deteced!\n",
      "2021-11-11 23:10:34.885 INFO face_util - face_recognition: new face!\n",
      "2021-11-11 23:10:34.978 INFO face_util - run_age_gender_api: got <Response [200]> from server!...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: Hi there. We haven't met. I only know that \n",
      "your estimated age is 43 \n",
      " and that your estimated gender is male. What's your name?\n",
      "\n",
      "Thomas\n",
      "Thomas\n",
      "Leolani2: So your name is Thomas?\n",
      "\n",
      "Yes\n",
      "Leolani2: : Nice to meet you, Thomas\n",
      "\n",
      "Leolani2: Nice to meet you, Thomas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parse_age(face):\n",
    "    return round(face.age[\"mean\"])\n",
    "def parse_gender(face):\n",
    "    return \"male\" if face.gender[\"m\"] > 0.5 else \"female\"\n",
    "def parse_bbox(face):\n",
    "    return [int(num) for num in face.bbox.tolist()]\n",
    "def parse_id(face):\n",
    "    return face.face_id['name'] if 'name' in face.face_id else f\"Stranger_t_{int(time.time() * 1e3)}\"\n",
    "def parse_name(face):\n",
    "    face_id = parse_id(face)\n",
    "    return face_id.split(\"_t_\")[0] if face_id else \"Stranger\"\n",
    "\n",
    "# First signals to get started\n",
    "faces =[]\n",
    "while not len(faces) == 1:\n",
    "    success, frame = camera.read()\n",
    "    if not success:\n",
    "        raise ValueError(\"Failed to take a picture\")\n",
    "        \n",
    "    image_time = int(time.time() * 1e3)\n",
    "    imagepath = d_util.absolute_path(scenarioStorage, scenario_id, Modality.IMAGE, f\"{image_time}.png\")\n",
    "    cv2.imwrite(imagepath, frame)\n",
    "    \n",
    "    faces = f_util.detect_faces(friends_path, imagepath)\n",
    "    if not faces:\n",
    "        response = \"Hi, anyone there? I can't see you..\"\n",
    "        time.sleep(3)\n",
    "    elif len(faces) > 1:\n",
    "        response = \"Hi there! Apologizes, but I will only talk to one of you at a time..\"\n",
    "        time.sleep(3)\n",
    "    else:\n",
    "        face = faces[0]\n",
    "        if parse_id(face) is None:\n",
    "            ### This is a stranger, we process the new face\n",
    "            human_id, human_name, _ = friend.get_to_know_person(scenario_ctrl, AGENT, parse_gender(face),\n",
    "                                                                parse_age(face), face.face_id, face.embedding,\n",
    "                                                                friends_path)\n",
    "            response = f\"Nice to meet you, {human_name}\"\n",
    "        else:\n",
    "            ### We know this person\n",
    "            human_id = parse_id(face)\n",
    "            human_name = parse_name(face)\n",
    "            response = f\"Hi {parse_name(face)}. Nice to see you again. How are you today?\"\n",
    "\n",
    "    print(f\"{AGENT}: {response}\\n\")\n",
    "\n",
    "    # Store signals, annotated with the infered Person information\n",
    "    textSignal = d_util.create_text_signal(scenario_ctrl, response)\n",
    "    scenario_ctrl.append_signal(textSignal)\n",
    "\n",
    "    image_bbox = (0, 0, frame.shape[1], frame.shape[0])\n",
    "    imageSignal = d_util.create_image_signal(scenario_ctrl, f\"{image_time}.png\", image_bbox, image_time)\n",
    "    mentions = [f_util.create_face_mention(imageSignal, \"front_camera\", image_time,\n",
    "                                           parse_bbox(face), parse_id(face), parse_name(face),\n",
    "                                           parse_age(face), parse_gender(face), face.det_score)\n",
    "               for face in faces]\n",
    "    imageSignal.mentions.extend(mentions)\n",
    "    scenario_ctrl.append_signal(imageSignal)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a conversation with a friend\n",
    "\n",
    "Below is a simple chat scenario in which we can say anything to our identified friend and store images and conversation in the EMISSOR scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-11 23:11:22.759 INFO face_util - load_binary_image: /Users/tkb/automatic/workspaces/robo/leolani-project/cltl-chatbots/data/2021-11-11-23_10_29/image/1636668682725.png image loaded!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: So you what do you want to talk about Thomas\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-11 23:11:24.337 INFO face_util - run_face_api: got <Response [200]> from server!...\n",
      "2021-11-11 23:11:24.339 INFO face_util - run_face_api: 1 faces deteced!\n",
      "2021-11-11 23:11:24.416 INFO face_util - run_age_gender_api: got <Response [200]> from server!...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-11 23:11:26.427 INFO face_util - load_binary_image: /Users/tkb/automatic/workspaces/robo/leolani-project/cltl-chatbots/data/2021-11-11-23_10_29/image/1636668686393.png image loaded!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas: bla\n",
      "\n",
      "Leolani2: So you what do you want to talk about Thomas\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-11 23:11:27.938 INFO face_util - run_face_api: got <Response [200]> from server!...\n",
      "2021-11-11 23:11:27.939 INFO face_util - run_face_api: 1 faces deteced!\n",
      "2021-11-11 23:11:28.011 INFO face_util - run_age_gender_api: got <Response [200]> from server!...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-11 23:11:29.668 INFO face_util - load_binary_image: /Users/tkb/automatic/workspaces/robo/leolani-project/cltl-chatbots/data/2021-11-11-23_10_29/image/1636668689634.png image loaded!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas: bla\n",
      "\n",
      "Leolani2: So you what do you want to talk about Thomas\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-11 23:11:31.123 INFO face_util - run_face_api: got <Response [200]> from server!...\n",
      "2021-11-11 23:11:31.124 INFO face_util - run_face_api: 1 faces deteced!\n",
      "2021-11-11 23:11:31.201 INFO face_util - run_age_gender_api: got <Response [200]> from server!...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-11 23:11:32.996 INFO face_util - load_binary_image: /Users/tkb/automatic/workspaces/robo/leolani-project/cltl-chatbots/data/2021-11-11-23_10_29/image/1636668692963.png image loaded!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas: bla\n",
      "\n",
      "Leolani2: So you what do you want to talk about Thomas\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-11 23:11:34.473 INFO face_util - run_face_api: got <Response [200]> from server!...\n",
      "2021-11-11 23:11:34.475 INFO face_util - run_face_api: 1 faces deteced!\n",
      "2021-11-11 23:11:34.563 INFO face_util - run_age_gender_api: got <Response [200]> from server!...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "stop\n",
      "Thomas: stop\n",
      "\n",
      "Leolani2: So you what do you want to talk about Thomas\n",
      "\n",
      "Leolani2: Good bye Thomas!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = \"So you what do you want to talk about \" + human_name\n",
    "print(f\"{AGENT}: {response}\\n\")\n",
    "textSignal = d_util.create_text_signal(scenario_ctrl, response)\n",
    "scenario_ctrl.append_signal(textSignal)\n",
    "\n",
    "utterance = \"\"\n",
    "while not (utterance.lower() == \"stop\" or utterance.lower() == \"bye\"):\n",
    "    # @TODO: also annotate the textSignal\n",
    "    # Apply some processing to the textSignal and add annotations\n",
    "    success, frame = camera.read()\n",
    "    if not success:\n",
    "        raise ValueError(\"Failed to take a picture\")\n",
    "        \n",
    "    image_time = int(time.time() * 1e3)\n",
    "    imagepath = d_util.absolute_path(scenarioStorage, scenario_id, Modality.IMAGE, f\"{image_time}.png\")\n",
    "    cv2.imwrite(imagepath, frame)\n",
    "    \n",
    "    faces = f_util.detect_faces(friends_path, imagepath)\n",
    "    if faces and not human_id in [parse_id(face) for face in faces]:\n",
    "        response = f\"Good bye {human_name}!\"\n",
    "        print(f\"{AGENT}: {response}\\n\")\n",
    "        textSignal = d_util.create_text_signal(scenario_ctrl, response)\n",
    "        scenario_ctrl.append_signal(textSignal)\n",
    "\n",
    "        if len(faces) > 1:\n",
    "            response = \"Apologizes, but I will only talk to one of you at a time..\"\n",
    "        else:\n",
    "            face = faces[0]\n",
    "            if parse_id(face) is None:\n",
    "                ### This is a stranger, we process the new face\n",
    "                human_id, human_name, _ = friend.get_to_know_person(scenario_ctrl, AGENT, parse_gender(face),\n",
    "                                                                    parse_age(face), face.face_id, face.embedding,\n",
    "                                                                    friends_path)\n",
    "                response = f\"Nice to meet you, {human_name}\"\n",
    "            else:\n",
    "                human_id = parse_id(face)\n",
    "                human_name = parse_name(face)\n",
    "                response = f\"Hi {parse_name(face)}. Nice to see you again. How are you today?\"\n",
    "\n",
    "        print(f\"{AGENT}: {response}\\n\")\n",
    "        textSignal = d_util.create_text_signal(scenario_ctrl, response)\n",
    "        scenario_ctrl.append_signal(textSignal)\n",
    "\n",
    "    utterance = input(\"\\n\")\n",
    "    if not utterance:\n",
    "        continue\n",
    "    print(f\"{human_name}: {utterance}\\n\")\n",
    "\n",
    "    # Create the response from the system and store this as a new signal\n",
    "    # We could use the throughts to respond\n",
    "    # @TODO generate a response from the thoughts\n",
    "    response = \"So you what do you want to talk about \" + human_name\n",
    "    print(f\"{AGENT}: {response}\\n\")\n",
    "\n",
    "    # Store signals, annotated with the infered Person information\n",
    "    textSignal = d_util.create_text_signal(scenario_ctrl, utterance)\n",
    "    scenario_ctrl.append_signal(textSignal)\n",
    "\n",
    "    textSignal = d_util.create_text_signal(scenario_ctrl, response)\n",
    "    scenario_ctrl.append_signal(textSignal)\n",
    "\n",
    "    image_bbox = (0, 0, frame.shape[1], frame.shape[0])\n",
    "    imageSignal = d_util.create_image_signal(scenario_ctrl, f\"{image_time}.png\", image_bbox, image_time)\n",
    "    mentions = [f_util.create_face_mention(imageSignal, \"front_camera\", image_time,\n",
    "                                           parse_bbox(face), face.face_id, parse_name(face),\n",
    "                                           parse_age(face), parse_gender(face), face.det_score)\n",
    "               for face in faces]\n",
    "    imageSignal.mentions.extend(mentions)\n",
    "    scenario_ctrl.append_signal(imageSignal)\n",
    "            \n",
    "print(f\"{AGENT}: Good bye {human_name}!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the end time of the scenario, save it and stop the containers\n",
    "\n",
    "After we stopped the interaction, we set the end time and save the scenario as EMISSOR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_ctrl.scenario.ruler.end = int(time.time() * 1e3)\n",
    "\n",
    "scenarioStorage.save_scenario(scenario_ctrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stopping the docker containers\n",
    "### This is only needed of you started them in this notebook\n",
    "\n",
    "#f_util.kill_container(container_fdr)\n",
    "#f_util.kill_container(container_ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Stop the camera when we are done\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
