{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's chat with a friend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo chat with Leolani. Leolani uses face recognition and gender/age\n",
    "estimation to estiablish your identity. When you are new, it will add you to her friends.\n",
    "\n",
    "To use the face functions, you need to install Docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.virtualenvs/leolani/lib/python3.8/site-packages/rdflib_jsonld/__init__.py:9: DeprecationWarning: The rdflib-jsonld package has been integrated into rdflib as of rdflib==6.0.1.  Please remove rdflib-jsonld from your project's dependencies.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import emissor as em\n",
    "from emissor.persistence import ScenarioStorage\n",
    "from emissor.representation.annotation import AnnotationType, Token, NER\n",
    "from emissor.representation.container import Index\n",
    "from emissor.representation.scenario import Modality, ImageSignal, TextSignal, Mention, Annotation, Scenario\n",
    "from cltl.brain.utils.helper_functions import brain_response_to_json\n",
    "\n",
    "#Others\n",
    "import uuid\n",
    "import time\n",
    "from datetime import datetime\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/tk/repos/cltl-chatbots/src/notebooks/lets-chat_with_a_friend.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tk/repos/cltl-chatbots/src/notebooks/lets-chat_with_a_friend.ipynb#ch0000003?line=10'>11</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mchatbots\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mface_util\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mf_util\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tk/repos/cltl-chatbots/src/notebooks/lets-chat_with_a_friend.ipynb#ch0000003?line=11'>12</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mchatbots\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext_util\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mt_util\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/tk/repos/cltl-chatbots/src/notebooks/lets-chat_with_a_friend.ipynb#ch0000003?line=12'>13</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mchatbots\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mintentions\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mget_to_know_you\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mfriend\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tk/repos/cltl-chatbots/src/notebooks/lets-chat_with_a_friend.ipynb#ch0000003?line=13'>14</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mchatbots\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mintentions\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtalk\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtalk\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/cltl-chatbots/src/chatbots/intentions/get_to_know_you.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='file:///home/tk/repos/cltl-chatbots/src/chatbots/intentions/get_to_know_you.py?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39memissor\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpersistence\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpersistence\u001b[39;00m \u001b[39mimport\u001b[39;00m ScenarioController\n\u001b[1;32m      <a href='file:///home/tk/repos/cltl-chatbots/src/chatbots/intentions/get_to_know_you.py?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39memissor\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrepresentation\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscenario\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageSignal, TextSignal, Scenario\n\u001b[0;32m----> <a href='file:///home/tk/repos/cltl-chatbots/src/chatbots/intentions/get_to_know_you.py?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchatbots\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcapsule_util\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mc_util\u001b[39;00m\n\u001b[1;32m      <a href='file:///home/tk/repos/cltl-chatbots/src/chatbots/intentions/get_to_know_you.py?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchatbots\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdriver_util\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39md_util\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/tk/repos/cltl-chatbots/src/chatbots/intentions/get_to_know_you.py?line=11'>12</a>\u001b[0m \u001b[39m### Function that tries to get the name for a new person. A while is used till the user is happy.\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/tk/repos/cltl-chatbots/src/chatbots/intentions/get_to_know_you.py?line=12'>13</a>\u001b[0m \u001b[39m### From the name a unique ID *human_id* is created by adding the time_stamp\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/tk/repos/cltl-chatbots/src/chatbots/intentions/get_to_know_you.py?line=13'>14</a>\u001b[0m \u001b[39m### We store the face embeddings in the friend_embeddings folder using the unique ID *human_id*\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/tk/repos/cltl-chatbots/src/chatbots/intentions/get_to_know_you.py?line=14'>15</a>\u001b[0m \u001b[39m### The function returns the human_name and the human_id.\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/tk/repos/cltl-chatbots/src/chatbots/intentions/get_to_know_you.py?line=15'>16</a>\u001b[0m \u001b[39m### Human_name is used to address the user, and human_id is used to store properties of the user\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# @TODO can we move the notebooks one level up instead?\n",
    "src_path = os.path.abspath(os.path.join('../'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "#### The next utils are needed for the interaction and creating triples and capsules\n",
    "import chatbots.util.driver_util as d_util\n",
    "import chatbots.util.face_util as f_util\n",
    "import chatbots.util.text_util as t_util\n",
    "import chatbots.intentions.get_to_know_you as friend\n",
    "import chatbots.intentions.talk as talk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Link your camera\n",
    "camera = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard initialisation of a scenario\n",
    "\n",
    "Setup file paths and scenario context information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories for 2022-03-24-21:41:31 created in /home/tk/repos/cltl-chatbots/data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "##### Setting the location\n",
    "place_id = str(uuid.uuid4())\n",
    "location = None\n",
    "try:\n",
    "    location = requests.get(\"https://ipinfo.io\").json()\n",
    "except:\n",
    "    print(\"failed to get the IP location\")\n",
    "\n",
    "##### Setting the agents\n",
    "AGENT = \"Leolani2\"\n",
    "human_name = \"Stranger\"\n",
    "human_id = \"stranger\"\n",
    "\n",
    "### The name of your scenario\n",
    "scenario_id = datetime.today().strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "\n",
    "### Specify the path to an existing data folder where your scenario is created and saved as a subfolder\n",
    "# Find the repository root dir\n",
    "parent, dir_name = (d_util.__file__, \"_\")\n",
    "while dir_name and dir_name != \"src\":\n",
    "    parent, dir_name = os.path.split(parent)\n",
    "root_dir = parent\n",
    "scenario_path = os.path.abspath(os.path.join(root_dir, 'data'))\n",
    "\n",
    "if not os.path.exists(scenario_path) :\n",
    "    os.mkdir(scenario_path)\n",
    "    print(\"Created a data folder for storing the scenarios\", scenario_path)\n",
    "\n",
    "### Create the scenario folder, the json files and a scenarioStorage and scenario in memory\n",
    "scenarioStorage = d_util.create_scenario(scenario_path, scenario_id)\n",
    "scenario_ctrl = scenarioStorage.create_scenario(scenario_id, int(time.time() * 1e3), None, AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the location of the face embedding information for her friends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The faces of friends are stored in a folder as embeddings. Every friend is identified through a name, gender and age property detected by the software. The name and the system time is used to create a unique identifier. We now save this in the file name of the mebdding file. A future version, we will create a json structure with the meta data on identities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paths with the friends: /home/tk/repos/cltl-chatbots/friend_embeddings\n"
     ]
    }
   ],
   "source": [
    "### Specify the path to an existing folder with the embeddings of your friends\n",
    "friends_path = os.path.abspath(os.path.join(root_dir, 'friend_embeddings'))\n",
    "if friends_path not in sys.path:\n",
    "    sys.path.append(friends_path)\n",
    "\n",
    "print(\"The paths with the friends:\", friends_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the docker containers for face detection and face property detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You only need to load the dockers once. The first time you load the docker, the images will be donwloaded from the DockerHub. This may take a few minutes depending on the speed of the internet connection. The images are cached in your local Docker installation.\n",
    "\n",
    "One the images are in your local Docker, they are loaded instantaniously. Once the docker is started you do not need to start it again and you can skip the next commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 21:41:43 -     INFO -                                                         root - starting a tae898/face-detection-recognition container ...\n",
      "2022-03-24 21:41:49 -     INFO -                                                         root - starting a tae898/age-gender container ...\n",
      "2022-03-24 21:41:54 -     INFO -                                                         root - starting a tae898/yolov5 container ...\n",
      "2022-03-24 21:42:00 -     INFO -                                                         root - starting a tae898/room-classification container ...\n",
      "2022-03-24 21:42:05 -     INFO -                                                         root - starting a tae898/emoberta-large container ...\n"
     ]
    }
   ],
   "source": [
    "### This is only needed if you start the docker containers from this notebook\n",
    "\n",
    "container_fdr = f_util.start_docker_container(\n",
    "    \"tae898/face-detection-recognition\", 10002\n",
    ")\n",
    "container_ag = f_util.start_docker_container(\"tae898/age-gender\", 10003)\n",
    "container_yolo = f_util.start_docker_container(\"tae898/yolov5\", 10004)\n",
    "container_room = f_util.start_docker_container(\"tae898/room-classification\", 10005)\n",
    "container_erc = f_util.start_docker_container(\"tae898/emoberta-large\", 10006)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is a problem starting the dockers, you may need to kill them and start them again. Use the following command to kill and rerun the previous command. Note that if there are running already you should not restart. Starting it again gives an error that the port is occupied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker kill $(docker ps -q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are now set to make a new friend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions in *intentions/get_to_know_you.py* are needed to get the properties and visual information for identifying a new friend.\n",
    "\n",
    "The visual information is based on the camera images of the uses from which we extract an averaged embedding.\n",
    "These embeddings are store in the *friend_embeddings* folder. \n",
    "\n",
    "By comparing an image with the stored embeddings, the system decides whether a person is a *stranger*.\n",
    "In case the user is a *stranger*, the system will try to get to know him/her.\n",
    "\n",
    "If you delete someone's embeddings from the *friend_embeddings* folder. This person will become a *stranger* again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 21:42:37 -     INFO -                                                         root - /home/tk/repos/cltl-chatbots/data/2022-03-24-21:41:31/image/1648154557448.png image loaded!\n",
      "2022-03-24 21:42:38 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:42:38 -     INFO -                                                         root - 1 faces deteced!\n",
      "2022-03-24 21:42:38 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:42:38 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:42:38 -     INFO -                                                         root - YOLO image annotation is done!\n",
      "2022-03-24 21:42:38 -     INFO -                                                         root - Annotating face, genders, and ages is done!\n",
      "2022-03-24 21:42:38 -     INFO -                                                         root - image annotation is done!\n",
      "2022-03-24 21:42:38 -     INFO -                                                         root - image saved at /home/tk/repos/cltl-chatbots/data/2022-03-24-21:41:31/image/1648154557448.png.ANNOTATED.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url http://127.0.0.1:10004\n",
      "Leolani2: Hi Vu_Amsterdam. Nice to see you again. How are you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parse_age(face_info):\n",
    "    return round(face_info.age[\"mean\"])\n",
    "def parse_gender(face_info):\n",
    "    return \"male\" if face_info.gender[\"m\"] > 0.5 else \"female\"\n",
    "def parse_bbox(face_info):\n",
    "    return [int(num) for num in face_info.bbox.tolist()]\n",
    "def parse_id(face_info):\n",
    "    return face_info.face_id['name'] if 'name' in face_info.face_id else f\"Stranger_t_{int(time.time() * 1e3)}\"\n",
    "def parse_name(face_info):\n",
    "    face_id = parse_id(face_info)\n",
    "    return face_id.split(\"_t_\")[0] if face_id else \"Stranger\"\n",
    "\n",
    "# First signals to get started\n",
    "faces =[]\n",
    "while not len(faces) == 1:\n",
    "    success, frame = camera.read()\n",
    "    if not success:\n",
    "        raise ValueError(\"Failed to take a picture\")\n",
    "        \n",
    "    image_time = int(time.time() * 1e3)\n",
    "    imagepath = d_util.absolute_path(scenarioStorage, scenario_id, Modality.IMAGE, f\"{image_time}.png\")\n",
    "    cv2.imwrite(imagepath, frame)\n",
    "    \n",
    "    faces = f_util.detect_faces(friends_path, imagepath)\n",
    "    \n",
    "    image_bbox = (0, 0, frame.shape[1], frame.shape[0])\n",
    "    imageSignal = d_util.create_image_signal(scenario_ctrl, f\"{image_time}.png\", image_bbox, image_time)\n",
    "    mentions = [f_util.create_face_mention(imageSignal, \"front_camera\", image_time,\n",
    "                                           parse_bbox(face), parse_id(face), parse_name(face),\n",
    "                                           parse_age(face), parse_gender(face), face.det_score)\n",
    "                for face in faces]\n",
    "    imageSignal.mentions.extend(mentions)\n",
    "    scenario_ctrl.append_signal(imageSignal)\n",
    "\n",
    "    if not faces:\n",
    "        response = \"Hi, anyone there? I can't see you..\"\n",
    "        time.sleep(3)\n",
    "    elif len(faces) > 1:\n",
    "        response = \"Hi there! Apologizes, but I will only talk to one of you at a time..\"\n",
    "        time.sleep(3)\n",
    "    else:\n",
    "        face = faces[0]\n",
    "        if parse_id(face) is None:\n",
    "            ### This is a stranger, we process the new face\n",
    "            human_id, human_name, _ = friend.get_to_know_person(scenario_ctrl, AGENT, parse_gender(face),\n",
    "                                                                parse_age(face), face.face_id, face.embedding,\n",
    "                                                                friends_path)\n",
    "            \n",
    "           # human_id = human_name  ### Hack because we cannot force the namespace through capsules, name and identity are the same till this is fixed\n",
    "\n",
    "\n",
    "            ### Add the new information to the signal\n",
    "            mention = f_util.create_face_mention(imageSignal, \"front_camera\", image_time,\n",
    "                                                 parse_bbox(face), human_id, human_name,\n",
    "                                                 parse_age(face), parse_gender(face), face.det_score)\n",
    "            imageSignal.mentions.append(mention)\n",
    "\n",
    "            response = f\"So you what do you want to talk about {human_name}?\"\n",
    "        else:\n",
    "            ### We know this person\n",
    "            human_id = parse_id(face)\n",
    "            human_name = parse_name(face)\n",
    "            response = f\"Hi {parse_name(face)}. Nice to see you again. How are you today?\"\n",
    "\n",
    "    print(f\"{AGENT}: {response}\\n\")\n",
    "\n",
    "    # Store signals, annotated with the infered Person information\n",
    "    textSignal = d_util.create_text_signal(scenario_ctrl, response)\n",
    "    scenario_ctrl.append_signal(textSignal)\n",
    "    \n",
    "scenarioStorage.save_scenario(scenario_ctrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a conversation with a friend\n",
    "\n",
    "Below is a simple chat scenario in which we can say anything to our identified friend and store images and conversation in the EMISSOR scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 21:42:42 -     INFO -                                                         root - /home/tk/repos/cltl-chatbots/data/2022-03-24-21:41:31/image/1648154562426.png image loaded!\n",
      "2022-03-24 21:42:42 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:42:42 -     INFO -                                                         root - 1 faces deteced!\n",
      "2022-03-24 21:42:42 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:42:43 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:42:43 -     INFO -                                                         root - YOLO image annotation is done!\n",
      "2022-03-24 21:42:43 -     INFO -                                                         root - Annotating face, genders, and ages is done!\n",
      "2022-03-24 21:42:43 -     INFO -                                                         root - image annotation is done!\n",
      "2022-03-24 21:42:43 -     INFO -                                                         root - image saved at /home/tk/repos/cltl-chatbots/data/2022-03-24-21:41:31/image/1648154562426.png.ANNOTATED.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url http://127.0.0.1:10004\n",
      "Vu_Amsterdam: (neutral) hey\n",
      "\n",
      "Leolani2:  So you what do you want to talk about Vu_Amsterdam?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 21:42:46 -     INFO -                                                         root - /home/tk/repos/cltl-chatbots/data/2022-03-24-21:41:31/image/1648154566510.png image loaded!\n",
      "2022-03-24 21:42:47 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:42:47 -     INFO -                                                         root - 1 faces deteced!\n",
      "2022-03-24 21:42:47 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:42:47 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:42:47 -     INFO -                                                         root - YOLO image annotation is done!\n",
      "2022-03-24 21:42:47 -     INFO -                                                         root - Annotating face, genders, and ages is done!\n",
      "2022-03-24 21:42:47 -     INFO -                                                         root - image annotation is done!\n",
      "2022-03-24 21:42:47 -     INFO -                                                         root - image saved at /home/tk/repos/cltl-chatbots/data/2022-03-24-21:41:31/image/1648154566510.png.ANNOTATED.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url http://127.0.0.1:10004\n",
      "Vu_Amsterdam: (neutral) how are you\n",
      "\n",
      "Leolani2:  So you what do you want to talk about Vu_Amsterdam?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 21:42:53 -     INFO -                                                         root - /home/tk/repos/cltl-chatbots/data/2022-03-24-21:41:31/image/1648154573126.png image loaded!\n",
      "2022-03-24 21:42:53 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:42:53 -     INFO -                                                         root - 1 faces deteced!\n",
      "2022-03-24 21:42:53 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:42:53 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:42:53 -     INFO -                                                         root - YOLO image annotation is done!\n",
      "2022-03-24 21:42:53 -     INFO -                                                         root - Annotating face, genders, and ages is done!\n",
      "2022-03-24 21:42:53 -     INFO -                                                         root - image annotation is done!\n",
      "2022-03-24 21:42:53 -     INFO -                                                         root - image saved at /home/tk/repos/cltl-chatbots/data/2022-03-24-21:41:31/image/1648154573126.png.ANNOTATED.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url http://127.0.0.1:10004\n",
      "Vu_Amsterdam: (neutral) Not much\n",
      "\n",
      "Leolani2:  So you what do you want to talk about Vu_Amsterdam?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 21:43:00 -     INFO -                                                         root - /home/tk/repos/cltl-chatbots/data/2022-03-24-21:41:31/image/1648154580903.png image loaded!\n",
      "2022-03-24 21:43:01 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:43:01 -     INFO -                                                         root - 1 faces deteced!\n",
      "2022-03-24 21:43:01 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:43:01 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:43:01 -     INFO -                                                         root - YOLO image annotation is done!\n",
      "2022-03-24 21:43:01 -     INFO -                                                         root - Annotating face, genders, and ages is done!\n",
      "2022-03-24 21:43:01 -     INFO -                                                         root - image annotation is done!\n",
      "2022-03-24 21:43:01 -     INFO -                                                         root - image saved at /home/tk/repos/cltl-chatbots/data/2022-03-24-21:41:31/image/1648154580903.png.ANNOTATED.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url http://127.0.0.1:10004\n",
      "Vu_Amsterdam: (neutral) I'm sleepy\n",
      "\n",
      "Leolani2:  So you what do you want to talk about Vu_Amsterdam?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 21:43:05 -     INFO -                                                         root - /home/tk/repos/cltl-chatbots/data/2022-03-24-21:41:31/image/1648154585601.png image loaded!\n",
      "2022-03-24 21:43:06 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:43:06 -     INFO -                                                         root - 1 faces deteced!\n",
      "2022-03-24 21:43:06 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:43:06 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:43:06 -     INFO -                                                         root - YOLO image annotation is done!\n",
      "2022-03-24 21:43:06 -     INFO -                                                         root - Annotating face, genders, and ages is done!\n",
      "2022-03-24 21:43:06 -     INFO -                                                         root - image annotation is done!\n",
      "2022-03-24 21:43:06 -     INFO -                                                         root - image saved at /home/tk/repos/cltl-chatbots/data/2022-03-24-21:41:31/image/1648154585601.png.ANNOTATED.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url http://127.0.0.1:10004\n",
      "Vu_Amsterdam: (anger) i wanna go home\n",
      "\n",
      "Leolani2:  So you what do you want to talk about Vu_Amsterdam?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 21:43:10 -     INFO -                                                         root - /home/tk/repos/cltl-chatbots/data/2022-03-24-21:41:31/image/1648154590031.png image loaded!\n",
      "2022-03-24 21:43:10 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:43:10 -     INFO -                                                         root - 1 faces deteced!\n",
      "2022-03-24 21:43:10 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:43:10 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:43:10 -     INFO -                                                         root - YOLO image annotation is done!\n",
      "2022-03-24 21:43:10 -     INFO -                                                         root - Annotating face, genders, and ages is done!\n",
      "2022-03-24 21:43:10 -     INFO -                                                         root - image annotation is done!\n",
      "2022-03-24 21:43:10 -     INFO -                                                         root - image saved at /home/tk/repos/cltl-chatbots/data/2022-03-24-21:41:31/image/1648154590031.png.ANNOTATED.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url http://127.0.0.1:10004\n",
      "Vu_Amsterdam: (neutral) exit\n",
      "\n",
      "Leolani2:  So you what do you want to talk about Vu_Amsterdam?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 21:43:12 -     INFO -                                                         root - /home/tk/repos/cltl-chatbots/data/2022-03-24-21:41:31/image/1648154592504.png image loaded!\n",
      "2022-03-24 21:43:13 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:43:13 -     INFO -                                                         root - 1 faces deteced!\n",
      "2022-03-24 21:43:13 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:43:13 -     INFO -                                                         root - got <Response [200]> from server!...\n",
      "2022-03-24 21:43:13 -     INFO -                                                         root - YOLO image annotation is done!\n",
      "2022-03-24 21:43:13 -     INFO -                                                         root - Annotating face, genders, and ages is done!\n",
      "2022-03-24 21:43:13 -     INFO -                                                         root - image annotation is done!\n",
      "2022-03-24 21:43:13 -     INFO -                                                         root - image saved at /home/tk/repos/cltl-chatbots/data/2022-03-24-21:41:31/image/1648154592504.png.ANNOTATED.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url http://127.0.0.1:10004\n",
      "Vu_Amsterdam: (neutral) bye\n",
      "\n",
      "Leolani2: Good bye Vu_Amsterdam!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stopped = False\n",
    "while not stopped:\n",
    "    utterance = input(\"\\n\")\n",
    "    utterance_timestamp = int(time.time() * 1e3)\n",
    "    if not utterance:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    # @TODO: also annotate the textSignal\n",
    "    # Apply some processing to the textSignal and add annotations\n",
    "    success, frame = camera.read()\n",
    "    if not success:\n",
    "        raise ValueError(\"Failed to take a picture\")\n",
    "        \n",
    "    image_time = int(time.time() * 1e3)\n",
    "    imagepath = d_util.absolute_path(scenarioStorage, scenario_id, Modality.IMAGE, f\"{image_time}.png\")\n",
    "    cv2.imwrite(imagepath, frame)\n",
    "    \n",
    "    faces = f_util.detect_faces(friends_path, imagepath)\n",
    "    \n",
    "    image_bbox = (0, 0, frame.shape[1], frame.shape[0])\n",
    "    imageSignal = d_util.create_image_signal(scenario_ctrl, f\"{image_time}.png\", image_bbox, image_time)\n",
    "    mentions = [f_util.create_face_mention(imageSignal, \"front_camera\", image_time,\n",
    "                                           parse_bbox(face), face.face_id, parse_name(face),\n",
    "                                           parse_age(face), parse_gender(face), face.det_score)\n",
    "                for face in faces]\n",
    "    imageSignal.mentions.extend(mentions)\n",
    "\n",
    "    greeting = \"\"\n",
    "    if faces and not human_id in [parse_id(face) for face in faces]:\n",
    "        response = f\"Good bye {human_name}!\"\n",
    "        print(f\"{AGENT}: {response}\\n\")\n",
    "        textSignal = d_util.create_text_signal(scenario_ctrl, response)\n",
    "        scenario_ctrl.append_signal(textSignal)\n",
    "\n",
    "        if len(faces) > 1:\n",
    "            greeting = \"Apologizes, but I will only talk to one person at a time..\"\n",
    "        else:\n",
    "            face = faces[0]\n",
    "            if parse_id(face) is None:\n",
    "                ### This is a stranger, we process the new face\n",
    "                human_id, human_name, _ = friend.get_to_know_person(scenario_ctrl, AGENT, parse_gender(face),\n",
    "                                                                    parse_age(face), face.face_id, face.embedding,\n",
    "                                                                    friends_path)\n",
    "                ### Add the new information to the signal\n",
    "                mention = f_util.create_face_mention(imageSignal, \"front_camera\", image_time,\n",
    "                                                     parse_bbox(face), human_id, human_name,\n",
    "                                                     parse_age(face), parse_gender(face), face.det_score)\n",
    "                imageSignal.mentions.append(mention)\n",
    "    \n",
    "                greeting = f\"Nice to meet you, {human_name}!\"\n",
    "            else:\n",
    "                human_id = parse_id(face)\n",
    "                human_name = parse_name(face)\n",
    "                greeting = f\"Hi {parse_name(face)}. Nice to see you again. How are you today?\"\n",
    "    else:\n",
    "        ### If no face is detected, assume it's still the same person talking\n",
    "        pass\n",
    "    \n",
    "    emotion = t_util.recognize_emotion(utterance)\n",
    "    emotion = max(emotion, key=emotion.get)\n",
    "    print(f\"{human_name}: ({emotion}) {utterance}\\n\")\n",
    "    utteranceSignal = d_util.create_text_signal(scenario_ctrl, utterance, utterance_timestamp)\n",
    "\n",
    "    if utterance.lower() == \"stop\" or utterance.lower() == \"bye\":\n",
    "        response = f\"Good bye {human_name}!\"\n",
    "        stopped = True\n",
    "    else:\n",
    "        # If there is no greeting, create a response from the system and store this as a new signal\n",
    "        # We could use the throughts to respond\n",
    "        # @TODO generate a response from the thoughts\n",
    "        response = f\"{greeting} So you what do you want to talk about {human_name}?\"\n",
    "\n",
    "    print(f\"{AGENT}: {response}\\n\")\n",
    "    responseSignal = d_util.create_text_signal(scenario_ctrl, response)\n",
    "\n",
    "    # Store signals, annotated with the infered Person information\n",
    "    scenario_ctrl.append_signal(utteranceSignal)\n",
    "    scenario_ctrl.append_signal(responseSignal)\n",
    "    scenario_ctrl.append_signal(imageSignal)\n",
    "    \n",
    "    scenarioStorage.save_scenario(scenario_ctrl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the end time of the scenario, save it and stop the containers\n",
    "\n",
    "After we stopped the interaction, we set the end time and save the scenario as EMISSOR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_ctrl.scenario.ruler.end = int(time.time() * 1e3)\n",
    "scenarioStorage.save_scenario(scenario_ctrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 21:43:18 -     INFO -                                                         root - container killed.\n",
      "2022-03-24 21:43:18 -     INFO -                                                         root - DONE!\n",
      "2022-03-24 21:43:18 -     INFO -                                                         root - container killed.\n",
      "2022-03-24 21:43:18 -     INFO -                                                         root - DONE!\n",
      "2022-03-24 21:43:19 -     INFO -                                                         root - container killed.\n",
      "2022-03-24 21:43:19 -     INFO -                                                         root - DONE!\n",
      "2022-03-24 21:43:19 -     INFO -                                                         root - container killed.\n",
      "2022-03-24 21:43:19 -     INFO -                                                         root - DONE!\n",
      "2022-03-24 21:43:20 -     INFO -                                                         root - container killed.\n",
      "2022-03-24 21:43:20 -     INFO -                                                         root - DONE!\n"
     ]
    }
   ],
   "source": [
    "## Stopping the docker containers\n",
    "## This is only needed if you started them in this notebook\n",
    "f_util.kill_container(container_fdr)\n",
    "f_util.kill_container(container_ag)\n",
    "f_util.kill_container(container_yolo)\n",
    "f_util.kill_container(container_room)\n",
    "f_util.kill_container(container_erc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Stop the camera when we are done\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b53195682b90176ba80cf6ab234538ddbed95bdb6ef2b8cf12cef7543a1f836"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
