{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uses interaction to push triples to the brain and query it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running, start GraphDB and make sure that there is a sandbox repository.\n",
    "GraphDB can be downloaded from:\n",
    "\n",
    "https://graphdb.ontotext.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piek/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/rdflib_jsonld/__init__.py:12: DeprecationWarning: The rdflib-jsonld package has been integrated into rdflib as of rdflib==6.0.1.  Please remove rdflib-jsonld from your project's dependencies.\n",
      "  DeprecationWarning,\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 8] nodename nor\n",
      "[nltk_data]     servname provided, or not known>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from random import getrandbits, choice\n",
    "import pathlib\n",
    "\n",
    "# general imports for EMISSOR and the BRAIN\n",
    "import emissor as em\n",
    "import requests\n",
    "from cltl import brain\n",
    "from cltl.brain.long_term_memory import LongTermMemory\n",
    "from cltl.brain.utils.helper_functions import brain_response_to_json\n",
    "from cltl.combot.backend.api.discrete import UtteranceType\n",
    "from cltl.reply_generation.data.sentences import GREETING, ASK_NAME, ELOQUENCE, TALK_TO_ME\n",
    "from cltl.reply_generation.lenka_replier import LenkaReplier\n",
    "from cltl.triple_extraction.api import Chat, UtteranceHypothesis\n",
    "from emissor.persistence import ScenarioStorage\n",
    "from emissor.representation.annotation import AnnotationType, Token, NER\n",
    "from emissor.representation.container import Index\n",
    "from emissor.representation.scenario import Modality, ImageSignal, TextSignal, Mention, Annotation, Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the chatbot utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "src_path = os.path.abspath(os.path.join('..'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "#### The next utils are needed for the interaction and creating triples and capsules\n",
    "import chatbots.util.driver_util as d_util\n",
    "import chatbots.util.capsule_util as c_util\n",
    "import chatbots.intentions.talk as talk\n",
    "import chatbots.intentions.get_to_know_you as friend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying the BRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We imported the brain from CLTL. We create an instance using the class *LongTermMemory*, which takes three parameters: 1) the address of the triple store, 2) a path to a folder for logging the triples and a boolean flag for clearing the repository and reload the initial ontologies.\n",
    "\n",
    "As the address of the triple store, we give the GraphDB localhost port (7200) and specify the name of the repository that we created beforehand. Any repository will do. We use here the *sandbox* repository. Note that you can also specify a remote SPARQL endpoint of another triple store or share a triple store among systems.\n",
    "\n",
    "For storing the triples generate, we define a scenario folder in a data folder relative to where the notebooks are stored. It is based on the timestamp when we start. We will use this scenario structure later for the interaction as well as we did before.\n",
    "\n",
    "Finall, if you set *clear_all* to *True*, the sandbox triple store is emptied (memory erased) and the basic ontological models are reloaded. Setting it to *False* means you add things to the current memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-10 14:03:06,916 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Uploading ontology to brain\n",
      "2021-11-10 14:03:08,690 -     INFO -   cltl.brain.basic_brain.TrustCalculator - Computed trust for all known agents\n"
     ]
    }
   ],
   "source": [
    "### The name of your scenario\n",
    "scenario_id = datetime.today().strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "\n",
    "### Specify the path to an existing data folder where your scenario is created and saved as a subfolder\n",
    "scenario_path = os.path.abspath(os.path.join('../../data'))\n",
    "if scenario_path not in sys.path:\n",
    "    sys.path.append(scenario_path)\n",
    "\n",
    "    ### Specify the path to an existing data folder where your scenario is created and saved as a subfolder\n",
    "scenario_path = os.path.abspath(os.path.join('../../data'))\n",
    "if scenario_path not in sys.path:\n",
    "    sys.path.append(scenario_path)\n",
    "\n",
    "if not os.path.exists(scenario_path) :\n",
    "    os.mkdir(scenario_path)\n",
    "    print(\"Created a data folder for storing the scenarios\", scenario_path)\n",
    "    \n",
    "rdffolder = scenario_path + \"/\" + scenario_id + \"/\" + \"rdf\"\n",
    "log_path = pathlib.Path(rdffolder)\n",
    "my_brain = brain.LongTermMemory(address=\"http://localhost:7200/repositories/sandbox\",\n",
    "                                log_dir=log_path,\n",
    "                                clear_all=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posting triples to the brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *talk.py* script in *intentions* demonstrates the basic API functions for posting and querying the BRAIN. The input of for these function is a triple in JSON format. In the next cell, we define such a triple for the subject 'Fred, the predicate 'like' and the object 'singing'. In addition to a *label* that is used to identify the resource URI in the knowledge graph, we also need to provide type information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_triple = {'subject': {'label': 'Fred', 'type': ['noun.person']},\n",
    "               'predicate': {'label': 'like', 'type': ['verb.emotion']},\n",
    "               'object': {'label': 'singing', 'type': ['noun.act']}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BRAIN uses the roboGRaSP model to capture knowledge. In roboGRaSP, we keep track of the *mentioning* of knowledge in signals. This can be either through conversation or though perception. Whenever a signal makes reference to knowledge (e.g. people, objects, properties), there is also a source of the signal and possibly a perspective.\n",
    "Sources are typically speakers with whom a system interacts but they can also be the camera or microphone of the agent that picked up a signal. Perspectives reflect the attitude and appraisal of the source towards the triple. Possible perspective values are, among others: certainty, sentiment, emotion, epistemic belief, deontic judgement, ethical judgment. Following GRaSP, the actual triple is reprsented as a claim made by the source in or through a signal and the perspective values are represented as attributions of the source.\n",
    "\n",
    "In order to deal with these GRaSP layers, we need to embed the *factual* triple within a so-called *capsule* JSON structures that provides contextual information, the source and the perspective. The following attributes are required:\n",
    "\n",
    "* The physical context is time and space: context_id, contry, region, city, place, place_id, position, date\n",
    "* The physical objects in the physical context: objects, people\n",
    "* The interactive context: chat, turn, utterance and utterance type \n",
    "* The author (source)\n",
    "* The triple: subject, predicate and object\n",
    "* The perspective\n",
    "\n",
    "Next is a capsule example, that contains the above triple embedded within the minimal contextual information:\n",
    "\n",
    "```\n",
    "{'context_id': '1',\n",
    "  'country': '',\n",
    "  'city': '',\n",
    "  'region': '',\n",
    "  'place': '',\n",
    "  'place_id': '',\n",
    "  'position': '',\n",
    "  'date': datetime.date(2021, 11, 9),\n",
    "  'objects': [],\n",
    "  'people': [],\n",
    "  'author': 'me',\n",
    "  'chat': '1',\n",
    "  'turn': '1',\n",
    "  'utterance': '',\n",
    "  'utterance_type': <UtteranceType.STATEMENT: 0>\n",
    "  'subject': {'label': 'Fred', 'type': ['agent']},\n",
    "  'predicate': {'label': 'like', 'type': ['verb.emotion']},\n",
    "  'object': {'label': 'Fred', 'type': ['noun.object']},\n",
    "  'perspective': []\n",
    "}\n",
    "```\n",
    "\n",
    "The *capsule_util.py* within util has a number of functions to create capsules. We use these functions within the different intentions that involve the brain, as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To post the above triple as a simple statement we use the *post_a_triple_and_get_thoughts* function from the *talk.py* that you find within the *intentions* module. This function takes a triple and an initialised brain as parameters and it returns the capsule that is created but also the response from the brain as a JSON structure. \n",
    "\n",
    "Posting triples to the brain is done through the *update* API function. This takes three parameters: the capsule and two boolean settings: *reason_types*  triggers linking subjects and entities to their types by consulting the semantic web, and *create_label* which triggers the system to create an additional *rdfs:label* property from the subject and object label if it is an entity. We typically set these to false, which are also the default values. Calling the update function not only stores the triple but is also followed by a series of preprogrammed SPAQRL queries that represent the *thoughts* on the changes to the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-10 17:23:48,634 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: fred_like_singing [person_->_act])\n",
      "2021-11-10 17:23:48,673 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Statement Novelty: 1 times, e.g. me on November,2021\n",
      "Capsule that provides the interactive contexts for the signal to which a triple is grouned:\n",
      "\n",
      "{'author': 'me',\n",
      " 'chat': '1',\n",
      " 'city': '',\n",
      " 'context_id': '1',\n",
      " 'country': '',\n",
      " 'date': datetime.date(2021, 11, 10),\n",
      " 'object': {'label': 'singing', 'type': ['noun.act']},\n",
      " 'objects': [],\n",
      " 'people': [],\n",
      " 'perspective': <cltl.brain.infrastructure.api.Perspective object at 0x7fd28105bad0>,\n",
      " 'place': '',\n",
      " 'place_id': '',\n",
      " 'position': '',\n",
      " 'predicate': {'type': 'like'},\n",
      " 'region': '',\n",
      " 'subject': {'label': 'Fred', 'type': ['noun.person']},\n",
      " 'triple': fred_like_singing [person_->_act]),\n",
      " 'turn': '1',\n",
      " 'type': <UtteranceType.STATEMENT: 0>,\n",
      " 'utterance': '',\n",
      " 'utterance_type': <UtteranceType.STATEMENT: 0>}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "\n",
    "capsule, throughts_json = talk.post_a_triple_and_get_thoughts(test_triple, my_brain)\n",
    "print(\"Capsule that provides the interactive contexts for the signal to which a triple is grouned:\\n\")\n",
    "pprint.pprint(capsule)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above print outs, we see the triple echoed in the capsule. After posting the triple, we could query the brain in GraphDB as is shown in the next image:\n",
    "\n",
    "![graph-db query](images/graph-db-query.png \"GraphDB query for the triple result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also caught the response of the brain to this new information, which looks as shown below. The *thoughts* element lists different possible issues: _complement_conflict,_complement_gaps, _entity_novelty, _negation_conflicts, _overlaps, _statement_novelty, _subject_gaps, trust. Since we have not added a lot of data, most elements are still empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thoughts resulting from posting the triples to the brain:\n",
      "\n",
      "{'response': '204',\n",
      " 'statement': {'author': 'me',\n",
      "               'chat': '1',\n",
      "               'city': '',\n",
      "               'context_id': '1',\n",
      "               'country': '',\n",
      "               'date': '2021-11-10',\n",
      "               'object': {'label': 'singing', 'type': ['noun.act']},\n",
      "               'objects': [],\n",
      "               'people': [],\n",
      "               'perspective': {'_certainty': 'UNDERSPECIFIED',\n",
      "                               '_emotion': 'UNDERSPECIFIED',\n",
      "                               '_polarity': 'UNDERSPECIFIED',\n",
      "                               '_sentiment': 'UNDERSPECIFIED',\n",
      "                               '_time': None},\n",
      "               'place': '',\n",
      "               'place_id': '',\n",
      "               'position': '',\n",
      "               'predicate': {'type': 'like'},\n",
      "               'region': '',\n",
      "               'subject': {'label': 'Fred', 'type': ['noun.person']},\n",
      "               'triple': {'_complement': {'_confidence': 0.0,\n",
      "                                          '_id': 'http://cltl.nl/leolani/world/singing',\n",
      "                                          '_label': 'singing',\n",
      "                                          '_offset': None,\n",
      "                                          '_types': ['act', 'Instance']},\n",
      "                          '_predicate': {'_cardinality': 1,\n",
      "                                         '_confidence': 0.0,\n",
      "                                         '_id': 'http://cltl.nl/leolani/n2mu/like',\n",
      "                                         '_label': 'like',\n",
      "                                         '_offset': None},\n",
      "                          '_subject': {'_confidence': 0.0,\n",
      "                                       '_id': 'http://cltl.nl/leolani/world/Fred',\n",
      "                                       '_label': 'fred',\n",
      "                                       '_offset': None,\n",
      "                                       '_types': ['person', 'Instance']}},\n",
      "               'turn': '1',\n",
      "               'type': 'STATEMENT',\n",
      "               'utterance': '',\n",
      "               'utterance_type': 'STATEMENT'},\n",
      " 'thoughts': {'_complement_conflict': [],\n",
      "              '_complement_gaps': {'_complement': [], '_subject': []},\n",
      "              '_entity_novelty': {'_complement': 'False', '_subject': 'False'},\n",
      "              '_negation_conflicts': [],\n",
      "              '_overlaps': {'_complement': [], '_subject': []},\n",
      "              '_statement_novelty': [{'_provenance': {'_author': 'me',\n",
      "                                                      '_date': '2021-11-10T00:00:00'}}],\n",
      "              '_subject_gaps': {'_complement': [], '_subject': []},\n",
      "              '_trust': 0.5}}\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"Thoughts resulting from posting the triples to the brain:\\n\")\n",
    "pprint.pprint(throughts_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verbalise the thoughts. we use a replier *LenkaReplier* imported from *cltl.reply_generation*. This replier randomly selects a thought and uses templates to generate a natural language phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-10 17:46:56,850 -     INFO -   cltl.reply_generation.api.LenkaReplier - Booted\n",
      "Interesting! I had never heard about singing before!\n"
     ]
    }
   ],
   "source": [
    "replier = LenkaReplier()\n",
    "reply = replier.reply_to_statement(throughts_json, proactive=True, persist=True)\n",
    "print(reply)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call the replier repititively for the same response and it may select a different thought or phrasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I just learned something, I had never heard about fred before!\n",
      "If you don't mind me asking. What types can fred like\n",
      "I just learned something, I had never heard about singing before!\n",
      "I am curious. What types can fred like\n",
      "I am curious. What types of act orInstance like singing do person orInstance usually like\n",
      "Interesting! I had never heard about singing before!\n",
      "I would like to know. What types of act orInstance like singing do person orInstance usually like\n",
      "Interesting! I had never heard about fred before!\n",
      "I have heard this before. me told me about it in 2021 11 10T00:00:00\n",
      "Exciting news! I had never heard about singing before!\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    reply = replier.reply_to_statement(throughts_json, proactive=True, persist=True)\n",
    "    print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying the brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat': '1', 'turn': '1', 'author': 'me', 'utterance': '', 'utterance_type': <UtteranceType.STATEMENT: 0>, 'position': '', 'subject': {'label': 'Fred', 'type': ['agent']}, 'predicate': {'type': 'label'}, 'object': {'label': 'Fred', 'type': ['noun.object']}, 'context_id': '1', 'date': datetime.date(2021, 11, 5), 'place': '', 'place_id': '', 'country': '', 'region': '', 'city': '', 'objects': [], 'people': []}\n",
      "2021-11-05 14:54:44,452 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: fred_label_fred [agent_->_object])\n",
      "2021-11-05 14:54:44,505 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Entity Novelty: new subject - new object \n",
      "I did not know that! I had never heard about fred before!\n"
     ]
    }
   ],
   "source": [
    "test_triple = {'predicate': {'label': 'label'}, \n",
    "               'subject': {'label': 'Fred', 'type': ['agent']}, \n",
    "               'object': {'label': 'Fred', 'type': ['noun.object']}}\n",
    "\n",
    "thoughts = talk.post_a_triple(test_triple, replier, my_brain)\n",
    "print(thoughts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat': '1', 'turn': '1', 'author': 'me', 'utterance': '', 'utterance_type': <UtteranceType.STATEMENT: 0>, 'position': '', 'subject': {'label': 'Fred', 'type': ['noun.person']}, 'predicate': {'type': 'like'}, 'object': {'label': 'singing', 'type': ['noun.act']}, 'context_id': '1', 'date': datetime.date(2021, 11, 5), 'place': '', 'place_id': '', 'country': '', 'region': '', 'city': '', 'objects': [], 'people': []}\n",
      "2021-11-05 14:55:14,251 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: fred_like_singing [person_->_act])\n",
      "2021-11-05 14:55:14,295 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Statement Novelty: 1 times, e.g. me on November,2021\n",
      "2021-11-05 14:55:14,401 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Overlaps: 0 subject overlaps: e.g. '' - 1 object overlaps: e.g. me on November,2021 about lenka\n",
      "I am curious. What kinds of things can like a singing like fred\n"
     ]
    }
   ],
   "source": [
    "test_triple = {'predicate': {'label': 'like', 'type': ['prep']}, \n",
    "               'subject': {'label': 'Fred', 'type': ['noun.person']}, \n",
    "               'object': {'label': 'singing', 'type': ['noun.act']}}\n",
    "\n",
    "thoughts = talk.post_a_triple(test_triple, replier, my_brain)\n",
    "print(thoughts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat': '1', 'turn': '1', 'author': 'me', 'utterance': '', 'utterance_type': <UtteranceType.QUESTION: 1>, 'position': '', 'subject': {'label': 'fred', 'type': ['agent']}, 'predicate': {'type': 'like'}, 'object': {'label': '', 'type': []}, 'context_id': '1', 'date': datetime.date(2021, 11, 5), 'place': '', 'place_id': '', 'country': '', 'region': '', 'city': '', 'objects': [], 'people': []}\n",
      "2021-11-05 14:55:43,863 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in question: fred_like_? [agent_->_])\n",
      "I have no idea.\n"
     ]
    }
   ],
   "source": [
    "test_triple = {'predicate': {'label': 'like', 'type': ['verb.emotion']}, \n",
    "               'subject': {'label': 'fred', 'type': ['agent']}, \n",
    "               'object': {'label': '', 'type': []}}\n",
    "answer = talk.answer_a_query(test_triple, replier, my_brain)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat': '1', 'turn': '1', 'author': 'me', 'utterance': '', 'utterance_type': <UtteranceType.QUESTION: 1>, 'position': '', 'subject': {'label': 'fred', 'type': ['agent']}, 'predicate': {'type': 'like'}, 'object': {'label': '', 'type': []}, 'context_id': '1', 'date': datetime.date(2021, 11, 5), 'place': '', 'place_id': '', 'country': '', 'region': '', 'city': '', 'objects': [], 'people': []}\n",
      "2021-11-05 14:53:02,874 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in question: fred_like_? [agent_->_])\n",
      "I don't know\n"
     ]
    }
   ],
   "source": [
    "test_triple = {'predicate': {'label': 'like', 'type': ['verb.emotion']}, \n",
    "               'subject': {'label': 'fred', 'type': ['agent']}, \n",
    "               'object': {'label': '', 'type': []}}\n",
    "answer = talk.answer_a_query(test_triple, replier, my_brain)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard initialisation of a scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  ../../data/2021-11-04-17:39:09  Created \n",
      "Directory  ../../data/2021-11-04-17:39:09/image  Created \n"
     ]
    }
   ],
   "source": [
    "from random import getrandbits\n",
    "import requests\n",
    "##### Setting the location\n",
    "place_id = getrandbits(8)\n",
    "location = requests.get(\"https://ipinfo.io\").json()\n",
    "\n",
    "##### Setting the agents\n",
    "AGENT = \"Leolani2\"\n",
    "HUMAN_NAME = \"Stranger\"\n",
    "HUMAN_ID = \"stranger\"\n",
    "\n",
    "### The name of your scenario\n",
    "scenario_id = datetime.today().strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "\n",
    "### Specify the path to an existing data folder where your scenario is created and saved as a subfolder\n",
    "scenario_path = os.path.abspath(os.path.join('../../data'))\n",
    "if scenario_path not in sys.path:\n",
    "    sys.path.append(scenario_path)\n",
    "\n",
    "    ### Specify the path to an existing data folder where your scenario is created and saved as a subfolder\n",
    "scenario_path = os.path.abspath(os.path.join('../../data'))\n",
    "if scenario_path not in sys.path:\n",
    "    sys.path.append(scenario_path)\n",
    "\n",
    "if not os.path.exists(scenario_path) :\n",
    "    os.mkdir(scenario_path)\n",
    "    print(\"Created a data folder for storing the scenarios\", scenario_path)\n",
    "\n",
    "### Define the folder where the images and rdf are saved\n",
    "imagefolder = scenario_path + \"/\" + scenario_id + \"/\" + \"image\"\n",
    "\n",
    "### Create the scenario folder, the json files and a scenarioStorage and scenario in memory\n",
    "scenarioStorage = d_util.create_scenario(scenario_path, scenario_id)\n",
    "scenario = scenarioStorage.create_scenario(scenario_id, datetime.now().microsecond, datetime.now().microsecond, AGENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: How's it going? What is your name? Piek?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Piek\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek\n",
      "Leolani2: So your name is Piek?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-05 12:00:46,926 -     INFO - cltl.triple_extraction.api.Chat (Piek_t_926000)     000 - << Start of Chat with Piek_t_926000 >>\n",
      "Leolani2: Would you like to chat? I'll do my best to keep up\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " What is your name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek: What is your name\n",
      "2021-11-05 12:01:34,222 -     INFO - cltl.triple_extraction.api.Chat (Piek_t_926000)     001 - Piek_t_926000: \"What is your name\"\n",
      "UtteranceType.QUESTION\n",
      "{'predicate': {'label': 'name-is', 'type': ['noun.communication', 'verb.stative']}, 'subject': {'label': 'leolani', 'type': ['agent']}, 'object': {'label': '', 'type': []}}\n",
      "2021-11-05 12:01:34,228 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in question: leolani_like_? [agent_->_])\n",
      "Leolani2: I wouldn't know!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6w/bw7dqbl9727c48pcjjh32r140000gn/T/ipykernel_73292/2064755983.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mutterance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'stop'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mutterance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bye'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m###### Getting the next input signals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mutterance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHUMAN_NAME\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\": \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mutterance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtextSignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_text_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutterance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1008\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m         )\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cltl-chatbots/venv/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "#### Small sequence to learn name of speaker\n",
    "initial_prompt = f\"{choice(GREETING)} {choice(ASK_NAME)} {HUMAN_NAME}?\"\n",
    "print(AGENT + \": \" + initial_prompt)\n",
    "textSignal = d_util.create_text_signal(scenario, initial_prompt)\n",
    "scenario.append_signal(textSignal)\n",
    "\n",
    "#### Get name from person \n",
    "HUMAN_NAME, HUMAN_ID = friend.get_a_name_and_id(scenario, AGENT)\n",
    "\n",
    "chat = Chat(HUMAN_ID)\n",
    "\n",
    "#### Initial prompt by the system from which we create a TextSignal and store it\n",
    "initial_prompt = f\"{choice(TALK_TO_ME)}\"\n",
    "print(AGENT + \": \" + initial_prompt)\n",
    "textSignal = d_util.create_text_signal(scenario, initial_prompt)\n",
    "scenario.append_signal(textSignal)\n",
    "\n",
    "utterance = \"\"\n",
    "#### Get input and loop\n",
    "while not (utterance.lower() == 'stop' or utterance.lower() == 'bye'):\n",
    "    ###### Getting the next input signals\n",
    "    utterance = input('\\n')\n",
    "    print(HUMAN_NAME + \": \" + utterance)\n",
    "    textSignal = d_util.create_text_signal(scenario, utterance)\n",
    "    scenario.append_signal(textSignal)\n",
    "\n",
    "    #### Process input and generate reply\n",
    "    reply = talk.process_text_and_reply_(test_triple, UtteranceType.QUESTION, scenario, place_id, location, HUMAN_ID, textSignal, chat, replier, my_brain)\n",
    "    print(AGENT + \": \" + reply)\n",
    "    textSignal = d_util.create_text_signal(scenario, reply)\n",
    "    scenario.append_signal(textSignal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'answer_a_query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6w/bw7dqbl9727c48pcjjh32r140000gn/T/ipykernel_73292/1054911370.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_triple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'predicate'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'like'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'verb.emotion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'subject'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'leolani'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'agent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'object'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer_a_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUtteranceType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUERY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'answer_a_query' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario.scenario.ruler.end = datetime.now().microsecond\n",
    "scenarioStorage.save_scenario(scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
