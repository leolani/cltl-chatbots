{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uses interaction to push triples to the brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running, start GraphDB and make sure that there is a sandbox repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/selbaez/Documents/PhD/CLTL/cltl-chatbots/venv-cltl-chatbots/lib/python3.7/site-packages/rdflib_jsonld/__init__.py:12: DeprecationWarning: The rdflib-jsonld package has been integrated into rdflib as of rdflib==6.0.1.  Please remove rdflib-jsonld from your project's dependencies.\n",
      "  DeprecationWarning,\n",
      "[nltk_data] Downloading package punkt to /Users/selbaez/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from random import getrandbits, choice\n",
    "import pathlib\n",
    "\n",
    "# general imports for EMISSOR and the BRAIN\n",
    "import emissor as em\n",
    "import requests\n",
    "from cltl import brain\n",
    "from cltl.brain.long_term_memory import LongTermMemory\n",
    "from cltl.brain.utils.helper_functions import brain_response_to_json\n",
    "from cltl.combot.backend.api.discrete import UtteranceType\n",
    "from cltl.reply_generation.data.sentences import GREETING, ASK_NAME, ELOQUENCE\n",
    "from cltl.reply_generation.lenka_replier import LenkaReplier\n",
    "from cltl.triple_extraction.api import Chat, UtteranceHypothesis\n",
    "from emissor.persistence import ScenarioStorage\n",
    "from emissor.representation.annotation import AnnotationType, Token, NER\n",
    "from emissor.representation.container import Index\n",
    "from emissor.representation.scenario import Modality, ImageSignal, TextSignal, Mention, Annotation, Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "src_path = os.path.abspath(os.path.join('..'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "#### The next utils are needed for the interaction and creating triples and capsules\n",
    "import util.driver_util as d_util\n",
    "import util.capsule_util as c_util\n",
    "import intentions.talk as talk\n",
    "import dummies.text_to_triple as ttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  ../../data/2021-11-03-15:54:12  Created \n",
      "Directory  ../../data/2021-11-03-15:54:12/image  Created \n"
     ]
    }
   ],
   "source": [
    "##### Setting the location\n",
    "place_id = getrandbits(8)\n",
    "location = requests.get(\"https://ipinfo.io\").json()\n",
    "\n",
    "##### Setting the agents\n",
    "AGENT = \"Leolani2\"\n",
    "HUMAN_NAME = \"Stranger\"\n",
    "HUMAN_ID = \"stranger\"\n",
    "\n",
    "### The name of your scenario\n",
    "scenario_id = datetime.today().strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "\n",
    "### Specify the path to an existing data folder where your scenario is created and saved as a subfolder\n",
    "scenario_path = \"../../data\"\n",
    "\n",
    "### Define the folder where the images and rdf are saved\n",
    "imagefolder = scenario_path + \"/\" + scenario_id + \"/\" + \"image\"\n",
    "rdffolder = scenario_path + \"/\" + scenario_id + \"/\" + \"rdf\"\n",
    "\n",
    "### Create the scenario folder, the json files and a scenarioStorage and scenario in memory\n",
    "scenarioStorage = d_util.create_scenario(scenario_path, scenario_id)\n",
    "scenario = scenarioStorage.create_scenario(scenario_id, datetime.now().microsecond, datetime.now().microsecond, AGENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-03 15:54:14,464 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Uploading ontology to brain\n",
      "2021-11-03 15:54:16,273 -     INFO -   cltl.brain.basic_brain.TrustCalculator - Computed trust for all known agents\n",
      "2021-11-03 15:54:16,274 -    DEBUG -   cltl.reply_generation.api.LenkaReplier - Booted\n"
     ]
    }
   ],
   "source": [
    "log_path = pathlib.Path(rdffolder)\n",
    "my_brain = brain.LongTermMemory(address=\"http://localhost:7200/repositories/sandbox\",\n",
    "                                log_dir=log_path,\n",
    "                                clear_all=True)\n",
    "replier = LenkaReplier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: Good to see you! Who are you? Stranger?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Selene\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stranger: Selene\n",
      "2021-11-03 15:54:20,392 -     INFO - cltl.triple_extraction.api.Chat (Selene)            000 - << Start of Chat with Selene >>\n",
      "Leolani2: let's chat?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " I love cats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selene: I love cats\n",
      "2021-11-03 15:54:24,996 -     INFO -               cltl.triple_extraction.api - Started POS tagger\n",
      "2021-11-03 15:54:24,997 -     INFO -               cltl.triple_extraction.api - Started NER tagger\n",
      "2021-11-03 15:54:25,003 -     INFO -               cltl.triple_extraction.api - Loaded grammar\n",
      "2021-11-03 15:54:26,072 -     INFO - cltl.triple_extraction.api.Chat (Selene)            001 -     Selene: \"I love cats\"\n",
      "2021-11-03 15:54:27,371 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: selene_love_cats [person_->_animal])\n",
      "2021-11-03 15:54:27,383 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Entity Novelty: new subject - new object \n",
      "2021-11-03 15:54:29,051 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. own object - 15 gaps as object: e.g. like-by agent\n",
      "Leolani2: I just learned something, I did not know anything that selene love\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " I eat pizza\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selene: I eat pizza\n",
      "2021-11-03 15:54:40,609 -     INFO - cltl.triple_extraction.api.Chat (Selene)            002 -     Selene: \"I eat pizza\"\n",
      "2021-11-03 15:54:40,647 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: selene_eat_pizza [person_->_food])\n",
      "2021-11-03 15:54:40,659 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Entity Novelty: existing subject - new object \n",
      "2021-11-03 15:54:42,261 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. experience smell - 15 gaps as object: e.g. like-by agent\n",
      "Leolani2: I did not know that! I did not know anybody who eat pizza\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " what do I eat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selene: what do I eat\n",
      "2021-11-03 15:55:32,360 -     INFO - cltl.triple_extraction.api.Chat (Selene)            003 -     Selene: \"what do I eat\"\n",
      "2021-11-03 15:55:32,364 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in question: Selene_eat_? [person_->_])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only join an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k1/bs53rbv901qc_hqgfx1cqm5c0000gn/T/ipykernel_42746/2752255522.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m#### Process input and generate reply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     reply = talk.process_text_and_reply_hacked(scenario, place_id, location, HUMAN_ID, textSignal, chat, replier,\n\u001b[0;32m---> 33\u001b[0;31m                                                my_brain)\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAGENT\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\": \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mtextSignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_text_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/PhD/CLTL/cltl-chatbots/src/intentions/talk.py\u001b[0m in \u001b[0;36mprocess_text_and_reply_hacked\u001b[0;34m(scenario, place_id, location, human_id, textSignal, chat, replier, my_brain)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_brain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_brain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapsule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mresponse_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrain_response_to_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreply_to_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_utterance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mUtteranceType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTATEMENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/PhD/CLTL/cltl-chatbots/venv-cltl-chatbots/lib/python3.7/site-packages/cltl/reply_generation/lenka_replier.py\u001b[0m in \u001b[0;36mreply_to_question\u001b[0;34m(self, brain_response)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m' or '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutterance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subject'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                     \u001b[0;32mand\u001b[0m \u001b[0;34m' or '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutterance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0mutterance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 say += \"I know %s usually %s %s, but I do not know this case\" % (\n",
      "\u001b[0;31mTypeError\u001b[0m: can only join an iterable"
     ]
    }
   ],
   "source": [
    "#### Small sequence to learn name of speaker\n",
    "initial_prompt = f\"{choice(GREETING)} {choice(ASK_NAME)} {HUMAN_NAME}?\"\n",
    "print(AGENT + \": \" + initial_prompt)\n",
    "textSignal = d_util.create_text_signal(scenario, initial_prompt)\n",
    "scenario.append_signal(textSignal)\n",
    "\n",
    "#### Get name from person  \n",
    "utterance = input('\\n')\n",
    "print(HUMAN_NAME + \": \" + utterance)\n",
    "textSignal = d_util.create_text_signal(scenario, utterance)\n",
    "scenario.append_signal(textSignal)\n",
    "\n",
    "HUMAN_NAME = ttt.get_your_name(utterance)\n",
    "HUMAN_ID = HUMAN_NAME\n",
    "chat = Chat(HUMAN_ID)\n",
    "\n",
    "#### Initial prompt by the system from which we create a TextSignal and store it\n",
    "initial_prompt = \"let's chat?\"\n",
    "print(AGENT + \": \" + initial_prompt)\n",
    "textSignal = d_util.create_text_signal(scenario, initial_prompt)\n",
    "scenario.append_signal(textSignal)\n",
    "\n",
    "#### Get input and loop\n",
    "while not (utterance.lower() == 'stop' or utterance.lower() == 'bye'):\n",
    "    ###### Getting the next input signals\n",
    "    utterance = input('\\n')\n",
    "    print(HUMAN_NAME + \": \" + utterance)\n",
    "    textSignal = d_util.create_text_signal(scenario, utterance)\n",
    "    scenario.append_signal(textSignal)\n",
    "\n",
    "    #### Process input and generate reply\n",
    "    reply = talk.process_text_and_reply(scenario, place_id, location, HUMAN_ID, textSignal, chat, replier, my_brain)\n",
    "    print(AGENT + \": \" + reply)\n",
    "    textSignal = d_util.create_text_signal(scenario, reply)\n",
    "    scenario.append_signal(textSignal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scenario.scenario.end = datetime.now().microsecond\n",
    "scenarioStorage.save_scenario(scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-cltl-chatbots",
   "language": "python",
   "name": "venv-cltl-chatbots"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
