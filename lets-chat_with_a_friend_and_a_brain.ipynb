{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's chat with a friend and I have a brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo chat with Leolani that combine face recognition and storage in the BRAIN.\n",
    "\n",
    "Don't forget to install emissor by `pip install .` at the root of this repo.\n",
    "Install the requirements `pip install -r requirements.txt`\n",
    "you might also have to run `python -m spacy download en`\n",
    "\n",
    "Occasionally you have to kill the docker containers if you force close the chat.\n",
    "`docker kill $(docker ps -q)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piek/Desktop/t-MA-Combots-2021/code/venv/lib/python3.7/site-packages/rdflib_jsonld/__init__.py:12: DeprecationWarning: The rdflib-jsonld package has been integrated into rdflib as of rdflib==6.0.1.  Please remove rdflib-jsonld from your project's dependencies.\n",
      "  DeprecationWarning,\n",
      "[nltk_data] Downloading package punkt to /Users/piek/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# general imports for EMISSOR and the BRAIN\n",
    "import emissor as em\n",
    "from cltl import brain\n",
    "from cltl.triple_extraction.api import Chat, UtteranceHypothesis\n",
    "from emissor.persistence import ScenarioStorage\n",
    "from emissor.representation.annotation import AnnotationType, Token, NER\n",
    "from emissor.representation.container import Index\n",
    "from emissor.representation.scenario import Modality, ImageSignal, TextSignal, Mention, Annotation, Scenario\n",
    "from cltl.brain.long_term_memory import LongTermMemory\n",
    "from cltl.combot.backend.api.discrete import UtteranceType\n",
    "\n",
    "# specific imports\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import requests\n",
    "import pickle\n",
    "\n",
    "#### The next utils are needed for the interaction and creating triples and capsules\n",
    "import util.driver_util as d_util\n",
    "import util.capsule_util as c_util\n",
    "import util.face_util as f_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Link your camera\n",
    "camera = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the BRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pathlib.PosixPath'>\n",
      "2021-10-29 10:19:18,094 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Booted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:19:18.094 DEBUG basic_brain - __init__: Booted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:19:18,095 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Clearing brain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:19:18.095 DEBUG basic_brain - clear_brain: Clearing brain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:19:20,189 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Checking if ontology is in brain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:19:20.189 DEBUG basic_brain - ontology_is_uploaded: Checking if ontology is in brain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:19:20,192 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:19:20.192 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:19:20,659 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Uploading ontology to brain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:19:20.659 INFO basic_brain - upload_ontology: Uploading ontology to brain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:19:22,639 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Booted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:19:22.639 DEBUG basic_brain - __init__: Booted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:19:22,642 -    DEBUG -  cltl.brain.basic_brain.LocationReasoner - Booted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:19:22.642 DEBUG basic_brain - __init__: Booted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:19:22,645 -    DEBUG -      cltl.brain.basic_brain.TypeReasoner - Booted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:19:22.645 DEBUG basic_brain - __init__: Booted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:19:22,648 -    DEBUG -   cltl.brain.basic_brain.TrustCalculator - Booted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:19:22.648 DEBUG basic_brain - __init__: Booted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:19:22,888 -    DEBUG -   cltl.brain.basic_brain.TrustCalculator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:19:22.888 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:19:22,934 -     INFO -   cltl.brain.basic_brain.TrustCalculator - Computed trust for all known agents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:19:22.934 INFO trust_calculator - compute_trust_network: Computed trust for all known agents\n"
     ]
    }
   ],
   "source": [
    "# Initialise the brain in GraphDB\n",
    "import pathlib\n",
    "log_path=pathlib.Path('./logs')\n",
    "print(type(log_path))\n",
    "my_brain = brain.LongTermMemory(address=\"http://localhost:7200/repositories/sandbox\",\n",
    "                           log_dir=log_path,\n",
    "                           clear_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard initialisation of a scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  ./data/2021-10-29-10:19:30  Created \n",
      "Directory  ./data/2021-10-29-10:19:30/image  Created \n"
     ]
    }
   ],
   "source": [
    "from random import getrandbits\n",
    "\n",
    "##### Setting the location\n",
    "place_id = getrandbits(8)\n",
    "location = requests.get(\"https://ipinfo.io\").json()\n",
    "\n",
    "##### Setting the agents\n",
    "AGENT = \"Leolani2\"\n",
    "HUMAN_NAME = \"Stranger\"\n",
    "HUMAN_ID = \"VOID\"\n",
    "\n",
    "### The name of your scenario\n",
    "scenario_id = datetime.today().strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "\n",
    "### Specify the path to an existing data folder where your scenario is created and saved as a subfolder\n",
    "scenario_path = \"./data\"\n",
    "\n",
    "### Define the folder where the images are saved\n",
    "imagefolder = scenario_path + \"/\" + scenario_id + \"/\" + \"image\"\n",
    "\n",
    "\n",
    "### Create the scenario folder, the json files and a scenarioStorage and scenario in memory\n",
    "scenarioStorage = d_util.create_scenario(scenario_path, scenario_id)\n",
    "scenario = scenarioStorage.create_scenario(scenario_id, datetime.now().microsecond, datetime.now().microsecond, AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the docker containers for face detection and face property detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the docker images are running you can skip the next part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You only need to load the dockers once. The first time you load the docker, the images will be donwloaded from the DockerHub. This may take a few minutes depending on the speed of the internet connection. The images are cached in your local Docker installation.\n",
    "\n",
    "One the images are in your local Docker, they are loaded instantaniously. Once the docker is started you do not need to start it again and you can skip the next commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#container_fdr = f_util.start_docker_container(\"tae898/face-detection-recognition:v0.1\", 10002)\n",
    "#container_ag = f_util.start_docker_container(\"tae898/age-gender:v0.2\", 10003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is a problem starting the dockers, you may need to kill them and start them again. Use the following command to kill and rerun the previous command. Note that if there are running already you should not restart. Starting it again gives an error that the port is occupied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!docker kill $(docker ps -q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting and storing triples from an utterance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function processes any textSignal using the baseline language model from the Leolani platform.\n",
    "This model uses a context-free grammar and closed-class lexicons specifically designed for social robot interaction.\n",
    "\n",
    "The function creates a capsule for posting any triples and perspective to the BRAIN.\n",
    "If no triples are extracted, a dummy prompt is returned: \"Any gossip?\".\n",
    "\n",
    "Any thoughts coming from the BRAIN are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_and_think (scenario: Scenario, \n",
    "                  place_id:str, \n",
    "                  location: str, \n",
    "                  textSignal: TextSignal,\n",
    "                  human_id: str,\n",
    "                  my_brain:LongTermMemory):\n",
    "    thoughts = \"\"\n",
    "    chat = Chat(human_id)\n",
    "    chat.add_utterance([UtteranceHypothesis(c_util.seq_to_text(textSignal.seq), 1.0)])\n",
    "    chat.last_utterance.analyze()\n",
    "    # No triple was extracted, so we missed three items (s, p, o)\n",
    "    if chat.last_utterance.triple is None:\n",
    "        utterance = \"Any gossip?\" + '\\n'\n",
    "    else:\n",
    "        triple = c_util.rephrase_triple_json_for_capsule(chat.last_utterance.triple)\n",
    "        # A triple was extracted so we compare it elementwise\n",
    "        capsule = c_util.scenario_utterance_and_triple_to_capsule(scenario, \n",
    "                                                                  place_id,\n",
    "                                                                  location,\n",
    "                                                                  textSignal, \n",
    "                                                                  human_id,\n",
    "                                                                  chat.last_utterance.perspective, \n",
    "                                                                  triple)\n",
    "        print('Capsule:', capsule)\n",
    "        thoughts = my_brain.update(capsule, reason_types=True)\n",
    "        #print(thoughts)\n",
    "    return thoughts    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new friend.\n",
    "\n",
    "The next functions are needed to get the properties and visual information for identifying a new friend.\n",
    "The visual information is based on the camera images of the uses from which we extract an averaged embedding.\n",
    "These embeddings are store in the *friend_embeddings* folder. \n",
    "\n",
    "By comparing an image with the stored embeddings, the system decides whether a person is a *stranger*.\n",
    "In case the user is a *stranger*, the system will try to get to know him/her.\n",
    "\n",
    "If you delete someone's embeddings from the *friend_embeddings* folder. This person will become a *stranger* again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function that creates capsules for the basic properties of a friend: name, age and gender.\n",
    "### The capsules are sent to the BRAIN. Thoughts are caught and returned for each property.\n",
    "\n",
    "def process_new_friend_and_think (scenario: Scenario, \n",
    "                  place_id:str, \n",
    "                  location: str, \n",
    "                  human_id: str,\n",
    "                  textSignal: TextSignal,\n",
    "                  imageSignal: ImageSignal,\n",
    "                  age: str,\n",
    "                  gender: str,\n",
    "                  human_name: str,\n",
    "                  my_brain:LongTermMemory):\n",
    "    age_thoughts = \"\"\n",
    "    gender_thoughts = \"\"\n",
    "    name_thoughts = \"\"\n",
    "\n",
    "\n",
    "    if human_name:\n",
    "        # A triple was extracted so we compare it elementwise\n",
    "        perspective = {\"certainty\": 1, \"polarity\": 1, \"sentiment\": 1}\n",
    "        capsule = c_util.scenario_utterance_to_capsule(scenario, \n",
    "                                                                  place_id,\n",
    "                                                                  location,\n",
    "                                                                  textSignal,\n",
    "                                                                  human_id,\n",
    "                                                                  perspective,\n",
    "                                                                  human_id,\n",
    "                                                                  \"label\",\n",
    "                                                                  human_name)\n",
    "\n",
    "        name_thoughts = my_brain.update(capsule, reason_types=True)\n",
    "        print('Name capsule:', capsule)\n",
    "\n",
    "\n",
    "    if age:\n",
    "        # A triple was extracted so we compare it elementwise\n",
    "        capsule = c_util.scenario_image_triple_to_capsule(scenario, \n",
    "                                                                  place_id,\n",
    "                                                                  location,\n",
    "                                                                  imageSignal,\n",
    "                                                                  \"front_camera\", \n",
    "                                                                  human_id,\n",
    "                                                                  \"age\",\n",
    "                                                                  str(age))\n",
    "\n",
    "        age_thoughts = my_brain.update(capsule, reason_types=True)\n",
    "        print('Age capsule:', capsule)\n",
    "\n",
    "    if gender:\n",
    "        capsule = c_util.scenario_image_triple_to_capsule(scenario, \n",
    "                                                                  place_id,\n",
    "                                                                  location,\n",
    "                                                                  imageSignal,\n",
    "                                                                  \"front_camera\", \n",
    "                                                                  human_id,\n",
    "                                                                  \"gender\",\n",
    "                                                                  gender)\n",
    "\n",
    "        gender_thoughts = my_brain.update(capsule, reason_types=True)\n",
    "        print('Gender capsule:', capsule)\n",
    "\n",
    "    return name_thoughts, age_thoughts, gender_thoughts    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function that tries to get the name for a new person. A while is used till the user is happy.\n",
    "### From the name a unique ID *human_id* is created by adding the time_stamp\n",
    "### We store the face embeddings in the friend_embeddings folder using the unique ID *human_id*\n",
    "### The function returns the human_name and the human_id.\n",
    "### Human_name is used to address the user, and human_id is used to store properties of the user\n",
    "\n",
    "def get_to_know_person(scenario: Scenario, agent:str, gender:str, age: str, uuid_name: str, embedding):\n",
    "        ### This is a stranger\n",
    "        ### We create the agent response and store it as a text signal\n",
    "        human_name = \"Stranger\"\n",
    "        response = (\n",
    "            f\"Hi there. We haven't met. I only know that \\n\"\n",
    "            f\"your estimated age is {age} \\n and that your estimated gender is \"\n",
    "            f\"{gender}. What's your name?\"\n",
    "        )\n",
    "        print(f\"{agent}: {response}\")\n",
    "        textSignal = d_util.create_text_signal(scenario, response)\n",
    "        scenario.append_signal(textSignal)\n",
    "        \n",
    "        confirm = \"\"\n",
    "        while confirm.lower().find(\"yes\")==-1:\n",
    "            ### We take the response from the user and store it as a text signal\n",
    "            utterance = input(\"\\n\")\n",
    "            textSignal = d_util.create_text_signal(scenario, utterance)\n",
    "            scenario.append_signal(textSignal)\n",
    "            print(utterance)\n",
    "            #### We hack the response to find the name of our new fiend\n",
    "            #### This name needs to be set in the scenario and assigned to the global variable human\n",
    "            human_name = \" \".join([foo.title() for foo in utterance.strip().split()])\n",
    "            human_name = \"_\".join(human_name.split())\n",
    "        \n",
    "            response = (f\"So your name is {human_name}?\")\n",
    "            print(f\"{agent}: {response}\")\n",
    "            textSignal = d_util.create_text_signal(scenario, response)\n",
    "            scenario.append_signal(textSignal)\n",
    "            \n",
    "            ### We take the response from the user and store it as a text signal\n",
    "            confirm = input(\"\\n\")\n",
    "            textSignal = d_util.create_text_signal(scenario, confirm)\n",
    "            scenario.append_signal(textSignal)\n",
    "\n",
    "\n",
    "        current_time = str(datetime.now().microsecond)\n",
    "        human_id = human_name+\"_t_\"+current_time\n",
    "        #### We create the embedding\n",
    "        to_save = {\"uuid\": uuid_name[\"uuid\"], \"embedding\": embedding}\n",
    "\n",
    "        with open(f\"./friend_embeddings/{human_id}.pkl\", \"wb\") as stream:\n",
    "            pickle.dump(to_save, stream)\n",
    "            \n",
    "        return human_id, human_name, textSignal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Friends of Leolani are saved in the embeddings folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:02.438 INFO face_util - load_binary_image: ./data/2021-10-29-10:19:30/image/403344.png image loaded!\n",
      "2021-10-29 10:23:03.193 INFO face_util - run_face_api: got <Response [200]> from server!...\n",
      "2021-10-29 10:23:03.195 INFO face_util - run_face_api: 1 faces deteced!\n",
      "2021-10-29 10:23:03.197 INFO face_util - face_recognition: new face!\n",
      "2021-10-29 10:23:03.241 INFO face_util - run_age_gender_api: got <Response [200]> from server!...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: Hi there. We haven't met. I only know that \n",
      "your estimated age is 52 \n",
      " and that your estimated gender is male. What's your name?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Piek\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek\n",
      "Leolani2: So your name is Piek?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:09,229 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:09.229 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:09,236 -    DEBUG -  cltl.brain.basic_brain.LocationReasoner - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:09.236 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:09,252 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: piek-t-191694_label_piek [person_->_object])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:09.252 INFO LTM_statement_processing - model_graphs: Triple in statement: piek-t-191694_label_piek [person_->_object])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:09,254 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:09.254 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:09,286 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:09.286 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:09,293 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:09.293 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:09,336 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Entity Novelty: new subject - new object \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:09.336 INFO thought_generator - fill_entity_novelty: Entity Novelty: new subject - new object \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:09,338 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:09.338 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:09,345 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:09.345 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:10,222 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting triples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:10.222 DEBUG basic_brain - _upload_to_brain: Posting triples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11,189 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11.189 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11,237 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Negation Conflicts: piek-t-191694 on October,2021 about POSITIVE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11.237 INFO thought_generator - get_negation_conflicts: Negation Conflicts: piek-t-191694 on October,2021 about POSITIVE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11,240 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11.240 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11,287 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11.287 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11,294 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. like-by agent - 15 gaps as object: e.g. be-friends-with person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11.294 INFO thought_generator - get_entity_gaps: Gaps: 26 gaps as subject: e.g. like-by agent - 15 gaps as object: e.g. be-friends-with person\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11,296 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11.296 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11,337 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11.337 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11,344 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 0 gaps as subject: e.g. '' - 2 gaps as object: e.g. own person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11.344 INFO thought_generator - get_entity_gaps: Gaps: 0 gaps as subject: e.g. '' - 2 gaps as object: e.g. own person\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11,346 -    DEBUG -   cltl.brain.basic_brain.TrustCalculator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11.346 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name capsule: {'chat': '2021-10-29-10:19:30', 'turn': '10e166fc-c5f2-4997-a07e-07909f96515c', 'author': 'piek-t-191694', 'utterance': 'yes', 'utterance_type': <UtteranceType.STATEMENT: 0>, 'position': '0-3', 'subject': {'label': 'Piek_t_191694', 'type': 'person'}, 'predicate': {'type': 'label'}, 'object': {'label': 'Piek', 'type': 'object'}, 'perspective': <cltl.brain.infrastructure.api.Perspective object at 0x7ff4d8c64c90>, 'context_id': 'Leolani2', 'date': datetime.date(2021, 10, 29), 'place': 'Amsterdam', 'place_id': 141, 'country': 'NL', 'region': 'North Holland', 'city': 'Amsterdam', 'objects': [{'type': 'chair', 'confidence': 0.59, 'id': 1}, {'type': 'table', 'confidence': 0.73, 'id': 1}, {'type': 'pillbox', 'confidence': 0.32, 'id': 1}], 'people': [{'name': 'Piek_t_191694', 'confidence': 0.98, 'id': 1}], 'triple': piek-t-191694_label_piek [person_->_object]), 'type': <UtteranceType.STATEMENT: 0>}\n",
      "2021-10-29 10:23:11,389 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11.389 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11,396 -    DEBUG -  cltl.brain.basic_brain.LocationReasoner - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11.396 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11,450 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: piek-t-191694_age_52 [person_->_string])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11.450 INFO LTM_statement_processing - model_graphs: Triple in statement: piek-t-191694_age_52 [person_->_string])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11,451 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11.451 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11,486 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11.486 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11,491 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11.491 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11,534 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Entity Novelty: existing subject - new object \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11.534 INFO thought_generator - fill_entity_novelty: Entity Novelty: existing subject - new object \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11,536 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11.536 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11,542 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:11.542 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:12,492 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting triples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:12.492 DEBUG basic_brain - _upload_to_brain: Posting triples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13,288 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13.288 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13,334 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Negation Conflicts: front-camera on October,2021 about POSITIVE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13.334 INFO thought_generator - get_negation_conflicts: Negation Conflicts: front-camera on October,2021 about POSITIVE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13,336 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13.336 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13,346 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13.346 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13,387 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. own object - 15 gaps as object: e.g. cook-by food\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13.387 INFO thought_generator - get_entity_gaps: Gaps: 26 gaps as subject: e.g. own object - 15 gaps as object: e.g. cook-by food\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13,389 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13.389 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13,395 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13.395 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13,437 -    DEBUG -   cltl.brain.basic_brain.TrustCalculator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13.437 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age capsule: {'chat': '2021-10-29-10:19:30', 'turn': 'fb8bda90-4de8-4ce1-9ba8-be94e27240fb', 'author': 'front-camera', 'utterance': '', 'position': 'image', 'perspective': <cltl.brain.infrastructure.api.Perspective object at 0x7ff4f8f76fd0>, 'subject': {'label': 'Piek_t_191694', 'type': 'person'}, 'predicate': {'type': 'age'}, 'object': {'label': '52', 'type': 'string'}, 'context_id': 'Leolani2', 'date': datetime.date(2021, 10, 29), 'place': 'Amsterdam', 'place_id': 141, 'country': 'NL', 'region': 'North Holland', 'city': 'Amsterdam', 'objects': [{'type': 'chair', 'confidence': 0.59, 'id': 1}, {'type': 'table', 'confidence': 0.73, 'id': 1}, {'type': 'pillbox', 'confidence': 0.32, 'id': 1}], 'people': [{'name': 'front_camera', 'confidence': 0.98, 'id': 1}], 'triple': piek-t-191694_age_52 [person_->_string]), 'type': <UtteranceType.STATEMENT: 0>}\n",
      "2021-10-29 10:23:13,447 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13.447 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13,486 -    DEBUG -  cltl.brain.basic_brain.LocationReasoner - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13.486 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13,503 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: piek-t-191694_gender_male [person_->_string])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13.503 INFO LTM_statement_processing - model_graphs: Triple in statement: piek-t-191694_gender_male [person_->_string])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13,505 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13.505 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13,536 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13.536 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13,543 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13.543 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13,585 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Entity Novelty: existing subject - new object \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13.585 INFO thought_generator - fill_entity_novelty: Entity Novelty: existing subject - new object \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13,587 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13.587 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13,595 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:13.595 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:14,498 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting triples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:14.498 DEBUG basic_brain - _upload_to_brain: Posting triples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:15,438 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:15.438 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:15,484 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Negation Conflicts: front-camera on October,2021 about POSITIVE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:15.484 INFO thought_generator - get_negation_conflicts: Negation Conflicts: front-camera on October,2021 about POSITIVE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:15,486 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:15.486 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:15,497 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:15.497 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:15,539 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. be-family-of person - 15 gaps as object: e.g. write-by book\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:15.539 INFO thought_generator - get_entity_gaps: Gaps: 26 gaps as subject: e.g. be-family-of person - 15 gaps as object: e.g. write-by book\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:15,540 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:15.540 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:15,545 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:15.545 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:15,586 -    DEBUG -   cltl.brain.basic_brain.TrustCalculator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:15.586 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender capsule: {'chat': '2021-10-29-10:19:30', 'turn': 'fb8bda90-4de8-4ce1-9ba8-be94e27240fb', 'author': 'front-camera', 'utterance': '', 'position': 'image', 'perspective': <cltl.brain.infrastructure.api.Perspective object at 0x7ff4b835eb90>, 'subject': {'label': 'Piek_t_191694', 'type': 'person'}, 'predicate': {'type': 'gender'}, 'object': {'label': 'male', 'type': 'string'}, 'context_id': 'Leolani2', 'date': datetime.date(2021, 10, 29), 'place': 'Amsterdam', 'place_id': 141, 'country': 'NL', 'region': 'North Holland', 'city': 'Amsterdam', 'objects': [{'type': 'chair', 'confidence': 0.59, 'id': 1}, {'type': 'table', 'confidence': 0.73, 'id': 1}, {'type': 'pillbox', 'confidence': 0.32, 'id': 1}], 'people': [{'name': 'front_camera', 'confidence': 0.98, 'id': 1}], 'triple': piek-t-191694_gender_male [person_->_string]), 'type': <UtteranceType.STATEMENT: 0>}\n",
      "Leolani2: Nice to meet you, Piek\n"
     ]
    }
   ],
   "source": [
    "#First step is to identify the speaker\n",
    "\n",
    "imagepath = \"\"\n",
    "uuid_name = \"\"\n",
    "# First signal\n",
    "success, frame = camera.read()\n",
    "\n",
    "if success:\n",
    "    ### check if we know the human\n",
    "    current_time = str(datetime.now().microsecond)\n",
    "    imagepath = imagefolder + \"/\" + current_time + \".png\"\n",
    "    cv2.imwrite(imagepath, frame)\n",
    "    imageSignal = d_util.create_image_signal(scenario, imagepath)\n",
    "    (\n",
    "        genders,\n",
    "        ages,\n",
    "        bboxes,\n",
    "        faces_detected,\n",
    "        det_scores,embeddings,\n",
    "    ) = f_util.do_stuff_with_image(imagepath)\n",
    "\n",
    "    # Here we assume that only one face is in the image\n",
    "    # TODO: deal with multiple people.\n",
    "    for k, (gender, age, bbox, uuid_name, faceprob, embedding) in enumerate(\n",
    "        zip(genders, ages, bboxes, faces_detected, det_scores, embeddings)\n",
    "    ):\n",
    "        age = round(age[\"mean\"])\n",
    "        gender = \"male\" if gender[\"m\"] > 0.5 else \"female\"\n",
    "        bbox = [int(num) for num in bbox.tolist()]\n",
    "    assert k == 0\n",
    "    if uuid_name[\"name\"] is None:\n",
    "        ### This is a stranger\n",
    "        ### We call the get_to_know function to create the data for a new friend\n",
    "        HUMAN_ID, HUMAN_NAME, textSignal = get_to_know_person(scenario, AGENT, gender, age, uuid_name, embedding)\n",
    "        ### We store the data in the BRAIN for the human_id that is returned            \n",
    "        name_thoughts, age_thoughts, gender_thoughts = process_new_friend_and_think (scenario, \n",
    "                  place_id, \n",
    "                  location, \n",
    "                  HUMAN_ID,\n",
    "                  textSignal,\n",
    "                  imageSignal,\n",
    "                  age,\n",
    "                  gender,\n",
    "                  HUMAN_NAME,\n",
    "                  my_brain)\n",
    "        \n",
    "        ### The system responds to the processing of the new name input and stores it as a textsignal\n",
    "        print(AGENT + f\": Nice to meet you, {HUMAN_NAME}\")\n",
    "        response = f\": Nice to meet you, {HUMAN_NAME}\"\n",
    "        textSignal = d_util.create_text_signal(scenario, response)\n",
    "        scenario.append_signal(textSignal)\n",
    "\n",
    "    else:\n",
    "        ### We know this person\n",
    "        HUMAN_ID= uuid_name['name']\n",
    "        HUMAN_NAME = HUMAN_ID.split(\"_t_\")[0]\n",
    "        response = f\"Hi {HUMAN_NAME}. Nice to see you again :)\"\n",
    "        print(f\"{AGENT}: {response}\")\n",
    "        textSignal = d_util.create_text_signal(scenario, response)\n",
    "        scenario.append_signal(textSignal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceed to communicate with an identified friend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next while loop is for continuous communication with the identified user until *stop* or *bye*.\n",
    "We process the user input and the captured image sequentially step by setp in the code block of the while loop.\n",
    "At the end of the code block, a response is generated and new input from the user is requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: How are you doing Piek\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " I am great.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek: I am great.\n",
      "2021-10-29 10:23:32,112 -     INFO - cltl.triple_extraction.api.Chat (Piek_t_191694)     000 - << Start of Chat with Piek_t_191694 >>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:32.112 INFO api - __init__: << Start of Chat with Piek_t_191694 >>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:32,114 -     INFO -               cltl.triple_extraction.api - Started POS tagger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:32.114 INFO api - __init__: Started POS tagger\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:32,116 -     INFO -               cltl.triple_extraction.api - Started NER tagger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:32.129 INFO ner - _start_server: Started NER server\n",
      "2021-10-29 10:23:32.116 INFO api - __init__: Started NER tagger\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:32,133 -     INFO -               cltl.triple_extraction.api - Loaded grammar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:32.133 INFO api - __init__: Loaded grammar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:33,274 -     INFO - cltl.triple_extraction.api.Chat (Piek_t_191694)     001 - Piek_t_191694: \"I am great.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:33.274 INFO api - add_utterance: Piek_t_191694: \"I am great.\"\n",
      "2021-10-29 10:23:33.288 INFO ner - _start_server: Started NER server\n",
      "2021-10-29 10:23:34.670 INFO analyzer - __init__: extracted perspective: {'sentiment': 0, 'certainty': 1, 'polarity': 1, 'emotion': <Emotion.NEUTRAL: 7>}\n",
      "2021-10-29 10:23:34.674 INFO api - analyze: RDF    subject: {\"label\": \"Piek_t_191694\", \"type\": [\"agent\"]}\n",
      "2021-10-29 10:23:34.675 INFO api - analyze: RDF  predicate: {\"label\": \"be\", \"type\": [\"verb.stative\"]}\n",
      "2021-10-29 10:23:34.675 INFO api - analyze: RDF     object: {\"label\": \"great.\", \"type\": [\"agent\"]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subject': {'label': 'Piek_t_191694', 'type': ['agent']}, 'predicate': {'label': 'be', 'type': ['verb.stative']}, 'object': {'label': 'great.', 'type': ['agent']}}\n",
      "{'subject': {'Piek_t_191694', 'agent'}, 'predicate': {'be', 'stative'}, 'object': {'agent', 'great.'}}\n",
      "Capsule: {'chat': '2021-10-29-10:19:30', 'turn': '1dac8d02-0844-4c9e-9b7a-ba7c4e83c543', 'author': 'Piek_t_191694', 'utterance': 'I am great.', 'utterance_type': <UtteranceType.STATEMENT: 0>, 'position': '0-11', 'subject': {'label': 'piek', 'type': 'person'}, 'predicate': {'type': 'see'}, 'object': {'label': 'pills', 'type': 'object'}, 'perspective': {'sentiment': 0, 'certainty': 1, 'polarity': 1, 'emotion': <Emotion.NEUTRAL: 7>}, 'context_id': 'Leolani2', 'date': datetime.date(2021, 10, 29), 'place': 'Amsterdam', 'place_id': 141, 'country': 'NL', 'region': 'North Holland', 'city': 'Amsterdam', 'objects': [{'type': 'chair', 'confidence': 0.59, 'id': 1}, {'type': 'table', 'confidence': 0.73, 'id': 1}, {'type': 'pillbox', 'confidence': 0.32, 'id': 1}], 'people': [{'name': 'Piek_t_191694', 'confidence': 0.98, 'id': 1}]}\n",
      "2021-10-29 10:23:34,681 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:34.681 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:34,687 -    DEBUG -  cltl.brain.basic_brain.LocationReasoner - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:34.687 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:34,705 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: piek_see_pills [person_->_object])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:34.705 INFO LTM_statement_processing - model_graphs: Triple in statement: piek_see_pills [person_->_object])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:34,706 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:34.706 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:34,735 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:34.735 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:34,741 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:34.741 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:34,785 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Entity Novelty: new subject - new object \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:34.785 INFO thought_generator - fill_entity_novelty: Entity Novelty: new subject - new object \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:34,787 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:34.787 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:34,794 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:34.794 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:35,685 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting triples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:35.685 DEBUG basic_brain - _upload_to_brain: Posting triples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:36,787 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:36.787 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:36,794 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Negation Conflicts: piek-t-191694 on October,2021 about POSITIVE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:36.794 INFO thought_generator - get_negation_conflicts: Negation Conflicts: piek-t-191694 on October,2021 about POSITIVE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:36,796 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:36.796 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:36,838 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:36.838 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:36,894 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. be-family-of person - 17 gaps as object: e.g. read-by book\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:36.894 INFO thought_generator - get_entity_gaps: Gaps: 26 gaps as subject: e.g. be-family-of person - 17 gaps as object: e.g. read-by book\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:36,896 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:36.896 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:36,936 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:36.936 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:36,941 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 0 gaps as subject: e.g. '' - 2 gaps as object: e.g. own agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:36.941 INFO thought_generator - get_entity_gaps: Gaps: 0 gaps as subject: e.g. '' - 2 gaps as object: e.g. own agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:36,943 -    DEBUG -   cltl.brain.basic_brain.TrustCalculator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:36.943 DEBUG basic_brain - _submit_query: Posting query\n",
      "2021-10-29 10:23:37.047 INFO face_util - load_binary_image: ./data/2021-10-29-10:19:30/image/12736.png image loaded!\n",
      "2021-10-29 10:23:37.779 INFO face_util - run_face_api: got <Response [200]> from server!...\n",
      "2021-10-29 10:23:37.780 INFO face_util - run_face_api: 1 faces deteced!\n",
      "2021-10-29 10:23:37.831 INFO face_util - run_age_gender_api: got <Response [200]> from server!...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: So you what do you want to talk about Piek\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Universe and about you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:46,634 -     INFO - cltl.triple_extraction.api.Chat (Piek_t_191694)     000 - << Start of Chat with Piek_t_191694 >>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:46.634 INFO api - __init__: << Start of Chat with Piek_t_191694 >>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:47,475 -     INFO - cltl.triple_extraction.api.Chat (Piek_t_191694)     001 - Piek_t_191694: \"Universe and about you\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 10:23:47.475 INFO api - add_utterance: Piek_t_191694: \"Universe and about you\"\n",
      "2021-10-29 10:23:47.477 WARNING analyzer - analyze: Couldn't parse input\n",
      "2021-10-29 10:23:47.543 INFO face_util - load_binary_image: ./data/2021-10-29-10:19:30/image/510434.png image loaded!\n",
      "2021-10-29 10:23:48.296 INFO face_util - run_face_api: got <Response [200]> from server!...\n",
      "2021-10-29 10:23:48.297 INFO face_util - run_face_api: 1 faces deteced!\n",
      "2021-10-29 10:23:48.342 INFO face_util - run_age_gender_api: got <Response [200]> from server!...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: So you what do you want to talk about Piek\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " stop\n"
     ]
    }
   ],
   "source": [
    "### First prompt\n",
    "response = \"How are you doing \"+HUMAN_NAME\n",
    "textSignal = d_util.create_text_signal(scenario, response)\n",
    "scenario.append_signal(textSignal)\n",
    "\n",
    "print(AGENT + \": \" + response)\n",
    "\n",
    "#### Get the input from the user\n",
    "utterance = input(\"\\n\")\n",
    "print(HUMAN_NAME + \": \" + utterance)\n",
    "\n",
    "while not (utterance.lower() == \"stop\" or utterance.lower() == \"bye\"):\n",
    "    textSignal = d_util.create_text_signal(scenario, utterance)\n",
    "    scenario.append_signal(textSignal)\n",
    "\n",
    "    # @TODO: also annotate the textSignal\n",
    "    # Apply some processing to the textSignal and add annotations\n",
    "        \n",
    "    # We process the utterance and store triples in the brain\n",
    "    # We catch the thoughts as the response\n",
    "    thoughts = process_text_and_think (scenario, \n",
    "                  place_id, \n",
    "                  location, \n",
    "                  textSignal, \n",
    "                  HUMAN_ID, my_brain)\n",
    "        \n",
    "    ## We capture the image again\n",
    "    ## For now, we only take pictures of faces of the user\n",
    "    ## @TODO add object recognition and check if there are other people detected than the user\n",
    "   \n",
    "    success, frame = camera.read()\n",
    "    if success:\n",
    "        current_time = str(datetime.now().microsecond)\n",
    "        imagepath = imagefolder + \"/\" + current_time + \".png\"\n",
    "        cv2.imwrite(imagepath, frame)\n",
    "        (\n",
    "            genders,\n",
    "            ages,\n",
    "            bboxes,\n",
    "            faces_detected,\n",
    "            det_scores,\n",
    "            embeddings,\n",
    "        ) = f_util.do_stuff_with_image(imagepath)\n",
    "\n",
    "\n",
    "\n",
    "    if success:\n",
    "        imageSignal = d_util.create_image_signal(scenario, imagepath)\n",
    "        container_id = str(uuid.uuid4())\n",
    "\n",
    "        #### Properties are now stored as annotations\n",
    "        #### We do not store these proeprties again to the BRAIN\n",
    "        for gender, age, bbox, name, faceprob in zip(\n",
    "            genders, ages, bboxes, faces_detected, det_scores\n",
    "        ):\n",
    "\n",
    "            age = round(age[\"mean\"])\n",
    "            gender = \"male\" if gender[\"m\"] > 0.5 else \"female\"\n",
    "            bbox = [int(num) for num in bbox.tolist()]\n",
    "\n",
    "        f_util.add_face_annotation(imageSignal,container_id, \"front_camera\", container_id, current_time,\n",
    "                                        bbox,HUMAN_ID,HUMAN_NAME, age, gender,faceprob)\n",
    "                                   \n",
    "        scenario.append_signal(imageSignal)\n",
    "\n",
    "    # Create the response from the system and store this as a new signal\n",
    "    # We could use the throughts to respond\n",
    "    # @TODO generate a response from the thoughts or based on the user query\n",
    "\n",
    "    utterance = \"So you what do you want to talk about \" + HUMAN_NAME + \"\\n\"\n",
    "    response = utterance[::-1]\n",
    "    print(AGENT + \": \" + utterance)\n",
    "    textSignal = d_util.create_text_signal(scenario, utterance)\n",
    "    scenario.append_signal(textSignal)\n",
    "\n",
    "    # Getting the next input signals\n",
    "    utterance = input(\"\\n\")\n",
    "\n",
    "    ### We now have a new input check if the user wants to continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the end time of the scenario, save it and stop the containers\n",
    "\n",
    "After we stopped the interaction, we set the end time and save the scenario as EMISSOR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scenario.scenario.end = datetime.now().microsecond\n",
    "scenarioStorage.save_scenario(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stopping the docker containers\n",
    "### This is only needed of you started them in this notebook\n",
    "\n",
    "#f_util.kill_container(container_fdr)\n",
    "#f_util.kill_container(container_ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Stop the camera when we are done\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
