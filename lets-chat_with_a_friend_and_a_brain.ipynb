{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's chat with a friend and I have a brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo chat with Leolani that combine face recognition and storage in the BRAIN.\n",
    "\n",
    "Don't forget to install emissor by `pip install .` at the root of this repo.\n",
    "Install the requirements `pip install -r requirements.txt`\n",
    "you might also have to run `python -m spacy download en`\n",
    "\n",
    "Occasionally you have to kill the docker containers if you force close the chat.\n",
    "`docker kill $(docker ps -q)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piek/Desktop/t-MA-Combots-2021/code/venv/lib/python3.7/site-packages/rdflib_jsonld/__init__.py:12: DeprecationWarning: The rdflib-jsonld package has been integrated into rdflib as of rdflib==6.0.1.  Please remove rdflib-jsonld from your project's dependencies.\n",
      "  DeprecationWarning,\n",
      "[nltk_data] Downloading package punkt to /Users/piek/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import emissor as em\n",
    "from cltl import brain\n",
    "from cltl.triple_extraction.api import Chat, UtteranceHypothesis\n",
    "from emissor.persistence import ScenarioStorage\n",
    "from emissor.representation.annotation import AnnotationType, Token, NER\n",
    "from emissor.representation.container import Index\n",
    "from emissor.representation.scenario import (\n",
    "    Modality,\n",
    "    ImageSignal,\n",
    "    TextSignal,\n",
    "    Mention,\n",
    "    Annotation,\n",
    "    Scenario,\n",
    ")\n",
    "from emissor.representation.scenario import Modality, ImageSignal, TextSignal, Mention, Annotation, Scenario\n",
    "from cltl.brain.long_term_memory import LongTermMemory\n",
    "from cltl.combot.backend.api.discrete import UtteranceType\n",
    "\n",
    "\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import requests\n",
    "import pickle\n",
    "\n",
    "#### The next utils are needed for the interaction and creating triples and capsules\n",
    "import util.driver_util as d_util\n",
    "import util.capsule_util as c_util\n",
    "import util.face_util as f_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Link your camera\n",
    "camera = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pathlib.PosixPath'>\n",
      "2021-10-28 22:45:23,831 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Booted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:23.831 DEBUG basic_brain - __init__: Booted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:23,832 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Clearing brain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:23.832 DEBUG basic_brain - clear_brain: Clearing brain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:24,538 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Checking if ontology is in brain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:24.538 DEBUG basic_brain - ontology_is_uploaded: Checking if ontology is in brain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:24,541 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:24.541 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:24,955 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Uploading ontology to brain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:24.955 INFO basic_brain - upload_ontology: Uploading ontology to brain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:26,276 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Booted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:26.276 DEBUG basic_brain - __init__: Booted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:26,278 -    DEBUG -  cltl.brain.basic_brain.LocationReasoner - Booted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:26.278 DEBUG basic_brain - __init__: Booted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:26,281 -    DEBUG -      cltl.brain.basic_brain.TypeReasoner - Booted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:26.281 DEBUG basic_brain - __init__: Booted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:26,284 -    DEBUG -   cltl.brain.basic_brain.TrustCalculator - Booted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:26.284 DEBUG basic_brain - __init__: Booted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:26,429 -    DEBUG -   cltl.brain.basic_brain.TrustCalculator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:26.429 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:26,436 -     INFO -   cltl.brain.basic_brain.TrustCalculator - Computed trust for all known agents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:26.436 INFO trust_calculator - compute_trust_network: Computed trust for all known agents\n"
     ]
    }
   ],
   "source": [
    "# Initialise the brain in GraphDB\n",
    "import pathlib\n",
    "log_path=pathlib.Path('./logs')\n",
    "print(type(log_path))\n",
    "my_brain = brain.LongTermMemory(address=\"http://localhost:7200/repositories/sandbox\",\n",
    "                           log_dir=log_path,\n",
    "                           clear_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard initialisation of a scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  ./data/2021-10-28-22:45:31  Created \n",
      "Directory  ./data/2021-10-28-22:45:31/image  Created \n"
     ]
    }
   ],
   "source": [
    "from random import getrandbits\n",
    "\n",
    "##### Setting the location\n",
    "place_id = getrandbits(8)\n",
    "location = requests.get(\"https://ipinfo.io\").json()\n",
    "\n",
    "##### Setting the agents\n",
    "agent = \"Leolani2\"\n",
    "human = \"Stranger\"\n",
    "\n",
    "### The name of your scenario\n",
    "scenario_id = datetime.today().strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "\n",
    "### Specify the path to an existing data folder where your scenario is created and saved as a subfolder\n",
    "scenario_path = \"./data\"\n",
    "\n",
    "### Define the folder where the images are saved\n",
    "imagefolder = scenario_path + \"/\" + scenario_id + \"/\" + \"image\"\n",
    "\n",
    "\n",
    "### Create the scenario folder, the json files and a scenarioStorage and scenario in memory\n",
    "scenarioStorage = d_util.create_scenario(scenario_path, scenario_id)\n",
    "scenario = scenarioStorage.create_scenario(scenario_id, datetime.now().microsecond, datetime.now().microsecond, agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the docker containers for face detection and face property detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKIP THIS IF DOCKER IMAGES ARE RUNNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You only need to load the dockers once. The first time you load the docker, the images will be donwloaded from the DockerHub. This may take a few minutes depending on the speed of the internet connection. The images are cached in your local Docker installation.\n",
    "\n",
    "One the images are in your local Docker, they are loaded instantaniously. Once the docker is started you do not need to start it again and you can skip the next commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 09:29:12.348 INFO face_util - start_docker_container: starting a tae898/face-detection-recognition:v0.1 container ...\n",
      "2021-10-28 09:29:18.268 INFO face_util - start_docker_container: starting a tae898/age-gender:v0.2 container ...\n"
     ]
    }
   ],
   "source": [
    "container_fdr = f_util.start_docker_container(\"tae898/face-detection-recognition:v0.1\", 10002)\n",
    "container_ag = f_util.start_docker_container(\"tae898/age-gender:v0.2\", 10003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is a problem starting the dockers, you may need to kill them and start them again. Use the following command to kill and rerun the previous command. Note that if there are running already you should not restart. Starting it again gives an error that the port is occupied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!docker kill $(docker ps -q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are now set to make a new friend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_and_think (scenario: Scenario, \n",
    "                  place_id:str, \n",
    "                  location: str, \n",
    "                  textSignal: TextSignal,\n",
    "                  human: str,\n",
    "                  my_brain:LongTermMemory):\n",
    "    thoughts = \"\"\n",
    "    chat = Chat(human)\n",
    "    chat.add_utterance([UtteranceHypothesis(c_util.seq_to_text(textSignal.seq), 1.0)])\n",
    "    chat.last_utterance.analyze()\n",
    "    # No triple was extracted, so we missed three items (s, p, o)\n",
    "    if chat.last_utterance.triple is None:\n",
    "        utterance = \"Any gossip\" + '\\n'\n",
    "    else:\n",
    "        triple = c_util.rephrase_triple_json_for_capsule(chat.last_utterance.triple)\n",
    "        # A triple was extracted so we compare it elementwise\n",
    "        capsule = c_util.scenario_utterance_and_triple_to_capsule(scenario, \n",
    "                                                                  place_id,\n",
    "                                                                  location,\n",
    "                                                                  textSignal, \n",
    "                                                                  human,\n",
    "                                                                  chat.last_utterance.perspective, \n",
    "                                                                  triple)\n",
    "        print('Capsule:', capsule)\n",
    "        thoughts = my_brain.update(capsule, reason_types=True)\n",
    "        #print(thoughts)\n",
    "    return thoughts    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_new_friend_and_think (scenario: Scenario, \n",
    "                  place_id:str, \n",
    "                  location: str, \n",
    "                  human_id: str,\n",
    "                  textSignal: TextSignal,\n",
    "                  imageSignal: ImageSignal,\n",
    "                  age: str,\n",
    "                  gender: str,\n",
    "                  human_name: str,\n",
    "                  my_brain:LongTermMemory):\n",
    "    age_thoughts = \"\"\n",
    "    gender_thoughts = \"\"\n",
    "    name_thoughts = \"\"\n",
    "\n",
    "\n",
    "    if human_name:\n",
    "        # A triple was extracted so we compare it elementwise\n",
    "        perspective = {\"certainty\": 1, \"polarity\": 1, \"sentiment\": 1}\n",
    "        capsule = c_util.scenario_utterance_to_capsule(scenario, \n",
    "                                                                  place_id,\n",
    "                                                                  location,\n",
    "                                                                  textSignal,\n",
    "                                                                  human_id,\n",
    "                                                                  perspective,\n",
    "                                                                  human_id,\n",
    "                                                                  \"label\",\n",
    "                                                                  human_name)\n",
    "\n",
    "        name_thoughts = my_brain.update(capsule, reason_types=True)\n",
    "        print('Name capsule:', capsule)\n",
    "\n",
    "\n",
    "    if age:\n",
    "        # A triple was extracted so we compare it elementwise\n",
    "        capsule = c_util.scenario_image_triple_to_capsule(scenario, \n",
    "                                                                  place_id,\n",
    "                                                                  location,\n",
    "                                                                  imageSignal,\n",
    "                                                                  \"front_camera\", \n",
    "                                                                  human_id,\n",
    "                                                                  \"age\",\n",
    "                                                                  str(age))\n",
    "\n",
    "        age_thoughts = my_brain.update(capsule, reason_types=True)\n",
    "        print('Age capsule:', capsule)\n",
    "\n",
    "    if gender:\n",
    "        capsule = c_util.scenario_image_triple_to_capsule(scenario, \n",
    "                                                                  place_id,\n",
    "                                                                  location,\n",
    "                                                                  imageSignal,\n",
    "                                                                  \"front_camera\", \n",
    "                                                                  human_id,\n",
    "                                                                  \"gender\",\n",
    "                                                                  gender)\n",
    "\n",
    "        gender_thoughts = my_brain.update(capsule, reason_types=True)\n",
    "        print('Gender capsule:', capsule)\n",
    "\n",
    "        #print(thoughts)\n",
    "    return name_thoughts, age_thoughts, gender_thoughts    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_to_know_person(scenario: Scenario, agent:str, gender:str, age: str, uuid_name: str, embedding):\n",
    "        ### This is a stranger\n",
    "        ### We create the agent response and store it as a text signal\n",
    "        human_name = \"Stranger\"\n",
    "        response = (\n",
    "            f\"Hi there. We haven't met. I only know that \\n\"\n",
    "            f\"your estimated age is {age} \\n and that your estimated gender is \"\n",
    "            f\"{gender}. What's your name?\"\n",
    "        )\n",
    "        print(f\"{agent}: {response}\")\n",
    "        textSignal = d_util.create_text_signal(scenario, response)\n",
    "        scenario.append_signal(textSignal)\n",
    "        \n",
    "        confirm = \"\"\n",
    "        while confirm.lower().find(\"yes\")==-1:\n",
    "            ### We take the response from the user and store it as a text signal\n",
    "            utterance = input(\"\\n\")\n",
    "            textSignal = d_util.create_text_signal(scenario, utterance)\n",
    "            scenario.append_signal(textSignal)\n",
    "            print(utterance)\n",
    "            #### We hack the response to find the name of our new fiend\n",
    "            #### This name needs to be set in the scenario and assigned to the global variable human\n",
    "            human_name = \" \".join([foo.title() for foo in utterance.strip().split()])\n",
    "            human_name = \"_\".join(human_name.split())\n",
    "        \n",
    "            response = (f\"So your name is {human_name}?\")\n",
    "            print(f\"{agent}: {response}\")\n",
    "            textSignal = d_util.create_text_signal(scenario, response)\n",
    "            scenario.append_signal(textSignal)\n",
    "            \n",
    "            ### We take the response from the user and store it as a text signal\n",
    "            confirm = input(\"\\n\")\n",
    "            textSignal = d_util.create_text_signal(scenario, confirm)\n",
    "            scenario.append_signal(textSignal)\n",
    "\n",
    "\n",
    "        current_time = str(datetime.now().microsecond)\n",
    "        human_id = human_name+\"_t_\"+current_time\n",
    "        #### We create the embedding\n",
    "        to_save = {\"uuid\": uuid_name[\"uuid\"], \"embedding\": embedding}\n",
    "\n",
    "        with open(f\"./friend_embeddings/{human_id}.pkl\", \"wb\") as stream:\n",
    "            pickle.dump(to_save, stream)\n",
    "            \n",
    "        return human_id, human_name, textSignal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Friends of Leolani are saved in the embeddings folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:39.807 INFO face_util - load_binary_image: ./data/2021-10-28-22:45:31/image/762056.png image loaded!\n",
      "2021-10-28 22:45:40.592 INFO face_util - run_face_api: got <Response [200]> from server!...\n",
      "2021-10-28 22:45:40.593 INFO face_util - run_face_api: 1 faces deteced!\n",
      "2021-10-28 22:45:40.595 INFO face_util - face_recognition: new face!\n",
      "2021-10-28 22:45:40.664 INFO face_util - run_age_gender_api: got <Response [200]> from server!...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: Hi there. We haven't met. I only know that \n",
      "your estimated age is 33 \n",
      " and that your estimated gender is male. What's your name?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Piek\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek\n",
      "Leolani2: So your name is Piek?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:46,557 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:46.557 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:46,564 -    DEBUG -  cltl.brain.basic_brain.LocationReasoner - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:46.564 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:46,583 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: piek-t-517960_label_piek [person_->_object])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:46.583 INFO LTM_statement_processing - model_graphs: Triple in statement: piek-t-517960_label_piek [person_->_object])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:46,585 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:46.585 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:46,591 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:46.591 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:46,597 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:46.597 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:46,604 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Entity Novelty: new subject - new object \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:46.604 INFO thought_generator - fill_entity_novelty: Entity Novelty: new subject - new object \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:46,605 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:46.605 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:46,612 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:46.612 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47,451 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting triples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47.451 DEBUG basic_brain - _upload_to_brain: Posting triples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47,738 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47.738 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47,746 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Negation Conflicts: piek-t-517960 on October,2021 about POSITIVE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47.746 INFO thought_generator - get_negation_conflicts: Negation Conflicts: piek-t-517960 on October,2021 about POSITIVE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47,748 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47.748 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47,758 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47.758 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47,766 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. be-member-of institution - 15 gaps as object: e.g. cook-by food\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47.766 INFO thought_generator - get_entity_gaps: Gaps: 26 gaps as subject: e.g. be-member-of institution - 15 gaps as object: e.g. cook-by food\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47,768 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47.768 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47,774 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47.774 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47,782 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 0 gaps as subject: e.g. '' - 2 gaps as object: e.g. own agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47.782 INFO thought_generator - get_entity_gaps: Gaps: 0 gaps as subject: e.g. '' - 2 gaps as object: e.g. own agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47,784 -    DEBUG -   cltl.brain.basic_brain.TrustCalculator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47.784 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name capsule: {'chat': '2021-10-28-22:45:31', 'turn': '6ae63c95-972f-45cd-9e16-f6d51ee81e33', 'author': 'piek-t-517960', 'utterance': 'yes', 'utterance_type': <UtteranceType.STATEMENT: 0>, 'position': '0-3', 'subject': {'label': 'Piek_t_517960', 'type': 'person'}, 'predicate': {'type': 'label'}, 'object': {'label': 'Piek', 'type': 'object'}, 'perspective': <cltl.brain.infrastructure.api.Perspective object at 0x7f91004446d0>, 'context_id': 'Leolani2', 'date': datetime.date(2021, 10, 28), 'place': 'Weesp', 'place_id': 64, 'country': 'NL', 'region': 'North Holland', 'city': 'Weesp', 'objects': [{'type': 'chair', 'confidence': 0.59, 'id': 1}, {'type': 'table', 'confidence': 0.73, 'id': 1}, {'type': 'pillbox', 'confidence': 0.32, 'id': 1}], 'people': [{'name': 'Piek_t_517960', 'confidence': 0.98, 'id': 1}], 'triple': piek-t-517960_label_piek [person_->_object]), 'type': <UtteranceType.STATEMENT: 0>}\n",
      "2021-10-28 22:45:47,794 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47.794 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47,800 -    DEBUG -  cltl.brain.basic_brain.LocationReasoner - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47.800 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47,820 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: piek-t-517960_age_33 [person_->_string])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47.820 INFO LTM_statement_processing - model_graphs: Triple in statement: piek-t-517960_age_33 [person_->_string])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47,821 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47.821 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47,827 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47.827 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47,833 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47.833 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47,838 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Entity Novelty: existing subject - new object \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47.838 INFO thought_generator - fill_entity_novelty: Entity Novelty: existing subject - new object \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47,840 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47.840 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47,847 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:47.847 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:48,788 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting triples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:48.788 DEBUG basic_brain - _upload_to_brain: Posting triples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49,071 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49.071 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49,078 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Negation Conflicts: front-camera on October,2021 about POSITIVE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49.078 INFO thought_generator - get_negation_conflicts: Negation Conflicts: front-camera on October,2021 about POSITIVE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49,080 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49.080 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49,090 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49.090 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49,100 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. work-at institution - 15 gaps as object: e.g. like agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49.100 INFO thought_generator - get_entity_gaps: Gaps: 26 gaps as subject: e.g. work-at institution - 15 gaps as object: e.g. like agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49,102 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49.102 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49,109 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49.109 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49,116 -    DEBUG -   cltl.brain.basic_brain.TrustCalculator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49.116 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age capsule: {'chat': '2021-10-28-22:45:31', 'turn': '0e5b4c78-abbc-45f9-bd73-522cc49c5c80', 'author': 'front-camera', 'utterance': '', 'position': 'image', 'perspective': <cltl.brain.infrastructure.api.Perspective object at 0x7f9151767790>, 'subject': {'label': 'Piek_t_517960', 'type': 'person'}, 'predicate': {'type': 'age'}, 'object': {'label': '33', 'type': 'string'}, 'context_id': 'Leolani2', 'date': datetime.date(2021, 10, 28), 'place': 'Weesp', 'place_id': 64, 'country': 'NL', 'region': 'North Holland', 'city': 'Weesp', 'objects': [{'type': 'chair', 'confidence': 0.59, 'id': 1}, {'type': 'table', 'confidence': 0.73, 'id': 1}, {'type': 'pillbox', 'confidence': 0.32, 'id': 1}], 'people': [{'name': 'front_camera', 'confidence': 0.98, 'id': 1}], 'triple': piek-t-517960_age_33 [person_->_string]), 'type': <UtteranceType.STATEMENT: 0>}\n",
      "2021-10-28 22:45:49,127 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49.127 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49,134 -    DEBUG -  cltl.brain.basic_brain.LocationReasoner - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49.134 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49,156 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: piek-t-517960_gender_male [person_->_string])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49.156 INFO LTM_statement_processing - model_graphs: Triple in statement: piek-t-517960_gender_male [person_->_string])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49,157 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49.157 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49,163 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49.163 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49,169 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49.169 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49,174 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Entity Novelty: existing subject - new object \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49.174 INFO thought_generator - fill_entity_novelty: Entity Novelty: existing subject - new object \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49,175 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49.175 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49,182 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:49.182 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:50,166 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting triples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:50.166 DEBUG basic_brain - _upload_to_brain: Posting triples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:50,469 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:50.469 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:50,476 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Negation Conflicts: front-camera on October,2021 about POSITIVE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:50.476 INFO thought_generator - get_negation_conflicts: Negation Conflicts: front-camera on October,2021 about POSITIVE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:50,478 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:50.478 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:50,487 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:50.487 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:50,496 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. favorite interest - 15 gaps as object: e.g. read-by book\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:50.496 INFO thought_generator - get_entity_gaps: Gaps: 26 gaps as subject: e.g. favorite interest - 15 gaps as object: e.g. read-by book\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:50,498 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:50.498 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:50,505 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:50.505 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:50,510 -    DEBUG -   cltl.brain.basic_brain.TrustCalculator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:50.510 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender capsule: {'chat': '2021-10-28-22:45:31', 'turn': '0e5b4c78-abbc-45f9-bd73-522cc49c5c80', 'author': 'front-camera', 'utterance': '', 'position': 'image', 'perspective': <cltl.brain.infrastructure.api.Perspective object at 0x7f91203ac790>, 'subject': {'label': 'Piek_t_517960', 'type': 'person'}, 'predicate': {'type': 'gender'}, 'object': {'label': 'male', 'type': 'string'}, 'context_id': 'Leolani2', 'date': datetime.date(2021, 10, 28), 'place': 'Weesp', 'place_id': 64, 'country': 'NL', 'region': 'North Holland', 'city': 'Weesp', 'objects': [{'type': 'chair', 'confidence': 0.59, 'id': 1}, {'type': 'table', 'confidence': 0.73, 'id': 1}, {'type': 'pillbox', 'confidence': 0.32, 'id': 1}], 'people': [{'name': 'front_camera', 'confidence': 0.98, 'id': 1}], 'triple': piek-t-517960_gender_male [person_->_string]), 'type': <UtteranceType.STATEMENT: 0>}\n",
      "Leolani2: Nice to meet you, Piek\n"
     ]
    }
   ],
   "source": [
    "#First step is to identify the speaker\n",
    "\n",
    "imagepath = \"\"\n",
    "uuid_name = \"\"\n",
    "# First signal\n",
    "success, frame = camera.read()\n",
    "\n",
    "if success:\n",
    "    ### check if we know the human\n",
    "    current_time = str(datetime.now().microsecond)\n",
    "    imagepath = imagefolder + \"/\" + current_time + \".png\"\n",
    "    cv2.imwrite(imagepath, frame)\n",
    "    imageSignal = d_util.create_image_signal(scenario, imagepath)\n",
    "    (\n",
    "        genders,\n",
    "        ages,\n",
    "        bboxes,\n",
    "        faces_detected,\n",
    "        det_scores,embeddings,\n",
    "    ) = f_util.do_stuff_with_image(imagepath)\n",
    "\n",
    "    # Here we assume that only one face is in the image\n",
    "    # TODO: deal with multiple people.\n",
    "    for k, (gender, age, bbox, uuid_name, faceprob, embedding) in enumerate(\n",
    "        zip(genders, ages, bboxes, faces_detected, det_scores, embeddings)\n",
    "    ):\n",
    "        age = round(age[\"mean\"])\n",
    "        gender = \"male\" if gender[\"m\"] > 0.5 else \"female\"\n",
    "        bbox = [int(num) for num in bbox.tolist()]\n",
    "    assert k == 0\n",
    "    if uuid_name[\"name\"] is None:\n",
    "        ### This is a stranger\n",
    "        \n",
    "\n",
    "        human_id, human, textSignal = get_to_know_person(scenario, agent, gender, age, uuid_name, embedding)\n",
    "                    \n",
    "        name_thoughts, age_thoughts, gender_thoughts = process_new_friend_and_think (scenario, \n",
    "                  place_id, \n",
    "                  location, \n",
    "                  human_id,\n",
    "                  textSignal,\n",
    "                  imageSignal,\n",
    "                  age,\n",
    "                  gender,\n",
    "                  human,\n",
    "                  my_brain)\n",
    "        \n",
    "        ### The system responds to the processing of the new name input and stores it as a textsignal\n",
    "        print(agent + f\": Nice to meet you, {human}\")\n",
    "        response = f\": Nice to meet you, {human}\"\n",
    "        textSignal = d_util.create_text_signal(scenario, response)\n",
    "        scenario.append_signal(textSignal)\n",
    "\n",
    "    else:\n",
    "        ### We know this person\n",
    "        human_id= uuid_name['name']\n",
    "        human = human_id.split(\"_t_\")[0]\n",
    "        response = f\"Hi {human}. Nice to see you again :)\"\n",
    "        print(f\"{agent}: {response}\")\n",
    "        textSignal = d_util.create_text_signal(scenario, response)\n",
    "        scenario.append_signal(textSignal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceed with the communication with an identified friend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: How are you doingPiek\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " I like pizza\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piek: I like pizza\n",
      "2021-10-28 22:45:59,231 -     INFO - cltl.triple_extraction.api.Chat (Piek)              000 - << Start of Chat with Piek >>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:59.231 INFO api - __init__: << Start of Chat with Piek >>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:59,232 -     INFO -               cltl.triple_extraction.api - Started POS tagger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:59.232 INFO api - __init__: Started POS tagger\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:59,234 -     INFO -               cltl.triple_extraction.api - Started NER tagger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:59.234 INFO api - __init__: Started NER tagger\n",
      "2021-10-28 22:45:59.248 INFO ner - _start_server: Started NER server\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:59,250 -     INFO -               cltl.triple_extraction.api - Loaded grammar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:45:59.250 INFO api - __init__: Loaded grammar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:00,406 -     INFO - cltl.triple_extraction.api.Chat (Piek)              001 -       Piek: \"I like pizza\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:00.406 INFO api - add_utterance:       Piek: \"I like pizza\"\n",
      "2021-10-28 22:46:00.419 INFO ner - _start_server: Started NER server\n",
      "2021-10-28 22:46:01.903 INFO analyzer - __init__: extracted perspective: {'sentiment': '0.75', 'certainty': 1, 'polarity': 1, 'emotion': <Emotion.NEUTRAL: 7>}\n",
      "2021-10-28 22:46:01.908 INFO api - analyze: RDF    subject: {\"label\": \"Piek\", \"type\": [\"agent\"]}\n",
      "2021-10-28 22:46:01.908 INFO api - analyze: RDF  predicate: {\"label\": \"like\", \"type\": [\"verb.emotion\"]}\n",
      "2021-10-28 22:46:01.909 INFO api - analyze: RDF     object: {\"label\": \"pizza\", \"type\": [\"noun.food\"]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subject': {'label': 'Piek', 'type': ['agent']}, 'predicate': {'label': 'like', 'type': ['verb.emotion']}, 'object': {'label': 'pizza', 'type': ['noun.food']}}\n",
      "{'subject': {'Piek', 'agent'}, 'predicate': {'like', 'emotion'}, 'object': {'pizza', 'food'}}\n",
      "Capsule: {'chat': '2021-10-28-22:45:31', 'turn': '3652934c-ad68-4b4e-8b61-e301529b24cd', 'author': 'Piek', 'utterance': 'I like pizza', 'utterance_type': <UtteranceType.STATEMENT: 0>, 'position': '0-12', 'subject': {'label': 'piek', 'type': 'person'}, 'predicate': {'type': 'see'}, 'object': {'label': 'pills', 'type': 'object'}, 'perspective': {'sentiment': '0.75', 'certainty': 1, 'polarity': 1, 'emotion': <Emotion.NEUTRAL: 7>}, 'context_id': 'Leolani2', 'date': datetime.date(2021, 10, 28), 'place': 'Weesp', 'place_id': 64, 'country': 'NL', 'region': 'North Holland', 'city': 'Weesp', 'objects': [{'type': 'chair', 'confidence': 0.59, 'id': 1}, {'type': 'table', 'confidence': 0.73, 'id': 1}, {'type': 'pillbox', 'confidence': 0.32, 'id': 1}], 'people': [{'name': 'Piek', 'confidence': 0.98, 'id': 1}]}\n",
      "2021-10-28 22:46:01,914 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:01.914 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:01,943 -    DEBUG -  cltl.brain.basic_brain.LocationReasoner - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:01.943 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:01,961 -     INFO -    cltl.brain.basic_brain.LongTermMemory - Triple in statement: piek_see_pills [person_->_object])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:01.961 INFO LTM_statement_processing - model_graphs: Triple in statement: piek_see_pills [person_->_object])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:01,963 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:01.963 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:01,992 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:01.992 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:01,997 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:01.997 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:02,040 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Entity Novelty: new subject - new object \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:02.040 INFO thought_generator - fill_entity_novelty: Entity Novelty: new subject - new object \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:02,041 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:02.041 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:02,048 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:02.048 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:03,068 -    DEBUG -    cltl.brain.basic_brain.LongTermMemory - Posting triples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:03.068 DEBUG basic_brain - _upload_to_brain: Posting triples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:03,946 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:03.946 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:03,992 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Negation Conflicts: piek on October,2021 about POSITIVE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:03.992 INFO thought_generator - get_negation_conflicts: Negation Conflicts: piek on October,2021 about POSITIVE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:03,994 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:03.994 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:04,003 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:04.003 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:04,043 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 26 gaps as subject: e.g. experience taste - 17 gaps as object: e.g. like agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:04.043 INFO thought_generator - get_entity_gaps: Gaps: 26 gaps as subject: e.g. experience taste - 17 gaps as object: e.g. like agent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:04,045 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:04.045 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:04,099 -    DEBUG -  cltl.brain.basic_brain.ThoughtGenerator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:04.099 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:04,145 -     INFO -  cltl.brain.basic_brain.ThoughtGenerator - Gaps: 0 gaps as subject: e.g. '' - 2 gaps as object: e.g. own person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:04.145 INFO thought_generator - get_entity_gaps: Gaps: 0 gaps as subject: e.g. '' - 2 gaps as object: e.g. own person\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:04,147 -    DEBUG -   cltl.brain.basic_brain.TrustCalculator - Posting query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:04.147 DEBUG basic_brain - _submit_query: Posting query\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leolani2: So you what do you want to talk about Piek\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Bye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-28 22:46:07.147 INFO face_util - load_binary_image: ./data/2021-10-28-22:45:31/image/102140.png image loaded!\n",
      "2021-10-28 22:46:07.896 INFO face_util - run_face_api: got <Response [200]> from server!...\n",
      "2021-10-28 22:46:07.898 INFO face_util - run_face_api: 1 faces deteced!\n",
      "2021-10-28 22:46:07.942 INFO face_util - run_age_gender_api: got <Response [200]> from server!...\n"
     ]
    }
   ],
   "source": [
    "### First prompt\n",
    "response = \"How are you doing\"+human\n",
    "textSignal = d_util.create_text_signal(scenario, response)\n",
    "scenario.append_signal(textSignal)\n",
    "\n",
    "print(agent + \": \" + response)\n",
    "\n",
    "utterance = input(\"\\n\")\n",
    "print(human + \": \" + utterance)\n",
    "\n",
    "while not (utterance.lower() == \"stop\" or utterance.lower() == \"bye\"):\n",
    "    textSignal = d_util.create_text_signal(scenario, utterance)\n",
    "    scenario.append_signal(textSignal)\n",
    "\n",
    "    # @TODO: also annotate the textSignal\n",
    "    # Apply some processing to the textSignal and add annotations\n",
    "        \n",
    "    # We process the utterance and store triples in the brain\n",
    "    # We catch the thoughts as the response\n",
    "    thoughts = process_text_and_think (scenario, \n",
    "                  place_id, \n",
    "                  location, \n",
    "                  textSignal, \n",
    "                  human, my_brain)\n",
    "        \n",
    "    ## We capture the image again\n",
    "    if success:\n",
    "        imageSignal = d_util.create_image_signal(scenario, imagepath)\n",
    "        container_id = str(uuid.uuid4())\n",
    "\n",
    "        #### Properties are now stored as annotations\n",
    "        #### We do not store these proeprties again to the BRAIN\n",
    "        for gender, age, bbox, name, faceprob in zip(\n",
    "            genders, ages, bboxes, faces_detected, det_scores\n",
    "        ):\n",
    "\n",
    "            age = round(age[\"mean\"])\n",
    "            gender = \"male\" if gender[\"m\"] > 0.5 else \"female\"\n",
    "            bbox = [int(num) for num in bbox.tolist()]\n",
    "\n",
    "            annotations = []\n",
    "\n",
    "            annotations.append(\n",
    "                {\n",
    "                    \"source\": \"machine\",\n",
    "                    \"timestamp\": current_time,\n",
    "                    \"type\": \"person\",\n",
    "                    \"value\": {\n",
    "                        \"name\": name,\n",
    "                        \"age\": age,\n",
    "                        \"gender\": gender,\n",
    "                        \"faceprob\": faceprob,\n",
    "                    },\n",
    "                }\n",
    "            )\n",
    "\n",
    "            mention_id = str(uuid.uuid4())\n",
    "            segment = [\n",
    "                {\"bounds\": bbox, \"container_id\": container_id, \"type\": \"MultiIndex\"}\n",
    "            ]\n",
    "            imageSignal.mentions.append(\n",
    "                {\"annotations\": annotations, \"id\": mention_id, \"segment\": segment}\n",
    "            )\n",
    "\n",
    "        scenario.append_signal(imageSignal)\n",
    "\n",
    "    # Create the response from the system and store this as a new signal\n",
    "    # We could use the throughts to respond\n",
    "    # @TODO generate a response from the thoughts\n",
    "\n",
    "    utterance = \"So you what do you want to talk about \" + human + \"\\n\"\n",
    "    response = utterance[::-1]\n",
    "    print(agent + \": \" + utterance)\n",
    "    textSignal = d_util.create_text_signal(scenario, utterance)\n",
    "    scenario.append_signal(textSignal)\n",
    "\n",
    "    # Getting the next input signals\n",
    "    utterance = input(\"\\n\")\n",
    "\n",
    "    success, frame = camera.read()\n",
    "    if success:\n",
    "        current_time = str(datetime.now().microsecond)\n",
    "        imagepath = imagefolder + \"/\" + current_time + \".png\"\n",
    "        cv2.imwrite(imagepath, frame)\n",
    "        (\n",
    "            genders,\n",
    "            ages,\n",
    "            bboxes,\n",
    "            faces_detected,\n",
    "            det_scores,\n",
    "            embeddings,\n",
    "        ) = f_util.do_stuff_with_image(imagepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the end time of the scenario, save it and stop the containers\n",
    "\n",
    "After we stopped the interaction, we set the end time and save the scenario as EMISSOR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scenario.scenario.end = datetime.now().microsecond\n",
    "scenarioStorage.save_scenario(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stopping the docker containers\n",
    "### This is only needed of you started them in this notebook\n",
    "\n",
    "#f_util.kill_container(container_fdr)\n",
    "#f_util.kill_container(container_ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Stop the camera when we are done\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
