{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMISSOR chat bot with audio backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNDER CONSTRUCTION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running with ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cltl.asr.speechbrain_asr import SpeechbrainASR\n",
    "from cltl.asr.wav2vec_asr import Wav2Vec2ASR\n",
    "from cltl.backend.api.camera import CameraResolution\n",
    "from cltl.backend.source.pyaudio_source import PyAudioSource\n",
    "from cltl.backend.source.cv2_source import SystemImageSource\n",
    "from cltl.backend.source.client_source import ClientAudioSource, ClientImageSource\n",
    "from cltl.vad.webrtc_vad import WebRtcVAD\n",
    "\n",
    "from cltl.backend.api.util import raw_frames_to_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_remote = False\n",
    "\n",
    "audio_source = (\n",
    "    ClientAudioSource(\"http://192.168.1.176:8000/audio\")\n",
    "    if run_remote\n",
    "    else PyAudioSource(16000, 1, 480)\n",
    ")\n",
    "image_source = (\n",
    "    ClientImageSource(\"http://192.168.1.176:8000/video\")\n",
    "    if run_remote\n",
    "    else SystemImageSource(CameraResolution.QVGA)\n",
    ")\n",
    "\n",
    "\n",
    "# Add a `storage` directory to store audio files to VAD or ASR for debugging\n",
    "vad = WebRtcVAD(allow_gap=250, padding=5)\n",
    "asr = Wav2Vec2ASR(\"jonatasgrosman/wav2vec2-large-xlsr-53-english\", 16000)\n",
    "# asr = SpeechbrainASR(model_id=\"speechbrain/asr-transformer-transformerlm-librispeech\", sampling_rate=16000, storage=\"wav\")\n",
    "\n",
    "\n",
    "def detect_and_transcribe():\n",
    "    with audio_source as audio:\n",
    "        frames = raw_frames_to_np(\n",
    "            audio, audio_source.frame_size, audio_source.channels, audio_source.depth\n",
    "        )\n",
    "\n",
    "        print(\"Listening\")\n",
    "        speech, offset, consumed = tuple(vad.detect_vad(frames, audio_source.rate))\n",
    "        print(\"Voice activity detected\")\n",
    "\n",
    "        with image_source as img_src:\n",
    "            image = img_src.capture()\n",
    "\n",
    "        text = asr.speech_to_text(np.concatenate(tuple(speech)), audio_source.rate)\n",
    "\n",
    "        return text, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    print(\"Please talk to calibrate Voice Activity Detection\")\n",
    "    try:\n",
    "        detect_and_transcribe()\n",
    "    except Exception as e:\n",
    "        print(\"Failed\", e)\n",
    "\n",
    "print(\"Calibrated VAD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tts_headers = {\"Content-type\": \"text/plain\"}\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        text, image = detect_and_transcribe()\n",
    "        print(\"Detected text:\", text)\n",
    "\n",
    "        print(\"Captured image:\", image.image.shape)\n",
    "        plt.imshow(image.image)\n",
    "        plt.show()\n",
    "\n",
    "        if run_remote:\n",
    "            requests.post(\n",
    "                \"http://192.168.1.176:8000/text\",\n",
    "                data=f\"Did you say {text}?\",\n",
    "                headers=tts_headers,\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(\"Failed\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}